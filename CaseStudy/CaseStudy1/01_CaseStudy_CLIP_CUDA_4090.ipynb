{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e7c181-807c-450e-bcd1-c0e534afb410",
   "metadata": {},
   "source": [
    "Case study 1: Single-Category Classification using N24News Dataset\n",
    "-------------------------------------------------------------\n",
    "\n",
    "This demo shows how to classify a single news article into one of 24 category\n",
    "using the N24News dataset. Each article in the dataset includes both textual\n",
    "and visual information.\n",
    "\n",
    "Source: https://aclanthology.org/2022.lrec-1.729/\n",
    "\n",
    "\n",
    "Each article contains the following fields:\n",
    "- 'section': Ground truth label (one of 24 category)\n",
    "- 'headline': Title of the article\n",
    "- 'abstract': Short summary of the article\n",
    "- 'article': Full text content\n",
    "- 'article_url': Link to the original article\n",
    "- 'image': Encoded image or metadata (optional)\n",
    "- 'caption': Image caption\n",
    "- 'image_id': Unique image identifier\n",
    "- 'image_path': Path to the associated image (e.g., 'N24News/imgs_200_sample1/12345.jpg')\n",
    "- 'article_id': Unique article identifier\n",
    "\n",
    "Image file: Multimodal_image\n",
    "\n",
    "Example category (See prompt_D1 for the complete category):\n",
    "------------------------\n",
    "1. Health\n",
    "2. Science\n",
    "3. Television\n",
    "...\n",
    "24. Global Business\n",
    "\n",
    "Reference:\n",
    "----------\n",
    "Wang, Z., Shan, X., Zhang, X., & Yang, J. (2022).\n",
    "N24News: A New Dataset for Multimodal News Classification.\n",
    "In *Proceedings of the Thirteenth Language Resources and Evaluation Conference* (pp. 6768â€“6775). LREC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770cb33d-5029-4e57-87f6-4b99aa9f2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade openai\n",
    "#!pip install --upgrade labelgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a79fbe4-dd49-40ec-b01a-9aebf484e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498d734c-217b-433b-9c7c-7ec5a4af868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2025-10-15 22:37:29.008444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-15 22:37:29.019758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-15 22:37:29.023229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-15 22:37:29.032424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-15 22:37:29.623218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jc/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from labelgenius import (\n",
    "    classification_CLIP_0_shot,\n",
    "    classification_CLIP_finetuned,\n",
    "    finetune_CLIP,\n",
    "    auto_verification,\n",
    "    classification_GPT,\n",
    "    generate_GPT_finetune_jsonl,\n",
    "    finetune_GPT,\n",
    "    price_estimation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e285eee-d2c6-49d9-8bc3-193509bea0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import base64\n",
    "import hashlib\n",
    "import threading\n",
    "import csv\n",
    "import warnings\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import CLIPProcessor, CLIPModel, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torchvision import transforms\n",
    "\n",
    "import sqlitedict\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# Device / Env\n",
    "# =========================\n",
    "def pick_device(prefer: str | None = None) -> torch.device:\n",
    "    if prefer == \"cuda\" and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if prefer == \"mps\" and hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if prefer == \"cpu\":\n",
    "        return torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = pick_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "FRIENDLY_MODEL_MESSAGE = (\n",
    "    \"You are encountering this error very likely because OpenAI updated model names \"\n",
    "    \"and/or parameters. Please check the current list of available models here:\\n\"\n",
    "    \"https://platform.openai.com/docs/models\\n\\n\"\n",
    "    \"After you identify the new model to use, please test it in the Playground to see \"\n",
    "    \"which parameters are supported:\\n\"\n",
    "    \"https://platform.openai.com/playground\\n\\n\"\n",
    "    \"If you continue to encounter errors, please email the author \"\n",
    "    \"[email removed due to double-blind revision process].\")\n",
    "\n",
    "_SAFE_DEFAULTS = dict(temperature=0.2, max_tokens=512)\n",
    "\n",
    "_MODEL_FALLBACKS = {\n",
    "    \"gpt-o4-mini\": [\"gpt-4o-mini\", \"gpt-4.1-mini\", \"gpt-4o\", \"gpt-4.1\"],\n",
    "    \"gpt-4o-mini\": [\"gpt-4.1-mini\", \"gpt-4o\", \"gpt-4.1\"],\n",
    "    \"gpt-5-nano\":  [\"gpt-4.1-mini\", \"gpt-4o-mini\", \"gpt-4.1\"],\n",
    "}\n",
    "\n",
    "def _strip_unknown_kwargs(kwargs: dict) -> dict:\n",
    "    bad = {\"reasoning\", \"reasoning_effort\", \"type\", \"top_logprobs\"}  # extend as needed\n",
    "    return {k: v for k, v in kwargs.items() if k not in bad}\n",
    "\n",
    "def _is_model_or_param_error(err: Exception) -> bool:\n",
    "    t = str(err).lower()\n",
    "    return any(s in t for s in [\n",
    "        \"invalid_request_error\", \"model_not_found\", \"unknown parameter\", \"unrecognized\",\n",
    "        \"unsupported\", \"does not exist\", \"not permitted\", \"missing required property\",\n",
    "    ])\n",
    "\n",
    "def print_env_info():\n",
    "    import platform, sys as _sys\n",
    "    try:\n",
    "        import openai as _oai\n",
    "        sdk_ver = getattr(_oai, \"__version__\", \"unknown\")\n",
    "    except Exception:\n",
    "        sdk_ver = \"unknown\"\n",
    "    logger.info(f\"[ENV] Python: {_sys.version.replace(chr(10),' ')}\")\n",
    "    logger.info(f\"[ENV] OpenAI SDK: {sdk_ver}\")\n",
    "    logger.info(f\"[ENV] Platform: {platform.platform()}\")\n",
    "\n",
    "# =========================\n",
    "# CLIP (zero-shot + fine-tune)\n",
    "# =========================\n",
    "base_model = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "def classification_CLIP_0_shot(\n",
    "    text_path,\n",
    "    img_dir=None,\n",
    "    mode=None,\n",
    "    prompt=None,\n",
    "    text_column=None,\n",
    "    predict_column=\"label\",\n",
    "):\n",
    "    if mode not in [\"text\", \"image\", \"both\"]:\n",
    "        raise ValueError(\"mode must be 'text', 'image', or 'both'\")\n",
    "    if prompt is None:\n",
    "        # NOTE: your original code referenced prompt_D1_CLIP; left unchanged\n",
    "        prompt = prompt_D1_CLIP  # noqa: F821 (assumed provided elsewhere)\n",
    "\n",
    "    use_text  = mode in [\"text\", \"both\"]\n",
    "    use_image = mode in [\"image\", \"both\"]\n",
    "\n",
    "    if use_text and not text_path:\n",
    "        raise ValueError(\"text_path cannot be empty\")\n",
    "    if use_image and not img_dir:\n",
    "        raise ValueError(\"img_dir cannot be empty\")\n",
    "\n",
    "    model     = CLIPModel.from_pretrained(base_model).to(device)\n",
    "    processor = CLIPProcessor.from_pretrained(base_model)\n",
    "\n",
    "    if text_path.endswith(\".csv\") or text_path.endswith(\".txt\"):\n",
    "        df = pd.read_csv(text_path)\n",
    "    elif text_path.endswith(\".jsonl\"):\n",
    "        df = pd.read_json(text_path, lines=True)\n",
    "    elif text_path.endswith((\".xlsx\", \".xls\")):\n",
    "        df = pd.read_excel(text_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t_inputs        = processor(text=prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "        prompt_features = model.get_text_features(**t_inputs)\n",
    "        prompt_features = F.normalize(prompt_features, p=2, dim=1)\n",
    "\n",
    "    predictions = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting\"):\n",
    "        sample_text = \"\"\n",
    "        if use_text:\n",
    "            sample_text = \" \".join(str(row[c]).strip() for c in text_column if c in row and pd.notna(row[c]))\n",
    "\n",
    "        image = None\n",
    "        if use_image:\n",
    "            img_path = os.path.join(img_dir, f\"{row['image_id']}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            else:\n",
    "                print(f\"Image does not exist: {img_path}\")\n",
    "                image = Image.new(\"RGB\", (224, 224), color=\"white\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if use_text and use_image:\n",
    "                inputs      = processor(text=sample_text, images=image, return_tensors=\"pt\").to(device)\n",
    "                text_f      = model.get_text_features(\n",
    "                    **{k: v for k, v in inputs.items() if k in [\"input_ids\", \"attention_mask\", \"position_ids\"]}\n",
    "                )\n",
    "                img_f       = model.get_image_features(inputs.pixel_values)\n",
    "                sample_feat = F.normalize((text_f + img_f) / 2, p=2, dim=1)\n",
    "            elif use_text:\n",
    "                inputs      = processor(text=sample_text, return_tensors=\"pt\").to(device)\n",
    "                text_f      = model.get_text_features(**inputs)\n",
    "                sample_feat = F.normalize(text_f, p=2, dim=1)\n",
    "            else:\n",
    "                inputs      = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "                img_f       = model.get_image_features(inputs.pixel_values)\n",
    "                sample_feat = F.normalize(img_f, p=2, dim=1)\n",
    "\n",
    "            sim      = sample_feat @ prompt_features.t()\n",
    "            pred_cls = sim.argmax().item() + 1\n",
    "            predictions.append(pred_cls)\n",
    "\n",
    "    df[predict_column] = predictions\n",
    "    return df\n",
    "\n",
    "class CLIPClassifier(torch.nn.Module):\n",
    "    def __init__(self, clip_model, num_classes, use_text=True, use_image=True):\n",
    "        super().__init__()\n",
    "        self.clip_model = clip_model\n",
    "        self.use_text   = use_text\n",
    "        self.use_image  = use_image\n",
    "        self.dropout    = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(clip_model.config.projection_dim, num_classes)\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        feats = []\n",
    "        if self.use_text:\n",
    "            text_feats = self.clip_model.get_text_features(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs.get(\"attention_mask\", None)\n",
    "            )\n",
    "            feats.append(text_feats)\n",
    "        if self.use_image:\n",
    "            img_feats = self.clip_model.get_image_features(pixel_values=inputs[\"pixel_values\"])\n",
    "            feats.append(img_feats)\n",
    "\n",
    "        combined = (feats[0] + feats[1]) / 2 if len(feats) == 2 else feats[0]\n",
    "        combined = torch.nn.functional.normalize(combined, p=2, dim=-1)\n",
    "        out      = self.dropout(combined)\n",
    "        logits   = self.classifier(out)\n",
    "        return logits, None\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        processor,\n",
    "        text_column=None,\n",
    "        img_dir=None,\n",
    "        use_text=True,\n",
    "        use_image=True,\n",
    "        true_label=None,\n",
    "        prompt=None,\n",
    "    ):\n",
    "        self.df = dataframe\n",
    "        self.processor = processor\n",
    "        self.text_column = text_column\n",
    "        self.img_dir = img_dir\n",
    "        self.use_text = use_text\n",
    "        self.use_image = use_image\n",
    "        self.true_label = true_label\n",
    "        self.prompt = prompt\n",
    "        self.max_length = processor.tokenizer.model_max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = None\n",
    "        if self.use_text:\n",
    "            if isinstance(self.text_column, list):\n",
    "                text = \" \".join(\n",
    "                    str(row[col]).strip()\n",
    "                    for col in self.text_column\n",
    "                    if col in row and pd.notna(row[col])\n",
    "                )\n",
    "            else:\n",
    "                text = str(row[self.text_column]).strip()\n",
    "            if self.prompt:\n",
    "                text = f\"{self.prompt} {text}\"\n",
    "\n",
    "        image = None\n",
    "        if self.use_image and self.img_dir:\n",
    "            img_id = row.get(\"image_id\", row.name)\n",
    "            img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            else:\n",
    "                print(f\"Image not found, using blank image for {img_id}\")\n",
    "                image = Image.new(\"RGB\", (224, 224), color=\"white\")\n",
    "\n",
    "        proc_kwargs = {\n",
    "            \"return_tensors\": \"pt\",\n",
    "            \"padding\": \"max_length\",\n",
    "            \"truncation\": True,\n",
    "            \"max_length\": self.max_length,\n",
    "        }\n",
    "        if self.use_text:\n",
    "            proc_kwargs[\"text\"] = text\n",
    "        if self.use_image:\n",
    "            proc_kwargs[\"images\"] = image\n",
    "\n",
    "        inputs = self.processor(**proc_kwargs)\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "\n",
    "        if self.true_label:\n",
    "            label = int(row[self.true_label])\n",
    "            if self.df[self.true_label].min() == 1:\n",
    "                label -= 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        return inputs, label\n",
    "\n",
    "\n",
    "# ==== PATCH: finetune_CLIP (start) ===========================================\n",
    "def finetune_CLIP(\n",
    "    mode=\"both\",\n",
    "    text_path=None,\n",
    "    text_column=None,\n",
    "    img_dir=None,\n",
    "    true_label=None,\n",
    "    prompt=None,\n",
    "    model_name=\"best_clip_model.pth\",\n",
    "    num_epochs=20,\n",
    "    batch_size=8,\n",
    "    learning_rate=1e-5\n",
    "):\n",
    "    \"\"\"\n",
    "    Fine-tune CLIP on a text, image, or multimodal dataset.\n",
    "\n",
    "    Internally remaps labels to 0..N-1 for CrossEntropyLoss.\n",
    "    Saves a mapping back to original labels in the checkpoint so predictions can be returned in original space.\n",
    "    \"\"\"\n",
    "\n",
    "    if mode not in [\"text\", \"image\", \"both\"]:\n",
    "        raise ValueError(\"mode must be one of 'text', 'image', or 'both'\")\n",
    "\n",
    "    use_text  = mode in [\"text\", \"both\"]\n",
    "    use_image = mode in [\"image\", \"both\"]\n",
    "\n",
    "    if use_text and not text_path:\n",
    "        raise ValueError(\"text_path cannot be empty\")\n",
    "    if use_image and not img_dir:\n",
    "        raise ValueError(\"img_dir cannot be empty\")\n",
    "\n",
    "    # --- Load dataset ---\n",
    "    if text_path.endswith(\".csv\") or text_path.endswith(\".txt\"):\n",
    "        df = pd.read_csv(text_path)\n",
    "    elif text_path.endswith(\".jsonl\"):\n",
    "        df = pd.read_json(text_path, lines=True)\n",
    "    elif text_path.endswith((\".xlsx\", \".xls\")):\n",
    "        df = pd.read_excel(text_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    print(f\"ðŸ“‚ Loaded {len(df)} records from {os.path.basename(text_path)}\")\n",
    "\n",
    "    if true_label not in df.columns:\n",
    "        raise ValueError(f\"Label column '{true_label}' not found in dataset\")\n",
    "\n",
    "    # --- Detect unique labels in original space, then remap to 0..N-1 ---\n",
    "    unique_labels = sorted(df[true_label].dropna().unique())\n",
    "    num_classes   = len(unique_labels)\n",
    "    original_to_new = {int(orig): int(idx) for idx, orig in enumerate(unique_labels)}\n",
    "    new_to_original = {int(idx): int(orig) for orig, idx in original_to_new.items()}\n",
    "\n",
    "    # Remap in place for training\n",
    "    df[true_label] = df[true_label].map(original_to_new)\n",
    "\n",
    "    print(f\"ðŸ” Detected {num_classes} classes: {unique_labels}\")\n",
    "    print(f\"ðŸ” Remapped labels for training -> 0-based indices: {original_to_new}\")\n",
    "\n",
    "    # --- Train/validation split ---\n",
    "    if len(df) < 5:\n",
    "        train_df, val_df = df, df\n",
    "        print(\"âš ï¸ Dataset too small for validation split - using full dataset for training and validation.\")\n",
    "    else:\n",
    "        val_size = max(1, int(len(df) * 0.2))\n",
    "        train_df = df.iloc[:-val_size].reset_index(drop=True)\n",
    "        val_df   = df.iloc[-val_size:].reset_index(drop=True)\n",
    "\n",
    "    # --- Device selection ---\n",
    "    training_device = device\n",
    "    if device.type == \"mps\":\n",
    "        training_device = torch.device(\"cpu\")\n",
    "        print(\"âš ï¸ MPS detected - using CPU to avoid tensor layout issues.\")\n",
    "    print(f\"ðŸ’» Using device: {training_device}\")\n",
    "\n",
    "    print(\"ðŸ§  Training setup:\")\n",
    "    print(f\"   â€¢ Mode: {mode}\")\n",
    "    print(f\"   â€¢ Text columns: {text_column}\")\n",
    "    print(f\"   â€¢ Label column: {true_label} (remapped to 0..{num_classes-1})\")\n",
    "    print(f\"   â€¢ Number of classes: {num_classes}\")\n",
    "    print(f\"   â€¢ Batch size: {batch_size}, Epochs: {num_epochs}, LR: {learning_rate}\")\n",
    "    if prompt:\n",
    "        print(f\"   â€¢ Prompt: {prompt}\")\n",
    "\n",
    "    # --- Model & processor ---\n",
    "    clip_model = CLIPModel.from_pretrained(base_model)\n",
    "    processor  = CLIPProcessor.from_pretrained(base_model)\n",
    "\n",
    "    train_dataset = NewsDataset(\n",
    "        train_df, processor, text_column=text_column, img_dir=img_dir,\n",
    "        use_text=use_text, use_image=use_image, true_label=true_label, prompt=prompt\n",
    "    )\n",
    "    val_dataset = NewsDataset(\n",
    "        val_df, processor, text_column=text_column, img_dir=img_dir,\n",
    "        use_text=use_text, use_image=use_image, true_label=true_label, prompt=prompt\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # --- Model, optimizer, loss ---\n",
    "    model = CLIPClassifier(clip_model, num_classes, use_text, use_image).to(training_device)\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # --- Training loop ---\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for _, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(training_device)\n",
    "            labels = labels.to(training_device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(**inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc  = 100.0 * correct / max(1, total)\n",
    "        train_loss = total_loss / max(1, len(train_loader))\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_correct, val_total, val_loss_accum = 0, 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(training_device)\n",
    "                labels = labels.to(training_device)\n",
    "\n",
    "                logits, _ = model(**inputs)\n",
    "                vloss = criterion(logits, labels)\n",
    "                val_loss_accum += float(vloss.item())\n",
    "                _, predicted = logits.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc  = 100.0 * val_correct / max(1, val_total)\n",
    "        val_loss = val_loss_accum / max(1, len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={train_loss:.4f} Acc={train_acc:.2f}% | Val Loss={val_loss:.4f} Acc={val_acc:.2f}%\")\n",
    "\n",
    "        # --- Save best model with label mapping back to original labels ---\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"best_accuracy\": best_accuracy,\n",
    "                \"num_classes\": num_classes,\n",
    "                \"label_mapping\": new_to_original  # key: 0..N-1 -> original label\n",
    "            }, model_name)\n",
    "            print(f\"âœ… Model saved - new best validation accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    print(f\"ðŸŽ¯ Fine-tuning complete - best validation accuracy: {best_accuracy:.2f}%\")\n",
    "    return best_accuracy\n",
    "# ==== PATCH: finetune_CLIP (end) =============================================\n",
    "\n",
    "\n",
    "# ==== PATCH: classification_CLIP_finetuned (start) ===========================\n",
    "def classification_CLIP_finetuned(\n",
    "    mode=None,\n",
    "    text_path=None,\n",
    "    text_column=[\"headline\"],\n",
    "    img_dir=None,\n",
    "    prompt=None,\n",
    "    model_name=\"best_clip_model.pth\",\n",
    "    batch_size=8,\n",
    "    num_classes=None,   # auto-detected if None\n",
    "    predict_column=\"label\",\n",
    "    true_label=None\n",
    "):\n",
    "    if mode not in [\"text\", \"image\", \"both\"]:\n",
    "        raise ValueError(\"mode must be one of 'text', 'image', or 'both'\")\n",
    "\n",
    "    # --- Load input data ---\n",
    "    if text_path.endswith(\".csv\") or text_path.endswith(\".txt\"):\n",
    "        df = pd.read_csv(text_path)\n",
    "    elif text_path.endswith(\".jsonl\"):\n",
    "        df = pd.read_json(text_path, lines=True)\n",
    "    elif text_path.endswith((\".xlsx\", \".xls\")):\n",
    "        df = pd.read_excel(text_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    print(f\"ðŸ“„ Loaded {len(df)} samples for prediction\")\n",
    "\n",
    "    _device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    processor = CLIPProcessor.from_pretrained(base_model)\n",
    "\n",
    "    # --- Load checkpoint safely ---\n",
    "    if not os.path.exists(model_name):\n",
    "        raise ValueError(f\"Model weights file does not exist: {model_name}\")\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(model_name, map_location=_device, weights_only=True)\n",
    "    except Exception:\n",
    "        print(\"âš ï¸ Safe load failed - retrying with weights_only=False ...\")\n",
    "        checkpoint = torch.load(model_name, map_location=_device, weights_only=False)\n",
    "\n",
    "    # --- Mapping back to original labels if present ---\n",
    "    mapping_back = checkpoint.get(\"label_mapping\", None)\n",
    "    if mapping_back is not None:\n",
    "        # convert possible tensor keys to int\n",
    "        mapping_back = {int(k): int(v) for k, v in mapping_back.items()}\n",
    "\n",
    "    # --- Auto-detect num_classes from checkpoint or mapping ---\n",
    "    if num_classes is None:\n",
    "        if \"num_classes\" in checkpoint and isinstance(checkpoint[\"num_classes\"], int):\n",
    "            num_classes = checkpoint[\"num_classes\"]\n",
    "        elif \"model_state_dict\" in checkpoint and \"classifier.weight\" in checkpoint[\"model_state_dict\"]:\n",
    "            num_classes = checkpoint[\"model_state_dict\"][\"classifier.weight\"].shape[0]\n",
    "        elif mapping_back is not None:\n",
    "            num_classes = len(mapping_back)\n",
    "        else:\n",
    "            num_classes = 2  # fallback\n",
    "        print(f\"ðŸ” Detected num_classes={num_classes} from checkpoint\")\n",
    "\n",
    "    # --- Build model skeleton ---\n",
    "    model = CLIPClassifier(\n",
    "        CLIPModel.from_pretrained(base_model),\n",
    "        num_classes,\n",
    "        use_text=(mode in [\"text\", \"both\"]),\n",
    "        use_image=(mode in [\"image\", \"both\"]),\n",
    "    ).to(_device)\n",
    "\n",
    "    # --- Load weights with head-shape safety ---\n",
    "    state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "    head_mismatch = False\n",
    "\n",
    "    if \"classifier.weight\" in state_dict:\n",
    "        ckpt_head_dim = state_dict[\"classifier.weight\"].shape[0]\n",
    "        if ckpt_head_dim != num_classes:\n",
    "            head_mismatch = True\n",
    "            print(f\"âš ï¸ Head mismatch: checkpoint={ckpt_head_dim}, model={num_classes}. Re-initializing classifier head.\")\n",
    "            state_dict.pop(\"classifier.weight\", None)\n",
    "            state_dict.pop(\"classifier.bias\", None)\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    if missing:\n",
    "        print(f\"âš™ï¸ Missing keys (ok if head was reset): {missing}\")\n",
    "    if unexpected:\n",
    "        print(f\"âš™ï¸ Unexpected keys: {unexpected}\")\n",
    "    if head_mismatch:\n",
    "        print(\"âœ… Classifier head reset successfully.\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # --- Dataset and DataLoader ---\n",
    "    dataset = NewsDataset(\n",
    "        df,\n",
    "        processor,\n",
    "        text_column=text_column,\n",
    "        img_dir=img_dir,\n",
    "        use_text=(mode in [\"text\", \"both\"]),\n",
    "        use_image=(mode in [\"image\", \"both\"]),\n",
    "        true_label=true_label,\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # --- Predict ---\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, _) in enumerate(tqdm(dataloader, desc=\"Predicting\")):\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(_device)\n",
    "            logits, _ = model(**inputs)\n",
    "            _, predicted = logits.max(1)\n",
    "\n",
    "            if mapping_back:\n",
    "                predictions.extend([mapping_back[int(p.cpu().item())] for p in predicted])\n",
    "            else:\n",
    "                # fallback - assume 1-based desired output\n",
    "                predictions.extend((predicted + 1).cpu().numpy())\n",
    "\n",
    "    df[predict_column] = predictions\n",
    "    print(f\"âœ… Prediction complete - {len(df)} rows labeled with original class IDs.\")\n",
    "    return df\n",
    "# ==== PATCH: classification_CLIP_finetuned (end) =============================\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Shared utilities\n",
    "# =========================\n",
    "def price_estimation(\n",
    "    response,\n",
    "    num_rows: int,\n",
    "    input_cost_per_million: float,\n",
    "    output_cost_per_million: float,\n",
    "    num_votes: int = 1) -> float:\n",
    "    usage = getattr(response, \"usage\", None)\n",
    "    if usage is None:\n",
    "        usage = response.get(\"usage\", {})\n",
    "\n",
    "    if isinstance(usage, dict):\n",
    "        input_tokens = usage.get(\"prompt_tokens\", usage.get(\"input_tokens\", 0))\n",
    "        output_tokens = usage.get(\"completion_tokens\", usage.get(\"output_tokens\", 0))\n",
    "    else:\n",
    "        input_tokens = getattr(usage, \"prompt_tokens\", getattr(usage, \"input_tokens\", 0))\n",
    "        output_tokens = getattr(usage, \"completion_tokens\", getattr(usage, \"output_tokens\", 0))\n",
    "\n",
    "    in_price  = input_cost_per_million / 1_000_000\n",
    "    out_price = output_cost_per_million / 1_000_000\n",
    "\n",
    "    cost_per_call = input_tokens * in_price + output_tokens * out_price\n",
    "    total_calls   = num_rows * num_votes\n",
    "    total         = cost_per_call * total_calls\n",
    "    low, high     = total * 0.90, total * 1.10\n",
    "\n",
    "    print(f\"\\nðŸ§® Estimated Cost for {total_calls:,} calls ({num_rows:,} rows Ã— {num_votes} votes)\")\n",
    "    print(f\"â€¢ Avg prompt tokens/call:     {input_tokens}\")\n",
    "    print(f\"â€¢ Avg completion tokens/call: {output_tokens}\")\n",
    "    print(f\"â€¢ Pricing ($/1M tokens): prompt=${input_cost_per_million}, completion=${output_cost_per_million}\")\n",
    "    print(f\"ðŸ’° Total: ${total:.4f}    (Â±10% â†’ ${low:.4f}â€“${high:.4f})\\n\")\n",
    "    return total\n",
    "\n",
    "def image_file_to_data_url(path: str) -> str:\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        b64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "        return f\"data:image/jpeg;base64,{b64}\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[image_data_url] {path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# =========================\n",
    "# GPT classification - data classes & cache\n",
    "# =========================\n",
    "@dataclass\n",
    "class ClassificationQuestion:\n",
    "    prompt: str\n",
    "    model_name: str\n",
    "    valid_values: list[str]\n",
    "    reasoning_effort: str | None\n",
    "    column_4_labeling: str            # \"text_class\" | \"image_class\" | \"final_class\"\n",
    "    text: str                         # text snippet OR data URL OR multimodal combo\n",
    "    label_num: int = 1\n",
    "    max_verify_retry: int = 2\n",
    "\n",
    "    def get_key(self) -> str:\n",
    "        # Normalize text & prompt to improve cache hit chance\n",
    "        norm_prompt = (self.prompt or \"\").strip().lower()\n",
    "        norm_text = (self.text or \"\").strip().lower()\n",
    "    \n",
    "        parts = [\n",
    "            norm_prompt,\n",
    "            self.model_name,\n",
    "            \",\".join(sorted(self.valid_values)),  # sort to normalize order\n",
    "            str(self.reasoning_effort),\n",
    "            self.column_4_labeling,\n",
    "            norm_text,\n",
    "            str(self.label_num),\n",
    "            str(self.max_verify_retry),\n",
    "        ]\n",
    "        return hashlib.md5(\"|\".join(parts).encode()).hexdigest()\n",
    "\n",
    "@dataclass\n",
    "class ClassificationTask:\n",
    "    column: str\n",
    "    prompt: str\n",
    "    model_name: str\n",
    "    valid_values: list[str]\n",
    "    reasoning_effort: str | None\n",
    "    column_4_labeling: str\n",
    "    label_num: int = 1\n",
    "    once_verify_num: int = 1\n",
    "    max_verify_retry: int = 5\n",
    "\n",
    "    def create_question(self, content: str) -> ClassificationQuestion:\n",
    "        return ClassificationQuestion(\n",
    "            prompt=self.prompt,\n",
    "            model_name=self.model_name,\n",
    "            valid_values=self.valid_values,\n",
    "            reasoning_effort=self.reasoning_effort,\n",
    "            column_4_labeling=self.column_4_labeling,\n",
    "            text=content,\n",
    "            label_num=self.label_num,\n",
    "            max_verify_retry=self.max_verify_retry,\n",
    "        )\n",
    "\n",
    "class DBCache:\n",
    "    def __init__(self):\n",
    "        self.db = sqlitedict.SqliteDict(\"db.sqlite\", autocommit=True)\n",
    "\n",
    "    def add(self, q: ClassificationQuestion, res):\n",
    "        self.db[q.get_key()] = res\n",
    "\n",
    "    def get(self, q: ClassificationQuestion):\n",
    "        return self.db.get(q.get_key())\n",
    "\n",
    "class MaxRetryException(Exception):\n",
    "    pass\n",
    "\n",
    "# =========================\n",
    "# >>> GPTClassifier (TEMPERATURE SUPPORT ADDED FOR GPT-4) <<<\n",
    "# =========================\n",
    "class GPTClassifier:\n",
    "    def __init__(self, client: OpenAI):\n",
    "        self.client = client\n",
    "        self.cache  = DBCache()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_output(candidate, valid_values: list[str], num_themes: int):\n",
    "        \"\"\"\n",
    "        Normalize and validate a single candidate output.\n",
    "\n",
    "        Returns:\n",
    "            list[int] of length num_themes if valid, else None.\n",
    "        \"\"\"\n",
    "        if candidate is None:\n",
    "            return None\n",
    "\n",
    "        # Normalize candidate to a list\n",
    "        if isinstance(candidate, (str, int)):\n",
    "            candidate = [candidate]\n",
    "\n",
    "        if not isinstance(candidate, (list, tuple)):\n",
    "            return None\n",
    "\n",
    "        # Convert values to strings, strip, and check membership\n",
    "        norm_strs = []\n",
    "        for v in candidate:\n",
    "            s = str(v).strip()\n",
    "            # accept bare integers like 5 as \"5\"\n",
    "            if s.isdigit() and s in valid_values:\n",
    "                norm_strs.append(s)\n",
    "            else:\n",
    "                # if it looks like \"05\" or non-digit tokens, reject\n",
    "                return None\n",
    "\n",
    "        # Length must match exactly\n",
    "        if len(norm_strs) != int(num_themes):\n",
    "            return None\n",
    "\n",
    "        # All values must be in valid_values\n",
    "        if any(s not in valid_values for s in norm_strs):\n",
    "            return None\n",
    "\n",
    "        # Convert to ints for downstream convenience\n",
    "        return [int(s) for s in norm_strs]\n",
    "\n",
    "    # -- Helpers: Responses-API wrapping --\n",
    "    @staticmethod\n",
    "    def _to_responses_input(messages):\n",
    "        converted = []\n",
    "        for m in messages:\n",
    "            role = m.get(\"role\", \"user\")\n",
    "            content = m.get(\"content\", \"\")\n",
    "            items = []\n",
    "            if isinstance(content, str):\n",
    "                items.append({\"type\": \"input_text\", \"text\": content})\n",
    "            elif isinstance(content, list):\n",
    "                for it in content:\n",
    "                    t = it.get(\"type\", \"text\")\n",
    "                    if t in (\"text\", \"input_text\"):\n",
    "                        items.append({\"type\": \"input_text\", \"text\": it.get(\"text\", \"\")})\n",
    "                    elif t in (\"image_url\", \"input_image\"):\n",
    "                        v = it.get(\"image_url\")\n",
    "                        url = v.get(\"url\") if isinstance(v, dict) else v\n",
    "                        items.append({\"type\": \"input_image\", \"image_url\": str(url)})\n",
    "                    else:\n",
    "                        items.append({\"type\": \"input_text\", \"text\": str(it)})\n",
    "            else:\n",
    "                items.append({\"type\": \"input_text\", \"text\": str(content)})\n",
    "            converted.append({\"role\": role, \"content\": items})\n",
    "        return converted\n",
    "\n",
    "    @staticmethod\n",
    "    def _wrap_responses_output(resp):\n",
    "        try:\n",
    "            text = resp.output_text\n",
    "        except Exception:\n",
    "            try:\n",
    "                text = \"\".join([o.get(\"content\", \"\") for o in resp.output[0].get(\"content\", [])])\n",
    "            except Exception:\n",
    "                text = \"\"\n",
    "        class _DummyChoice:\n",
    "            def __init__(self, txt): self.message = type(\"m\", (), {\"content\": txt})\n",
    "        return type(\"R\", (), {\"choices\": [_DummyChoice(text)]})\n",
    "\n",
    "    # --- Core API call (modified to accept temperature for GPT-4) ---\n",
    "    def fetch(self, messages, model, reasoning_effort, n, temperature: float | None = None):\n",
    "        \"\"\"\n",
    "        Resilient call:\n",
    "          - Uses Responses API for gpt-5* models (accepts reasoning.effort)\n",
    "          - Uses Chat Completions for other models\n",
    "          - GPT-4 family: now accepts 'temperature'\n",
    "        \"\"\"\n",
    "        candidates = [model] + _MODEL_FALLBACKS.get(model, [])\n",
    "        last_err = None\n",
    "\n",
    "        for pass_id in (0, 1):\n",
    "            for cand in candidates:\n",
    "                try:\n",
    "                    if cand.startswith(\"gpt-5\"):\n",
    "                        inputs = self._to_responses_input(messages)\n",
    "                        kwargs = dict(\n",
    "                            model=cand,\n",
    "                            input=inputs,\n",
    "                            reasoning={\"effort\": (reasoning_effort or \"minimal\")},\n",
    "                        )\n",
    "                        if pass_id == 1:\n",
    "                            kwargs.pop(\"reasoning\", None)\n",
    "                        resp = self.client.responses.create(**kwargs)\n",
    "                        return self._wrap_responses_output(resp)\n",
    "\n",
    "                    # GPT-4 family (and others) -> Chat Completions; add temperature if provided\n",
    "                    kwargs = dict(model=cand, messages=messages, n=n)\n",
    "                    if temperature is not None:\n",
    "                        kwargs[\"temperature\"] = float(temperature)\n",
    "                    if pass_id == 1:\n",
    "                        kwargs.update(_SAFE_DEFAULTS)\n",
    "                    return self.client.chat.completions.create(**kwargs)\n",
    "\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "                    if _is_model_or_param_error(e):\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "        logger.error(\"OpenAI call failed across requested model and fallbacks. Showing guidance.\")\n",
    "        logger.error(FRIENDLY_MODEL_MESSAGE)\n",
    "        if last_err:\n",
    "            logger.exception(last_err)\n",
    "        raise MaxRetryException(\"Failed after retries and fallbacks\")\n",
    "\n",
    "    # -- SINGLE call â†’ parsed labels (now forwards temperature) --\n",
    "    def classify(self, q: ClassificationQuestion, n: int, temperature: float | None = None):\n",
    "        \"\"\"\n",
    "        Run a single GPT call that may return up to n choices.\n",
    "        Returns:\n",
    "            parsed: list of parsed candidates (each candidate is list or scalar-like)\n",
    "            raw_texts: list of raw text replies for logging\n",
    "        \"\"\"\n",
    "        if q.column_4_labeling == \"text_class\":\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": str(q.prompt)},\n",
    "                {\"type\": \"text\", \"text\": str(q.text)},\n",
    "            ]\n",
    "        elif q.column_4_labeling == \"image_class\":\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": str(q.prompt)},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": q.text}},\n",
    "            ]\n",
    "        else:\n",
    "            if \"data:image\" in q.text:\n",
    "                txt, img = q.text.split(\"data:image\", 1)\n",
    "                img = \"data:image\" + img\n",
    "            else:\n",
    "                txt, img = q.text, \"\"\n",
    "            img = re.sub(r\"\\s+\", \"\", img)\n",
    "            content = [{\"type\": \"text\", \"text\": f\"{str(q.prompt)}\\nText: {str(txt).strip()}\"}]\n",
    "            if img.startswith(\"data:image\"):\n",
    "                content.append({\"type\": \"image_url\", \"image_url\": {\"url\": img}})\n",
    "\n",
    "        resp = self.fetch(\n",
    "            [{\"role\": \"user\", \"content\": content}],\n",
    "            q.model_name,\n",
    "            q.reasoning_effort or \"minimal\",\n",
    "            n,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        parsed = []\n",
    "        raw_texts = []\n",
    "        for choice in resp.choices:\n",
    "            raw = choice.message.content.strip() if getattr(choice, \"message\", None) else \"\"\n",
    "            raw_texts.append(raw)\n",
    "\n",
    "            # Try JSON-like list first\n",
    "            if raw.startswith(\"[\") and raw.endswith(\"]\"):\n",
    "                try:\n",
    "                    arr = json.loads(raw)\n",
    "                    parsed.append(arr)\n",
    "                    continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Try simple digits separated by commas or spaces\n",
    "            flat = re.findall(r\"\\b\\d+\\b\", raw)\n",
    "            if flat:\n",
    "                parsed.append([int(x) if x.isdigit() else x for x in flat])\n",
    "                continue\n",
    "\n",
    "            # As a last resort, keep raw as-is (will fail validation)\n",
    "            parsed.append(raw)\n",
    "\n",
    "        if not parsed:\n",
    "            logger.error(f\"No valid labels parsed. Raw reply: {resp.choices}\")\n",
    "        return parsed, raw_texts\n",
    "\n",
    "\n",
    "    # -- majority vote / cache (now forwards temperature) --\n",
    "    def multi_verify(\n",
    "        self,\n",
    "        q: ClassificationQuestion,\n",
    "        n,\n",
    "        retry=1,\n",
    "        freq=None,\n",
    "        temperature: float | None = None,\n",
    "        counters: dict | None = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Robust per-row classification:\n",
    "          - Checks SQLite cache first\n",
    "          - Validates each attempt immediately\n",
    "          - Retries up to q.max_verify_retry times\n",
    "          - Caches only valid outputs\n",
    "          - Returns [99,...] on final failure (not cached)\n",
    "          - IMPORTANT: counters['redo'] counts TRUE retries only\n",
    "                       (i.e., second attempt and beyond), never the first try.\n",
    "        \"\"\"\n",
    "        # 1) Cache check\n",
    "        cached = self.cache.get(q)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "    \n",
    "        max_retry = max(1, int(q.max_verify_retry))\n",
    "        attempt = 1\n",
    "        total_retries_this_row = 0\n",
    "        last_error = None\n",
    "        row_tag = f\"{getattr(q, 'row_idx', '?')}\"\n",
    "    \n",
    "        while attempt <= max_retry:\n",
    "            try:\n",
    "                parsed_list, raw_list = self.classify(q, n, temperature=temperature)\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                # Only a retry if we're going to try again\n",
    "                if attempt < max_retry:\n",
    "                    total_retries_this_row += 1\n",
    "                    if counters is not None:\n",
    "                        counters[\"redo\"] += 1\n",
    "                    print(f\"Row {row_tag} RETRY #{total_retries_this_row} â€” API error: {type(e).__name__}: {e}\")\n",
    "                    attempt += 1\n",
    "                    continue\n",
    "                # No more retries left\n",
    "                break\n",
    "\n",
    "            # Validate candidates\n",
    "            counts = {}\n",
    "            first_parsed_preview = None\n",
    "            first_raw_preview = None\n",
    "    \n",
    "            for idx, cand in enumerate(parsed_list or []):\n",
    "                if first_parsed_preview is None:\n",
    "                    first_parsed_preview = cand\n",
    "                if first_raw_preview is None:\n",
    "                    first_raw_preview = (raw_list[idx] if raw_list and idx < len(raw_list) else \"\")\n",
    "    \n",
    "                valid = self._validate_output(cand, q.valid_values, q.label_num)\n",
    "                if valid is not None:\n",
    "                    t = tuple(valid)\n",
    "                    counts[t] = counts.get(t, 0) + 1\n",
    "    \n",
    "            if counts:\n",
    "                # Success: majority vote\n",
    "                best_tuple = sorted(counts.items(), key=lambda kv: kv[1], reverse=True)[0][0]\n",
    "                best = list(best_tuple)\n",
    "                self.cache.add(q, best)\n",
    "                return best\n",
    "    \n",
    "            # Invalid output\n",
    "            parsed_preview_str = str(first_parsed_preview)\n",
    "            raw_preview_str = (first_raw_preview or \"\").replace(\"\\n\", \" \")[:200]\n",
    "    \n",
    "            if attempt < max_retry:\n",
    "                # We WILL retry â†’ count it\n",
    "                total_retries_this_row += 1\n",
    "                if counters is not None:\n",
    "                    counters[\"redo\"] += 1\n",
    "                print(\n",
    "                    f\"Row {row_tag} RETRY #{total_retries_this_row} â€” invalid output: \"\n",
    "                    f\"{parsed_preview_str} (expected {q.label_num} labels). Raw: \\\"{raw_preview_str}\\\"\"\n",
    "                )\n",
    "                attempt += 1\n",
    "                continue\n",
    "    \n",
    "            # No retries left, fall through to failure\n",
    "            break\n",
    "    \n",
    "        # Final failure\n",
    "        fail_reason = (\n",
    "            f\"{type(last_error).__name__}: {last_error}\"\n",
    "            if last_error is not None else\n",
    "            \"invalid format repeatedly.\"\n",
    "        )\n",
    "        print(f\"Row {row_tag} FAILED after {total_retries_this_row} retries. Last reason: {fail_reason}\")\n",
    "        return [99] * int(q.label_num)\n",
    "\n",
    "    \n",
    "    def classify_df(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        task: ClassificationTask,\n",
    "        return_sample_response=False,\n",
    "        temperature: float | None = None,\n",
    "        pbar=None,\n",
    "        counters=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Row-by-row processing:\n",
    "          - Counts cache hits in counters['cache']\n",
    "          - Counts TRUE retries in counters['redo'] (handled inside multi_verify)\n",
    "          - Progress bar postfix shows: âš¡ cache:<n> | retry:<m>\n",
    "        \"\"\"\n",
    "        out, sample = [], None\n",
    "    \n",
    "        for idx, rec in enumerate(df.to_dict(\"records\")):\n",
    "            q = task.create_question(rec.get(task.column, \"\"))\n",
    "            setattr(q, \"row_idx\", idx)\n",
    "    \n",
    "            # Cache check BEFORE classification (does not affect redo)\n",
    "            if self.cache.get(q) is not None:\n",
    "                if counters is not None:\n",
    "                    counters[\"cache\"] += 1\n",
    "    \n",
    "            if return_sample_response and sample is None:\n",
    "                sample = self.fetch(\n",
    "                    [{\"role\": \"user\",\n",
    "                      \"content\": [\n",
    "                          {\"type\": \"text\", \"text\": str(q.prompt)},\n",
    "                          {\"type\": \"text\", \"text\": str(q.text)}\n",
    "                      ]}],\n",
    "                    q.model_name,\n",
    "                    q.reasoning_effort or \"minimal\",\n",
    "                    1,\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "    \n",
    "            try:\n",
    "                lbl = self.multi_verify(\n",
    "                    q,\n",
    "                    task.once_verify_num,\n",
    "                    temperature=temperature,\n",
    "                    counters=counters,  # <- redo counted ONLY here, on true retries\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Row {idx} ERROR â€” {type(e).__name__}: {e}\")\n",
    "                lbl = [99] * int(task.label_num)\n",
    "    \n",
    "            rec[task.column_4_labeling] = lbl\n",
    "            out.append(rec)\n",
    "    \n",
    "            # Progress bar update\n",
    "            if pbar is not None:\n",
    "                postfix = (\n",
    "                    f\"âš¡ cache:{counters['cache']}\"\n",
    "                    if counters else \"\"\n",
    "                )\n",
    "                pbar.set_postfix_str(postfix, refresh=True)\n",
    "                pbar.update(1)\n",
    "    \n",
    "        df_out = pd.DataFrame(out)\n",
    "        return (df_out, sample) if return_sample_response else df_out\n",
    "\n",
    "\n",
    "    # -- DataFrame helper (now forwards temperature) --\n",
    "    def classify_df(self, df: pd.DataFrame, task: ClassificationTask,\n",
    "                    return_sample_response=False, temperature: float | None = None,\n",
    "                    pbar=None, counters=None):\n",
    "        \"\"\"\n",
    "        Processes dataframe row by row:\n",
    "        âœ… Tracks cache hits & re-runs\n",
    "        âœ… Shows âš¡ cache inline on progress bar\n",
    "        âœ… Updates tqdm postfix dynamically\n",
    "        \"\"\"\n",
    "        out, sample = [], None\n",
    "    \n",
    "        for idx, rec in enumerate(df.to_dict(\"records\")):\n",
    "            q = task.create_question(rec.get(task.column, \"\"))\n",
    "            try:\n",
    "                setattr(q, \"row_idx\", idx)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            # Check cache BEFORE calling multi_verify\n",
    "            cache_hit = self.cache.get(q) is not None\n",
    "    \n",
    "            if cache_hit:\n",
    "                if counters:\n",
    "                    counters[\"cache\"] += 1\n",
    "            else:\n",
    "                if counters:\n",
    "                    counters[\"redo\"] += 1\n",
    "\n",
    "    \n",
    "            if return_sample_response and sample is None:\n",
    "                sample = self.fetch(\n",
    "                    [{\"role\": \"user\",\n",
    "                      \"content\": [{\"type\": \"text\", \"text\": str(q.prompt)},\n",
    "                                  {\"type\": \"text\", \"text\": str(q.text)}]}],\n",
    "                    q.model_name,\n",
    "                    q.reasoning_effort or \"minimal\",\n",
    "                    1,\n",
    "                    temperature=temperature,\n",
    "                )\n",
    "    \n",
    "            try:\n",
    "                lbl = self.multi_verify(q, task.once_verify_num, temperature=temperature)\n",
    "            except Exception as e:\n",
    "                # Print clear reason for retry\n",
    "                print(f\"Row {getattr(q, 'row_idx', '?')} RETRY #{attempts+1} â€” error: {str(e)}\")\n",
    "                lbl = [99] * int(q.label_num)\n",
    "\n",
    "            rec[task.column_4_labeling] = lbl\n",
    "            out.append(rec)\n",
    "    \n",
    "            # âœ… tqdm updates\n",
    "            if pbar is not None:\n",
    "                postfix = f\"âš¡ cache: {counters['cache']} \" if counters else \"\"\n",
    "                pbar.set_postfix_str(postfix, refresh=True)\n",
    "                pbar.update(1)\n",
    "    \n",
    "        df_out = pd.DataFrame(out)\n",
    "        return (df_out, sample) if return_sample_response else df_out\n",
    "\n",
    "# =========================\n",
    "# classification_GPT (signature now includes temperature; forwarded)\n",
    "# =========================\n",
    "def classification_GPT(\n",
    "    text_path: str | None = None,\n",
    "    category: list[str] | None = None,\n",
    "    image_dir: str | None = None,\n",
    "    prompt: list[str] | str | None = None,\n",
    "    column_4_labeling: list[str] | None = None,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    api_key: str | None = None,\n",
    "    reasoning_effort: str | None = None,\n",
    "    temperature: float | None = None,     # <-- added\n",
    "    mode: str = \"both\",                   # \"text\" | \"image\" | \"both\"\n",
    "    output_column_name: str = \"label\",\n",
    "    num_themes: int = 1,\n",
    "    num_votes: int = 1,\n",
    "    batch_size: int = 1,\n",
    "    wait_time: float = 1.2\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    print_env_info()\n",
    "\n",
    "    category = [str(c) for c in (category or [])]\n",
    "    valid_efforts = {\"minimal\", \"low\", \"medium\", \"high\"}\n",
    "    if reasoning_effort is None:\n",
    "        reasoning_effort = \"minimal\"\n",
    "    if reasoning_effort not in valid_efforts:\n",
    "        raise ValueError(f\"reasoning_effort must be one of {valid_efforts}, got {reasoning_effort!r}\")\n",
    "    is_reasoning = reasoning_effort != \"minimal\"\n",
    "\n",
    "    # -- load data\n",
    "    if mode == \"image\":\n",
    "        if text_path and text_path.lower().endswith(\".json\"):\n",
    "            df0 = pd.DataFrame(json.load(open(text_path, encoding=\"utf-8\")))\n",
    "            if \"image_dir\" not in df0.columns:\n",
    "                df0[\"image_dir\"] = df0[\"image_id\"].apply(lambda x: os.path.join(image_dir, f\"{x}.jpg\"))\n",
    "        else:\n",
    "            if not image_dir:\n",
    "                raise ValueError(\"image_dir required (mode='image')\")\n",
    "            files = [f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "            df0 = pd.DataFrame({\n",
    "                \"image_id\":  [os.path.splitext(f)[0] for f in files],\n",
    "                \"image_dir\": [os.path.join(image_dir, f) for f in files],\n",
    "            })\n",
    "    else:\n",
    "        if not text_path:\n",
    "            raise ValueError(\"text_path required\")\n",
    "        ext = os.path.splitext(text_path)[1].lower()\n",
    "        if ext == \".json\":\n",
    "            df0 = pd.DataFrame(json.load(open(text_path, encoding=\"utf-8\")))\n",
    "        elif ext == \".csv\":\n",
    "            df0 = pd.read_csv(text_path)\n",
    "        elif ext in (\".xls\", \".xlsx\"):\n",
    "            df0 = pd.read_excel(text_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "        if mode == \"both\" and \"image_dir\" not in df0.columns:\n",
    "            if not image_dir:\n",
    "                raise ValueError(\"image_dir required for mode='both'\")\n",
    "            df0[\"image_dir\"] = df0[\"image_id\"].apply(lambda x: os.path.join(image_dir, f\"{x}.jpg\"))\n",
    "\n",
    "    df = df0.copy()\n",
    "    df[\"text_content\"] = (df.apply(\n",
    "        lambda r: \" \".join(\n",
    "            str(r[c]) for c in (column_4_labeling or [])\n",
    "            if c in r and pd.notna(r[c])\n",
    "        ), axis=1) if column_4_labeling else \"\")\n",
    "\n",
    "    if mode in (\"image\", \"both\"):\n",
    "        df[\"image_data_url\"] = df[\"image_dir\"].apply(image_file_to_data_url)\n",
    "    else:\n",
    "        df[\"image_data_url\"] = \"\"\n",
    "\n",
    "    if mode == \"both\":\n",
    "        df[\"final_input\"] = df[\"text_content\"] + \"\\n\" + df[\"image_data_url\"]\n",
    "    elif mode == \"image\":\n",
    "        df[\"final_input\"] = df[\"image_data_url\"]\n",
    "    else:\n",
    "        df[\"final_input\"] = df[\"text_content\"]\n",
    "\n",
    "    if isinstance(prompt, str) and prompt.strip():\n",
    "        base_prompt = prompt.strip()\n",
    "    else:\n",
    "        defs = \"; \".join(f\"{c}: {d}\" for c, d in zip(category, prompt)) if prompt else \"\"\n",
    "        base_prompt = (\n",
    "            f\"Themes: {', '.join(category)}. {defs} \"\n",
    "            f\"Return the top {num_themes} theme number(s) \"\n",
    "            \"(or an 8-element JSON array of 0/1). No extra words.\"\n",
    "        )\n",
    "\n",
    "    if mode == \"text\":\n",
    "        tasks = [(\"text_content\",  \"text_class\",  base_prompt)]\n",
    "    elif mode == \"image\":\n",
    "        tasks = [(\"image_data_url\",\"image_class\", base_prompt)]\n",
    "    else:\n",
    "        tasks = [(\"final_input\",   \"final_class\", base_prompt)]\n",
    "\n",
    "    clf   = GPTClassifier(OpenAI(api_key=api_key) if api_key else OpenAI())\n",
    "    first = True\n",
    "\n",
    "\n",
    "    outputs = []\n",
    "    n = len(df)\n",
    "    \n",
    "    # Global counters\n",
    "    counters = {\"cache\": 0, \"redo\": 0}\n",
    "    \n",
    "    pbar = tqdm(\n",
    "        total=n,\n",
    "        desc=f\"[ GPT â€¢ {tasks[0][1]} ]\",\n",
    "        unit=\"row\",\n",
    "        ncols=100,\n",
    "        dynamic_ncols=False,\n",
    "        leave=True,\n",
    "        position=0,\n",
    "        mininterval=0.5,\n",
    "        smoothing=0.1,\n",
    "        bar_format=\"{desc} {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} | ETA {remaining} | {rate_fmt} | {postfix}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    for start in range(0, n, max(1, batch_size)):\n",
    "        end = min(n, start + max(1, batch_size))\n",
    "        sub = df.iloc[start:end].copy()\n",
    "    \n",
    "        for col, lab, pr in tasks:\n",
    "            task = ClassificationTask(\n",
    "                column=col, prompt=pr, model_name=model,\n",
    "                valid_values=category, reasoning_effort=reasoning_effort,\n",
    "                column_4_labeling=lab, label_num=num_themes,\n",
    "                once_verify_num=num_votes, max_verify_retry=5,\n",
    "            )\n",
    "    \n",
    "            # Pass counters + tqdm bar\n",
    "            sub = clf.classify_df(sub, task, temperature=temperature, pbar=pbar, counters=counters)\n",
    "    \n",
    "        outputs.append(sub)\n",
    "        time.sleep(wait_time)\n",
    "    \n",
    "    # Ensure bar completes cleanly\n",
    "    pbar.n = pbar.total\n",
    "    pbar.refresh()\n",
    "    pbar.close()\n",
    "    \n",
    "    print(f\"\\nâœ… Finished classification of {n} rows.\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    df = pd.concat(outputs, ignore_index=True)\n",
    "\n",
    "    df.rename(columns={lab: output_column_name}, inplace=True)\n",
    "\n",
    "    if isinstance(df[output_column_name].iloc[0], list) and len(df[output_column_name].iloc[0]) == num_themes:\n",
    "        raw = output_column_name + \"_raw\"\n",
    "        df[raw] = df[output_column_name]\n",
    "        for i in range(num_themes):\n",
    "            df[f\"{output_column_name}_{i+1}\"] = df[output_column_name].apply(\n",
    "                lambda v, idx=i: int(v[idx]) if isinstance(v, list) else np.nan\n",
    "            )\n",
    "\n",
    "    df[output_column_name] = df[output_column_name].apply(\n",
    "        lambda x: x[0] if isinstance(x, list) and len(x) == 1 else x\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Fine-tune prep & jobs\n",
    "# =========================\n",
    "def generate_GPT_finetune_jsonl(\n",
    "    df: pd.DataFrame,\n",
    "    output_path: str = \"classification_result.jsonl\",\n",
    "    label_col: str | list[str] = \"true_class\",\n",
    "    system_prompt: str | list[str] | None = None,\n",
    "    input_col: str | list[str] = \"text_content\") -> None:\n",
    "\n",
    "    if isinstance(system_prompt, (list, tuple)):\n",
    "        sys_txt = \"\\n\".join(system_prompt).strip()\n",
    "    else:\n",
    "        sys_txt = system_prompt.strip() if isinstance(system_prompt, str) else None\n",
    "\n",
    "    label_cols = list(label_col) if isinstance(label_col, (list, tuple)) else [label_col]\n",
    "    input_cols = list(input_col) if isinstance(input_col, (list, tuple)) else [input_col]\n",
    "\n",
    "    for c in input_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing input column: {c}\")\n",
    "    for c in label_cols:\n",
    "        if c not in df.columns:\n",
    "            logger.warning(f\"Missing label column: {c}; skipping export\")\n",
    "            return\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for _, row in df.iterrows():\n",
    "            parts = [str(row[c]) for c in input_cols if pd.notna(row[c])]\n",
    "            if not parts:\n",
    "                continue\n",
    "            user_text = \" \".join(parts).strip()\n",
    "\n",
    "            raw = [row[c] for c in label_cols]\n",
    "            flat = []\n",
    "            for x in raw:\n",
    "                flat.extend(x if isinstance(x, (list, np.ndarray)) else [x])\n",
    "            clean = []\n",
    "            for v in flat:\n",
    "                if pd.isna(v):\n",
    "                    continue\n",
    "                try:\n",
    "                    clean.append(str(int(v)))\n",
    "                except:\n",
    "                    clean.append(str(v))\n",
    "            if not clean:\n",
    "                continue\n",
    "            label_str = \", \".join(clean)\n",
    "\n",
    "            msgs = []\n",
    "            if sys_txt:\n",
    "                msgs.append({\"role\": \"system\",    \"content\": sys_txt})\n",
    "            msgs.append({\"role\": \"user\",      \"content\": user_text})\n",
    "            msgs.append({\"role\": \"assistant\", \"content\": label_str.strip()})\n",
    "\n",
    "            fout.write(json.dumps({\"messages\": msgs}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def finetune_GPT(\n",
    "    training_file_path: str,\n",
    "    model: str = None,\n",
    "    method_type: str = \"supervised\",\n",
    "    hyperparameters: dict = None,\n",
    "    poll_interval: int = 15,\n",
    "    max_wait_time: int = 60*60,\n",
    "    api_key: str = None) -> str:\n",
    "    client = OpenAI(api_key=api_key) if api_key else OpenAI()\n",
    "\n",
    "    filename = os.path.basename(training_file_path)\n",
    "    with open(training_file_path, 'rb') as f:\n",
    "        upload_resp = client.files.create(file=(filename, f), purpose=\"fine-tune\")\n",
    "    try:\n",
    "        training_file_id = upload_resp.id\n",
    "    except AttributeError:\n",
    "        training_file_id = upload_resp['id']\n",
    "\n",
    "    method = {\"type\": method_type, method_type: {\"hyperparameters\": hyperparameters or {}}}\n",
    "\n",
    "    job_resp = client.fine_tuning.jobs.create(\n",
    "        training_file=training_file_id,\n",
    "        model=model,\n",
    "        method=method\n",
    "    )\n",
    "    try:\n",
    "        job_id = job_resp.id\n",
    "    except AttributeError:\n",
    "        job_id = job_resp['id']\n",
    "    print(\"Started fine-tune job\", job_id)\n",
    "\n",
    "    elapsed = 0\n",
    "    while elapsed < max_wait_time:\n",
    "        status = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        try:\n",
    "            st = status.status\n",
    "        except AttributeError:\n",
    "            st = status['status']\n",
    "        print(f\"[{elapsed}s] status={st}\")\n",
    "\n",
    "        if st == \"succeeded\":\n",
    "            try:\n",
    "                fine_model = status.fine_tuned_model\n",
    "            except AttributeError:\n",
    "                fine_model = status['fine_tuned_model']\n",
    "            print(\"âœ… succeeded:\", fine_model)\n",
    "            return fine_model\n",
    "\n",
    "        if st in (\"failed\", \"canceled\", \"cancelled\"):\n",
    "            try:\n",
    "                error_info = status.error\n",
    "            except AttributeError:\n",
    "                error_info = status.get('error', None)\n",
    "            print(f\"âŒ Job {job_id} ended with {st}. Error info: {error_info}\")\n",
    "            raise RuntimeError(f\"Fine-tune job {job_id} ended with status '{st}'\"\n",
    "                               + (f\": {error_info}\" if error_info else \"\"))\n",
    "\n",
    "        time.sleep(poll_interval)\n",
    "        elapsed += poll_interval\n",
    "\n",
    "    raise TimeoutError(f\"Job {job_id} didnâ€™t finish within {max_wait_time}s\")\n",
    "\n",
    "# =========================\n",
    "# Verification\n",
    "# =========================\n",
    "def auto_verification(\n",
    "    df: pd.DataFrame,\n",
    "    predicted_cols,\n",
    "    true_cols,\n",
    "    category: list = None,\n",
    "    sample_size: int = None) -> dict:\n",
    "\n",
    "    def _extract_scalar(x):\n",
    "        if isinstance(x, (list, tuple)) and len(x) == 1:\n",
    "            x = x[0]\n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def _normalize_series(col: pd.Series) -> pd.Series:\n",
    "        if category and col.dtype == object and not pd.api.types.is_list_like(col.iloc[0]):\n",
    "            mapping = {name: idx + 1 for idx, name in enumerate(category)}\n",
    "            col = col.map(mapping).astype(float)\n",
    "        if col.dtype == object or pd.api.types.is_list_like(col.iloc[0]):\n",
    "            col = col.map(_extract_scalar)\n",
    "        return col\n",
    "\n",
    "    if isinstance(predicted_cols, str):\n",
    "        predicted_cols = [predicted_cols]\n",
    "    if isinstance(true_cols, str):\n",
    "        true_cols = [true_cols]\n",
    "    if len(predicted_cols) != len(true_cols):\n",
    "        raise ValueError(\"The number of predicted columns must match the number of true columns.\")\n",
    "\n",
    "    total_correct, total_count = 0, 0\n",
    "    overall_results = {}\n",
    "\n",
    "    for p, t in zip(predicted_cols, true_cols):\n",
    "        if p not in df or t not in df:\n",
    "            raise KeyError(f\"Column '{p}' or '{t}' not in DataFrame\")\n",
    "\n",
    "        s_pred = _normalize_series(df[p])\n",
    "        s_true = _normalize_series(df[t])\n",
    "\n",
    "        valid = pd.concat([s_pred, s_true], axis=1).dropna()\n",
    "        if len(valid) == 0:\n",
    "            print(f\"No valid data to compare for '{p}' vs '{t}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if sample_size and len(valid) > sample_size:\n",
    "            valid = valid.sample(sample_size, random_state=42)\n",
    "\n",
    "        y_pred, y_true = valid.iloc[:, 0], valid.iloc[:, 1]\n",
    "\n",
    "        results = {\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"precision_macro\": precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            \"recall_macro\": recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            \"f1_macro\": f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            \"precision_micro\": precision_score(y_true, y_pred, average='micro', zero_division=0),\n",
    "            \"recall_micro\": recall_score(y_true, y_pred, average='micro', zero_division=0),\n",
    "            \"f1_micro\": f1_score(y_true, y_pred, average='micro', zero_division=0),\n",
    "            \"report\": classification_report(y_true, y_pred, zero_division=0),\n",
    "            \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "        print(f\"\\n== Verification of '{p}' vs. '{t}' ==\")\n",
    "        print(f\"Accuracy:   {results['accuracy']:.2%}\")\n",
    "        print(f\"Macro F1:   {results['f1_macro']:.2%}\")\n",
    "        print(f\"Micro  F1:  {results['f1_micro']:.2%}\")\n",
    "        print(\"\\nFull classification report:\")\n",
    "        print(results[\"report\"])\n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        print(results[\"confusion_matrix\"])\n",
    "\n",
    "        total_correct += (y_pred == y_true).sum()\n",
    "        total_count   += len(valid)\n",
    "        overall_results[f\"{p} vs {t}\"] = results\n",
    "\n",
    "    overall_accuracy = total_correct / total_count if total_count else 0.0\n",
    "    print(f\"\\n>> Overall accuracy: {overall_accuracy:.2%}\")\n",
    "    overall_results[\"overall_accuracy\"] = overall_accuracy\n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b744a6-13b2-4a7d-908a-d2ada44a2cf1",
   "metadata": {},
   "source": [
    "# Test with CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1b108-35d8-4d76-aecb-7bcffc2acd6c",
   "metadata": {},
   "source": [
    "## 1. Test with N=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710bb43c-eedc-4c23-8b45-f9e30cd5ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import io\n",
    "import pandas as pd\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Settings ---\n",
    "# Define the descriptive prompt for each category\n",
    "prompt_CLIP = [\n",
    "    \"a news article about health, including medical news, public health issues, fitness, mental health, and wellness.\",\n",
    "    \"a news article about science, covering scientific discoveries, research studies, space exploration, and innovations.\",\n",
    "    \"a news article about television, featuring TV shows, series reviews, industry news, and streaming platforms.\",\n",
    "    \"a news article about travel, focusing on tourism, destinations, travel guides, airlines, and vacation trends.\",\n",
    "    \"a news article about movies, including film industry news, reviews, box office reports, and upcoming releases.\",\n",
    "    \"a news article about dance, covering ballet, contemporary styles, street dance, performances, and dance competitions.\",\n",
    "    \"a news article about real estate, highlighting housing market trends, property sales, architecture, and urban planning.\",\n",
    "    \"a news article about the economy, featuring macroeconomics, inflation, stock markets, GDP growth, and financial policies.\",\n",
    "    \"a news article about sports, covering professional sports, competitions, athlete news, and game Demo_results.\",\n",
    "    \"a news article about theater, featuring plays, Broadway shows, live performances, and stage production reviews.\",\n",
    "    \"a news article about opinion pieces, including editorials, analysis, and expert commentaries.\",\n",
    "    \"a news article about music, covering albums, artists, concerts, festivals, and industry trends.\",\n",
    "    \"a news article about books, featuring literature, bestsellers, author interviews, and book reviews.\",\n",
    "    \"a news article about art and design, showcasing fine arts, visual arts, museums, exhibitions, and design trends.\",\n",
    "    \"a news article about style, including fashion trends, beauty, personal style, and cultural aesthetics.\",\n",
    "    \"a news article about media, covering journalism, publishing, digital media, and mass communication.\",\n",
    "    \"a news article about food, featuring restaurants, cooking, recipes, culinary trends, and food culture.\",\n",
    "    \"a news article about well-being, focusing on lifestyle, personal development, mental well-being, and self-care.\",\n",
    "    \"a news article about fashion, covering clothing, designers, fashion weeks, and industry insights.\",\n",
    "    \"a news article about technology, featuring AI, gadgets, software, cybersecurity, and tech innovations.\",\n",
    "    \"a news article about personal finance, including investing, budgeting, and financial planning.\",\n",
    "    \"a news article about education, featuring schools, universities, learning methods, and education policies.\",\n",
    "    \"a news article about automobiles, covering car industry news, electric vehicles, reviews, and trends.\",\n",
    "    \"a news article about global business, featuring international trade, corporations, mergers, and global markets.\"\n",
    "]\n",
    "\n",
    "# Define the list of 24 category labels\n",
    "category = [\n",
    "    \"1\", \"2\", \"3\", \"4\", \"5\", \"6\",\n",
    "    \"7\", \"8\", \"9\", \"10\", \"11\", \"12\",\n",
    "    \"13\", \"14\", \"15\", \"16\", \"17\", \"18\",\n",
    "    \"19\", \"20\", \"21\", \"22\", \"23\", \"24\"\n",
    "]\n",
    "text_cols   = [\"headline\",\"abstract\"]\n",
    "img_dir     = \"Data_train/imgs_all\"\n",
    "n_rounds    = 20\n",
    "n_epochs    = 20\n",
    "batch_size  = 8\n",
    "lr          = 1e-5\n",
    "\n",
    "acc_file = \"Result/accuracy_finetune.csv\"\n",
    "if not os.path.exists(acc_file):\n",
    "    pd.DataFrame(columns=[\"round\",\"accuracy\"]).to_csv(acc_file, index=False)\n",
    "\n",
    "buf = io.StringIO()\n",
    "model_path = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac0174e-3afc-498c-84ff-4ae26d182a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Round 1:\n",
      "============================================================\n",
      "  Predicting on split [1] (0-shot)â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 200)\n",
      "  â±ï¸  Prediction time: 0:00:06\n",
      "\n",
      "============================================================\n",
      "Round 2:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:01:25\n",
      "  Predicting on split [2]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 400)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 3:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:02:38\n",
      "  Predicting on split [3]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 600)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 4:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:03:53\n",
      "  Predicting on split [4]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 800)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 5:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:05:26\n",
      "  Predicting on split [5]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 1000)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 6:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:06:40\n",
      "  Predicting on split [6]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 1200)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 7:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:08:06\n",
      "  Predicting on split [7]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 1400)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 8:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:09:20\n",
      "  Predicting on split [8]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 1600)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 9:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:10:52\n",
      "  Predicting on split [9]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 1800)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 10:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:11:45\n",
      "  Predicting on split [10]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 2000)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 11:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:13:01\n",
      "  Predicting on split [11]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 2200)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 12:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:13:50\n",
      "  Predicting on split [12]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 2400)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 13:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:15:44\n",
      "  Predicting on split [13]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 2600)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 14:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:16:37\n",
      "  Predicting on split [14]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 2800)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 15:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:18:15\n",
      "  Predicting on split [15]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 3000)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 16:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:19:02\n",
      "  Predicting on split [16]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 3200)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 17:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:20:37\n",
      "  Predicting on split [17]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 3400)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 18:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:21:13\n",
      "  Predicting on split [18]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 3600)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 19:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:22:38\n",
      "  Predicting on split [19]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 3800)\n",
      "  â±ï¸  Prediction time: 0:00:04\n",
      "\n",
      "============================================================\n",
      "Round 20:\n",
      "============================================================\n",
      "  Fine-tuning on splits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]â€¦\n",
      "  â±ï¸  Fine-tuning time: 0:24:08\n",
      "  Predicting on split [20]â€¦\n",
      "  ðŸ§® Prediction data size: 200 rows (total so far: 4000)\n",
      "  â±ï¸  Prediction time: 0:00:04\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Initialize timing log file\n",
    "timing_file = \"Result/CLIP_timing_log_cuda.csv\"\n",
    "pd.DataFrame([[\"round\", \"stage\", \"rows_this_stage\", \"rows_total_so_far\",\n",
    "               \"duration_seconds\", \"duration_formatted\"]]).to_csv(\n",
    "    timing_file, index=False, header=False\n",
    ")\n",
    "\n",
    "def format_duration(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "train_total = 0\n",
    "pred_total  = 0\n",
    "\n",
    "for r in range(1, n_rounds + 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Round {r}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if r == 1:\n",
    "        # -------------------------------\n",
    "        # Zero-shot prediction\n",
    "        # -------------------------------\n",
    "        print(\"  Predicting on split [1] (0-shot)â€¦\")\n",
    "        stage_start = time.time()\n",
    "        with redirect_stdout(buf), redirect_stderr(buf):\n",
    "            df_pred = classification_CLIP_0_shot(\n",
    "                text_path      = f\"Data_train/nytimes_{r}.csv\",\n",
    "                img_dir        = img_dir,\n",
    "                mode           = \"both\",\n",
    "                prompt         = prompt_CLIP,\n",
    "                text_column    = text_cols,\n",
    "                predict_column = f\"Label_CLIP_{r}\",\n",
    "            )\n",
    "        predict_time = time.time() - stage_start\n",
    "        \n",
    "        # NEW: count + accumulate predictions\n",
    "        n_pred = len(df_pred)\n",
    "        pred_total += n_pred\n",
    "        print(f\"  ðŸ§® Prediction data size: {n_pred} rows (total so far: {pred_total})\")\n",
    "        print(f\"  â±ï¸  Prediction time: {format_duration(predict_time)}\")\n",
    "        \n",
    "        # Log timing + size\n",
    "        pd.DataFrame([[r, f\"prediction_0shot\",\n",
    "                       n_pred, pred_total,\n",
    "                       predict_time, format_duration(predict_time)]]).to_csv(\n",
    "            timing_file, mode=\"a\", header=False, index=False\n",
    "        )\n",
    "    else:\n",
    "        # -------------------------------\n",
    "        # 1) Fine-tune on previous splits\n",
    "        # -------------------------------\n",
    "        train_idxs = list(range(1, r))\n",
    "        print(f\"  Fine-tuning on splits {train_idxs}â€¦\")\n",
    "        finetune_start = time.time()\n",
    "        \n",
    "        with redirect_stdout(buf), redirect_stderr(buf):\n",
    "            dfs = [pd.read_csv(f\"Data_train/nytimes_{i}.csv\") for i in train_idxs]\n",
    "            train_df = pd.concat(dfs, ignore_index=True)\n",
    "            train_csv = f\"Data_train/nytimes_train_1_to_{r-1}.csv\"\n",
    "            train_df.to_csv(train_csv, index=False)\n",
    "            model_path = f\"CLIP_Finetuned/round{r}.pth\"\n",
    "            \n",
    "            # NEW: count + accumulate training rows\n",
    "            n_train = len(train_df)\n",
    "            train_total += n_train\n",
    "            print(f\"  ðŸ§® Training data size: {n_train} rows (total so far: {train_total})\")\n",
    "            \n",
    "            finetune_CLIP(\n",
    "                mode          = \"both\",\n",
    "                text_path     = train_csv,\n",
    "                img_dir       = img_dir,\n",
    "                text_column   = text_cols,\n",
    "                true_label    = \"section_numeric\",\n",
    "                model_name    = model_path,\n",
    "                num_epochs    = n_epochs,\n",
    "                batch_size    = batch_size,\n",
    "                learning_rate = lr,\n",
    "            )\n",
    "        \n",
    "        finetune_time = time.time() - finetune_start\n",
    "        print(f\"  â±ï¸  Fine-tuning time: {format_duration(finetune_time)}\")\n",
    "        \n",
    "        # Log timing + size\n",
    "        pd.DataFrame([[r, f\"finetuning\",\n",
    "                       n_train, train_total,\n",
    "                       finetune_time, format_duration(finetune_time)]]).to_csv(\n",
    "            timing_file, mode=\"a\", header=False, index=False\n",
    "        )\n",
    "        \n",
    "        # -------------------------------\n",
    "        # 2) Predict on current split\n",
    "        # -------------------------------\n",
    "        print(f\"  Predicting on split [{r}]â€¦\")\n",
    "        predict_start = time.time()\n",
    "        \n",
    "        with redirect_stdout(buf), redirect_stderr(buf):\n",
    "            df_pred = classification_CLIP_finetuned(\n",
    "                mode           = \"both\",\n",
    "                text_path      = f\"Data_train/nytimes_{r}.csv\",\n",
    "                img_dir        = img_dir,\n",
    "                text_column    = text_cols,\n",
    "                model_name     = model_path,\n",
    "                predict_column = f\"Label_CLIP_{r}\",\n",
    "            )\n",
    "        \n",
    "        predict_time = time.time() - predict_start\n",
    "        # NEW: count + accumulate predictions\n",
    "        n_pred = len(df_pred)\n",
    "        pred_total += n_pred\n",
    "        print(f\"  ðŸ§® Prediction data size: {n_pred} rows (total so far: {pred_total})\")\n",
    "        print(f\"  â±ï¸  Prediction time: {format_duration(predict_time)}\")\n",
    "        \n",
    "        # Log timing + size\n",
    "        pd.DataFrame([[r, f\"prediction_finetuned\",\n",
    "                       n_pred, pred_total,\n",
    "                       predict_time, format_duration(predict_time)]]).to_csv(\n",
    "            timing_file, mode=\"a\", header=False, index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a6142-0c9f-433c-8f2b-ee0da6d49459",
   "metadata": {},
   "source": [
    "# Apply to all testing df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f078c0-df7b-4ee2-a76d-92a88e1a0480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4000 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [01:27<00:00, 45.47it/s]\n"
     ]
    }
   ],
   "source": [
    "CLIP_1_all = classification_CLIP_0_shot(\n",
    "    text_path=\"Data_test/nytimes_test_sample4000.csv\",\n",
    "    img_dir=\"Data_test/imgs_test_sample4000\",\n",
    "    mode=\"both\",\n",
    "    prompt=prompt_CLIP,\n",
    "    text_column=[\"headline\", \"abstract\"],\n",
    "    predict_column=\"CLIP_1\",\n",
    ")\n",
    "\n",
    "CLIP_1_all.to_excel(\"Result/99_CLIP_all_0_shot.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6423ef-0119-434b-b2a9-c2940d598dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Round 2...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 3...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 4...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 5...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 6...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 7...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 8...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 9...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 10...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 11...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 12...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 13...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 14...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 15...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 16...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 17...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 18...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 19...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:53<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Processing Round 20...\n",
      "ðŸ“„ Loaded 4000 samples for prediction\n",
      "ðŸ” Detected num_classes=24 from checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:52<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction complete - 4000 rows labeled with original class IDs.\n",
      "Classification completed for all rounds.\n"
     ]
    }
   ],
   "source": [
    "# Load the initial dataset\n",
    "CLIP_test = pd.read_csv(\"Data_test/nytimes_test_sample4000.csv\")\n",
    "\n",
    "# Loop through rounds 1 to 20\n",
    "for round_num in range(2, 21):\n",
    "    print(f\"Processing Round {round_num}...\")\n",
    "\n",
    "    # Define the model path\n",
    "    model_path = f\"CLIP_Finetuned/round{round_num}.pth\"\n",
    "    \n",
    "    # Perform classification with the fine-tuned model\n",
    "    result = classification_CLIP_finetuned(\n",
    "        mode=\"both\",\n",
    "        text_path=\"Data_test/nytimes_test_sample4000.csv\",\n",
    "        text_column=[\"headline\", \"abstract\"],\n",
    "        img_dir=\"Data_test/imgs_test_sample4000\",\n",
    "        model_name=model_path,\n",
    "        predict_column=f\"CLIP_test_label{round_num}\"\n",
    "    )\n",
    "    \n",
    "    # Merge the result with the original dataframe\n",
    "    CLIP_test[f\"CLIP_test_label{round_num}\"] = result[f\"CLIP_test_label{round_num}\"]\n",
    "\n",
    "    # Save the results back to CSV after each round\n",
    "    CLIP_test.to_csv(\"Result/CLIP_test.csv\", index=False)\n",
    "\n",
    "    # Clear memory to avoid overflow\n",
    "    del result\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "print(\"Classification completed for all rounds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d395b82-dbf7-46d3-ba7d-4805c43eb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_test.to_excel(\"Result/CLIP_test.xlsx\", index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa23be9-487c-4eda-b88e-961fe708acd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.61475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.72150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.72225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.72950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.76300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.75050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.76650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.77675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.78375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.77300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.77775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.78150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.78900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.79450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.79675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.79675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.80500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.78300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.79975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Round  Accuracy\n",
       "0       2   0.61475\n",
       "1       3   0.72150\n",
       "2       4   0.72225\n",
       "3       5   0.72950\n",
       "4       6   0.76300\n",
       "5       7   0.75050\n",
       "6       8   0.76650\n",
       "7       9   0.77675\n",
       "8      10   0.78375\n",
       "9      11   0.77300\n",
       "10     12   0.77775\n",
       "11     13   0.78150\n",
       "12     14   0.78900\n",
       "13     15   0.79450\n",
       "14     16   0.79675\n",
       "15     17   0.79675\n",
       "16     18   0.80500\n",
       "17     19   0.78300\n",
       "18     20   0.79975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clip_test = pd.read_csv(\"Result/CLIP_test.csv\")\n",
    "\n",
    "# Initialize a dictionary to store the accuracy of each round\n",
    "accuracy_results = {}\n",
    "\n",
    "# Loop through each round to compare predictions with the ground truth\n",
    "for round_num in range(1, 21):\n",
    "    label_col = f\"CLIP_test_label{round_num}\"\n",
    "    if label_col in clip_test.columns:\n",
    "        # Calculate the accuracy\n",
    "        accuracy = (clip_test[label_col] == clip_test['section_numeric']).mean()\n",
    "        accuracy_results[round_num] = accuracy\n",
    "\n",
    "# Convert the results to a DataFrame for easy viewing\n",
    "accuracy_df = pd.DataFrame(list(accuracy_results.items()), columns=['Round', 'Accuracy'])\n",
    "\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5446a91b-55ef-44a6-bad4-2ca20976c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"Result/CLIP_test_accuracy.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
