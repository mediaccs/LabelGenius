{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5dd24d5-f7fc-464c-aaa1-56c9ff5a4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelgenius import (\n",
    "    classification_CLIP_0_shot,\n",
    "    classification_CLIP_finetuned,\n",
    "    finetune_CLIP,\n",
    "    auto_verification,\n",
    "    classification_GPT,\n",
    "    generate_GPT_finetune_jsonl,\n",
    "    finetune_GPT,\n",
    "    price_estimation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81974634-8d58-4cd8-a6b1-d1243584be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_GPT = [\n",
    "    \"0\", \"1\"\n",
    "]\n",
    "prompt_GPT = '''Here's a news article headline. Please label if it belongs to the following theme.\n",
    "            Return <1> if this headline belongs to these themes and return <0> if it does not belong to the themes.\n",
    "            Please code for each of the following 8 topics.\n",
    "            Please identify up to two dominant themes from the headline, which means you can have a max of 2 <1> in the answer you generated.\n",
    "            You don't have to label two topic if you don't fint it apply. Just enter 0s.\n",
    "            - Economic consequences: The story is about economic benefits or costs, or the costs involving immigration-related issues, including: Cost of mass deportation; Economic benefits of immigration (more tax revenue, cheap labor; Economic costs of immigration (taking jobs from Americans, immigrants using healthcare and educational services, overcrowding, housing concerns)\n",
    "            - Crime/safety: The story is about threats to American's safety, including: Immigration described as a major cause of increased rates of crime, gangs, drug trafficking, etc; Immigrants described as law-breakers who deserve punishment; Immigration described as a threat to national security via terrorism\n",
    "            - Family: The story is about the impact of immigration on families, including: Separating children from parents; Breaking up multi-generational families; Interfering with children's continued schooling\n",
    "            - Immigrant wellbeing: This story is about the negative impact of the immigration process on immigrants, including: Prejudice and bias toward immigrants; Physical and/or mental health or safety of immigrants; Immigration policies described as violations of immigrants' civil rights and liberties; Immigration policies regarding illegal immigrants described as unfair to immigrants who have waited to become citizens the legal way\n",
    "            - Culture/society: This story is about societal-wide factors or consequences related to immigration, including:; Immigration as a threat to American cultural identity, way of living, the predominance of English and Christianity, etc.; Immigrants as isolated from the rest of America, unable to assimilate into communities; Immigration as part of the celebrated history of immigration in America / America-as-melting-pot; Immigration policies as exemplars of society's immorality; Impact of immigration on a specific subculture/community in the US\n",
    "            - Politics:The story is mainly about the political issues around immigration, including: Political campaigns and upcoming elections (e.g., using immigration as a wedge issue or motivating force to get people to the polls); Fighting between the Democratic and Republican parties, or politicians; One political party or one politicianâ€™s stance on immigration. Therefore, when the news headline mentions a politicianâ€™s name, it often indicates the theme of politics\n",
    "            - Legislation/regulation: The story is about issues related to regulating immigration through legislation and other institutional measures: New immigration legislation being introduced/argued over; Flaws in current/old legislation; Enforcement of current legislation\n",
    "            - Public opinion: The study is about the publicâ€™s, including a specific communityâ€™s, reactions to immigration-related issues, including: Public opinion polls; Protests; Social media backlash; Community outrage; Celebrity responses/protests\n",
    "            Answer using the following format [0, 0, 0, 0, 0, 0, 0, 0]. Do not provide any other information'''\n",
    "\n",
    "\n",
    "api_key = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9508aa-7dfb-4131-b752-9ab78215d806",
   "metadata": {},
   "source": [
    "# Estimate Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1c3125-5b40-4048-b794-dc05a9367c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f27e45-60b8-4d98-9e61-51f965f593e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§® Estimated Cost for 12,000 calls (4,000 rows Ã— 3 votes)\n",
      "â€¢ Avg prompt tokens/call:     679\n",
      "â€¢ Avg completion tokens/call: 670\n",
      "â€¢ Pricing ($/1M tokens): prompt=$0.05, completion=$0.4\n",
      "ðŸ’° Total: $3.6234    (Â±10% â†’ $3.2611â€“$3.9857)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6233999999999997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_5_nano_r = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": prompt_GPT,\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Trump: 'Mexico Will Pay for the Wall'\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    },\n",
    "    \"verbosity\": \"medium\"\n",
    "  },\n",
    "  reasoning={\n",
    "    \"effort\": \"medium\"\n",
    "  },\n",
    "  tools=[],\n",
    "  store=True,\n",
    "  include=[\n",
    "    \"reasoning.encrypted_content\",\n",
    "    \"web_search_call.action.sources\"\n",
    "  ]\n",
    ")\n",
    "price_estimation (response_5_nano_r,\n",
    "                  num_rows = 4000,\n",
    "                  input_cost_per_million = 0.05,\n",
    "                  output_cost_per_million = 0.40,\n",
    "                  num_votes = 3)\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff98884-4d06-46ce-a62d-c67d5882e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§® Estimated Cost for 12,000 calls (4,000 rows Ã— 3 votes)\n",
      "â€¢ Avg prompt tokens/call:     679\n",
      "â€¢ Avg completion tokens/call: 30\n",
      "â€¢ Pricing ($/1M tokens): prompt=$0.05, completion=$0.4\n",
      "ðŸ’° Total: $0.5514    (Â±10% â†’ $0.4963â€“$0.6065)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5514000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_5_nano_nr = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": prompt_GPT,\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Trump: 'Mexico Will Pay for the Wall'\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    },\n",
    "    \"verbosity\": \"medium\"\n",
    "  },\n",
    "  reasoning={\n",
    "    \"effort\": \"minimal\"\n",
    "  },\n",
    "  tools=[],\n",
    "  store=True,\n",
    "  include=[\n",
    "    \"reasoning.encrypted_content\",\n",
    "    \"web_search_call.action.sources\"\n",
    "  ]\n",
    ")\n",
    "price_estimation (response_5_nano_nr,\n",
    "                  num_rows = 4000,\n",
    "                  input_cost_per_million = 0.05,\n",
    "                  output_cost_per_million = 0.40,\n",
    "                  num_votes = 3)\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "590f9ff7-9a8f-4075-a219-3b2652f2c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§® Estimated Cost for 12,000 calls (4,000 rows Ã— 3 votes)\n",
      "â€¢ Avg prompt tokens/call:     679\n",
      "â€¢ Avg completion tokens/call: 478\n",
      "â€¢ Pricing ($/1M tokens): prompt=$1.25, completion=$10\n",
      "ðŸ’° Total: $67.5450    (Â±10% â†’ $60.7905â€“$74.2995)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.545"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_5_r = client.responses.create(\n",
    "  model=\"gpt-5\",\n",
    "  input=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": prompt_GPT,\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Trump: 'Mexico Will Pay for the Wall'\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    },\n",
    "    \"verbosity\": \"medium\"\n",
    "  },\n",
    "  reasoning={\n",
    "    \"effort\": \"medium\"\n",
    "  },\n",
    "  tools=[],\n",
    "  store=True,\n",
    "  include=[\n",
    "    \"reasoning.encrypted_content\",\n",
    "    \"web_search_call.action.sources\"\n",
    "  ]\n",
    ")\n",
    "price_estimation (response_5_r,\n",
    "                  num_rows = 4000,\n",
    "                  input_cost_per_million = 1.25,\n",
    "                  output_cost_per_million = 10,\n",
    "                  num_votes = 3)\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844f7c6e-d723-4102-81f9-b4d592a8e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§® Estimated Cost for 12,000 calls (4,000 rows Ã— 3 votes)\n",
      "â€¢ Avg prompt tokens/call:     679\n",
      "â€¢ Avg completion tokens/call: 30\n",
      "â€¢ Pricing ($/1M tokens): prompt=$1.25, completion=$10\n",
      "ðŸ’° Total: $13.7850    (Â±10% â†’ $12.4065â€“$15.1635)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.785"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_5_r = client.responses.create(\n",
    "  model=\"gpt-5\",\n",
    "  input=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": prompt_GPT,\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Trump: 'Mexico Will Pay for the Wall'\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    },\n",
    "    \"verbosity\": \"medium\"\n",
    "  },\n",
    "  reasoning={\n",
    "    \"effort\": \"minimal\"\n",
    "  },\n",
    "  tools=[],\n",
    "  store=True,\n",
    "  include=[\n",
    "    \"reasoning.encrypted_content\",\n",
    "    \"web_search_call.action.sources\"\n",
    "  ]\n",
    ")\n",
    "price_estimation (response_5_r,\n",
    "                  num_rows = 4000,\n",
    "                  input_cost_per_million = 1.25,\n",
    "                  output_cost_per_million = 10,\n",
    "                  num_votes = 3)\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8d99937-eee8-4fda-957f-67a5f869f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§® Estimated Cost for 12,000 calls (4,000 rows Ã— 3 votes)\n",
      "â€¢ Avg prompt tokens/call:     679\n",
      "â€¢ Avg completion tokens/call: 30\n",
      "â€¢ Pricing ($/1M tokens): prompt=$0.8, completion=$3.2\n",
      "ðŸ’° Total: $7.6704    (Â±10% â†’ $6.9034â€“$8.4374)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.670400000000002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_41 = client.responses.create(\n",
    "  model=\"gpt-4.1-mini\",\n",
    "  input=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": prompt_GPT,\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"input_text\",\n",
    "          \"text\": \"Trump: 'Mexico Will Pay for the Wall'\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  text={\n",
    "    \"format\": {\n",
    "      \"type\": \"text\"\n",
    "    },\n",
    "    \"verbosity\": \"medium\"\n",
    "  },\n",
    "\n",
    ")\n",
    "price_estimation (response_5_r,\n",
    "                  num_rows = 4000,\n",
    "                  input_cost_per_million = 0.8,\n",
    "                  output_cost_per_million = 3.2,\n",
    "                  num_votes = 3)\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "# https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "587da3c1-3e2f-4e22-a63d-1305eda10a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0ed66c100dd96dd60068f6787e73b08193ba08e880ca797aa6', created_at=1760983166.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-mini-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_0ed66c100dd96dd60068f6787f42c481939fd22d309bb338aa', content=[ResponseOutputText(annotations=[], text='[0, 0, 0, 0, 0, 1, 1, 0]', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), truncation='disabled', usage=ResponseUsage(input_tokens=680, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=25, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=705), user=None, background=False, billing={'payer': 'openai'}, max_tool_calls=None, prompt_cache_key=None, safety_identifier=None, service_tier='default', store=True, top_logprobs=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_41"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece54283-c093-41cf-94d9-9ad6b8cb3fe7",
   "metadata": {},
   "source": [
    "# 0-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc76b92-efb1-401e-9397-242b5362f130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 19:18:59.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-19 19:18:59.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-19 19:18:59.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  4.63s/row | , âš¡ cache: 53  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GPT_5_nano_0shot = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category=category_GPT,\n",
    "    prompt=prompt_GPT,          \n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=api_key,\n",
    "    reasoning_effort= \"medium\",\n",
    "    mode=\"text\",\n",
    "    output_column_name=\"GPT_5_nano_r\",\n",
    "    num_themes=8,\n",
    "    num_votes=3,\n",
    "    wait_time = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GPT_5_nano_0shot.to_csv(\"Result/GPT_5_nano_r.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae47977-f11a-49a1-96cf-4c888ecfc069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_5_nano_0shot_1' vs. 'Q3_1' ==\n",
      "Accuracy:   91.74%\n",
      "Macro F1:   61.87%\n",
      "Micro  F1:  91.74%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       509\n",
      "           1       0.56      0.19      0.28        48\n",
      "\n",
      "    accuracy                           0.92       557\n",
      "   macro avg       0.75      0.59      0.62       557\n",
      "weighted avg       0.90      0.92      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[502   7]\n",
      " [ 39   9]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_2' vs. 'Q3_2' ==\n",
      "Accuracy:   89.41%\n",
      "Macro F1:   69.50%\n",
      "Micro  F1:  89.41%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       482\n",
      "           1       0.75      0.32      0.45        75\n",
      "\n",
      "    accuracy                           0.89       557\n",
      "   macro avg       0.83      0.65      0.70       557\n",
      "weighted avg       0.88      0.89      0.88       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[474   8]\n",
      " [ 51  24]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_3' vs. 'Q3_3' ==\n",
      "Accuracy:   98.20%\n",
      "Macro F1:   78.71%\n",
      "Micro  F1:  98.20%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       540\n",
      "           1       1.00      0.41      0.58        17\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.99      0.71      0.79       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[540   0]\n",
      " [ 10   7]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_4' vs. 'Q3_4' ==\n",
      "Accuracy:   82.94%\n",
      "Macro F1:   62.34%\n",
      "Micro  F1:  82.94%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       465\n",
      "           1       0.47      0.27      0.34        92\n",
      "\n",
      "    accuracy                           0.83       557\n",
      "   macro avg       0.67      0.61      0.62       557\n",
      "weighted avg       0.80      0.83      0.81       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[437  28]\n",
      " [ 67  25]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_5' vs. 'Q3_5' ==\n",
      "Accuracy:   93.00%\n",
      "Macro F1:   58.37%\n",
      "Micro  F1:  93.00%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       541\n",
      "           1       0.15      0.31      0.20        16\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.57      0.63      0.58       557\n",
      "weighted avg       0.96      0.93      0.94       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[513  28]\n",
      " [ 11   5]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_6' vs. 'Q3_6' ==\n",
      "Accuracy:   85.28%\n",
      "Macro F1:   82.41%\n",
      "Micro  F1:  85.28%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.61      0.75       204\n",
      "           1       0.82      0.99      0.90       353\n",
      "\n",
      "    accuracy                           0.85       557\n",
      "   macro avg       0.90      0.80      0.82       557\n",
      "weighted avg       0.87      0.85      0.84       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[125  79]\n",
      " [  3 350]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_7' vs. 'Q3_7' ==\n",
      "Accuracy:   63.73%\n",
      "Macro F1:   63.52%\n",
      "Micro  F1:  63.73%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.45      0.61       344\n",
      "           1       0.51      0.93      0.66       213\n",
      "\n",
      "    accuracy                           0.64       557\n",
      "   macro avg       0.72      0.69      0.64       557\n",
      "weighted avg       0.76      0.64      0.63       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[156 188]\n",
      " [ 14 199]]\n",
      "\n",
      "== Verification of 'GPT_5_nano_0shot_8' vs. 'Q3_8' ==\n",
      "Accuracy:   90.31%\n",
      "Macro F1:   59.91%\n",
      "Micro  F1:  90.31%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       527\n",
      "           1       0.21      0.30      0.25        30\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.59      0.62      0.60       557\n",
      "weighted avg       0.92      0.90      0.91       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[494  33]\n",
      " [ 21   9]]\n",
      "\n",
      ">> Overall accuracy: 86.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_5_nano_0shot_1 vs Q3_1': {'accuracy': 0.9174147217235189,\n",
       "  'precision_macro': 0.7452056377079482,\n",
       "  'recall_macro': 0.5868737721021611,\n",
       "  'f1_macro': 0.6187202380952381,\n",
       "  'precision_micro': 0.9174147217235189,\n",
       "  'recall_micro': 0.9174147217235189,\n",
       "  'f1_micro': 0.9174147217235189,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.99      0.96       509\\n           1       0.56      0.19      0.28        48\\n\\n    accuracy                           0.92       557\\n   macro avg       0.75      0.59      0.62       557\\nweighted avg       0.90      0.92      0.90       557\\n',\n",
       "  'confusion_matrix': array([[502,   7],\n",
       "         [ 39,   9]])},\n",
       " 'GPT_5_nano_0shot_2 vs Q3_2': {'accuracy': 0.8940754039497307,\n",
       "  'precision_macro': 0.8264285714285714,\n",
       "  'recall_macro': 0.651701244813278,\n",
       "  'f1_macro': 0.6950041299687236,\n",
       "  'precision_micro': 0.8940754039497307,\n",
       "  'recall_micro': 0.8940754039497307,\n",
       "  'f1_micro': 0.8940754039497307,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.90      0.98      0.94       482\\n           1       0.75      0.32      0.45        75\\n\\n    accuracy                           0.89       557\\n   macro avg       0.83      0.65      0.70       557\\nweighted avg       0.88      0.89      0.88       557\\n',\n",
       "  'confusion_matrix': array([[474,   8],\n",
       "         [ 51,  24]])},\n",
       " 'GPT_5_nano_0shot_3 vs Q3_3': {'accuracy': 0.9820466786355476,\n",
       "  'precision_macro': 0.990909090909091,\n",
       "  'recall_macro': 0.7058823529411764,\n",
       "  'f1_macro': 0.7870795107033639,\n",
       "  'precision_micro': 0.9820466786355476,\n",
       "  'recall_micro': 0.9820466786355476,\n",
       "  'f1_micro': 0.9820466786355476,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      1.00      0.99       540\\n           1       1.00      0.41      0.58        17\\n\\n    accuracy                           0.98       557\\n   macro avg       0.99      0.71      0.79       557\\nweighted avg       0.98      0.98      0.98       557\\n',\n",
       "  'confusion_matrix': array([[540,   0],\n",
       "         [ 10,   7]])},\n",
       " 'GPT_5_nano_0shot_4 vs Q3_4': {'accuracy': 0.829443447037702,\n",
       "  'precision_macro': 0.6693808026355197,\n",
       "  'recall_macro': 0.6057620383356709,\n",
       "  'f1_macro': 0.6233941852603111,\n",
       "  'precision_micro': 0.829443447037702,\n",
       "  'recall_micro': 0.829443447037702,\n",
       "  'f1_micro': 0.829443447037702,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.87      0.94      0.90       465\\n           1       0.47      0.27      0.34        92\\n\\n    accuracy                           0.83       557\\n   macro avg       0.67      0.61      0.62       557\\nweighted avg       0.80      0.83      0.81       557\\n',\n",
       "  'confusion_matrix': array([[437,  28],\n",
       "         [ 67,  25]])},\n",
       " 'GPT_5_nano_0shot_5 vs Q3_5': {'accuracy': 0.9299820466786356,\n",
       "  'precision_macro': 0.5652613925514689,\n",
       "  'recall_macro': 0.6303719963031423,\n",
       "  'f1_macro': 0.5837309571716011,\n",
       "  'precision_micro': 0.9299820466786356,\n",
       "  'recall_micro': 0.9299820466786356,\n",
       "  'f1_micro': 0.9299820466786356,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.95      0.96       541\\n           1       0.15      0.31      0.20        16\\n\\n    accuracy                           0.93       557\\n   macro avg       0.57      0.63      0.58       557\\nweighted avg       0.96      0.93      0.94       557\\n',\n",
       "  'confusion_matrix': array([[513,  28],\n",
       "         [ 11,   5]])},\n",
       " 'GPT_5_nano_0shot_6 vs Q3_6': {'accuracy': 0.8527827648114902,\n",
       "  'precision_macro': 0.896206657925408,\n",
       "  'recall_macro': 0.8021232572349053,\n",
       "  'f1_macro': 0.824076356577204,\n",
       "  'precision_micro': 0.8527827648114902,\n",
       "  'recall_micro': 0.8527827648114902,\n",
       "  'f1_micro': 0.8527827648114902,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.61      0.75       204\\n           1       0.82      0.99      0.90       353\\n\\n    accuracy                           0.85       557\\n   macro avg       0.90      0.80      0.82       557\\nweighted avg       0.87      0.85      0.84       557\\n',\n",
       "  'confusion_matrix': array([[125,  79],\n",
       "         [  3, 350]])},\n",
       " 'GPT_5_nano_0shot_7 vs Q3_7': {'accuracy': 0.6373429084380611,\n",
       "  'precision_macro': 0.7159294725642195,\n",
       "  'recall_macro': 0.6938803362812535,\n",
       "  'f1_macro': 0.6351686121919584,\n",
       "  'precision_micro': 0.6373429084380611,\n",
       "  'recall_micro': 0.6373429084380611,\n",
       "  'f1_micro': 0.6373429084380611,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.45      0.61       344\\n           1       0.51      0.93      0.66       213\\n\\n    accuracy                           0.64       557\\n   macro avg       0.72      0.69      0.64       557\\nweighted avg       0.76      0.64      0.63       557\\n',\n",
       "  'confusion_matrix': array([[156, 188],\n",
       "         [ 14, 199]])},\n",
       " 'GPT_5_nano_0shot_8 vs Q3_8': {'accuracy': 0.9030520646319569,\n",
       "  'precision_macro': 0.5867545076282941,\n",
       "  'recall_macro': 0.6186907020872865,\n",
       "  'f1_macro': 0.5990882917466411,\n",
       "  'precision_micro': 0.9030520646319569,\n",
       "  'recall_micro': 0.9030520646319569,\n",
       "  'f1_micro': 0.9030520646319569,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.96      0.94      0.95       527\\n           1       0.21      0.30      0.25        30\\n\\n    accuracy                           0.90       557\\n   macro avg       0.59      0.62      0.60       557\\nweighted avg       0.92      0.90      0.91       557\\n',\n",
       "  'confusion_matrix': array([[494,  33],\n",
       "         [ 21,   9]])},\n",
       " 'overall_accuracy': 0.8682675044883303}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_5_nano_0shot,\n",
    "    predicted_cols=[\n",
    "        \"GPT_5_nano_0shot_1\",\n",
    "        \"GPT_5_nano_0shot_2\",\n",
    "        \"GPT_5_nano_0shot_3\",\n",
    "        \"GPT_5_nano_0shot_4\",\n",
    "        \"GPT_5_nano_0shot_5\",\n",
    "        \"GPT_5_nano_0shot_6\",\n",
    "        \"GPT_5_nano_0shot_7\",\n",
    "        \"GPT_5_nano_0shot_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e1c6d-b069-4fba-a601-4a842caf84da",
   "metadata": {},
   "source": [
    "# Finetune with N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cb9ad6-62cb-47f5-a3da-a0775e29934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Finetune_df_1 = pd.read_excel(\"Data_train/train_1.xlsx\", sheet_name=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca02583f-f65d-41e0-8c1e-381578b7831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_GPT_finetune_jsonl(Finetune_df_1, \n",
    "                        output_path=\"GPT_Finetune/train_1.jsonl\", \n",
    "                        system_prompt = prompt_GPT,\n",
    "                        input_col = [\"Post_Title\"],\n",
    "                        label_col=[\"Q3_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de91058e-cabd-4aec-bb66-253833b8c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fine-tune job ftjob-4AEACpqhvmmti9pevFZd58hX\n",
      "[0s] status=validating_files\n",
      "[15s] status=validating_files\n",
      "[30s] status=validating_files\n",
      "[45s] status=validating_files\n",
      "[60s] status=validating_files\n",
      "[75s] status=validating_files\n",
      "[90s] status=validating_files\n",
      "[105s] status=validating_files\n",
      "[120s] status=validating_files\n",
      "[135s] status=validating_files\n",
      "[150s] status=running\n",
      "[165s] status=running\n",
      "[180s] status=running\n",
      "[195s] status=running\n",
      "[210s] status=running\n",
      "[225s] status=running\n",
      "[240s] status=running\n",
      "[255s] status=running\n",
      "[270s] status=running\n",
      "[285s] status=running\n",
      "[300s] status=running\n",
      "[315s] status=running\n",
      "[330s] status=running\n",
      "[345s] status=running\n",
      "[360s] status=running\n",
      "[375s] status=running\n",
      "[390s] status=running\n",
      "[405s] status=running\n",
      "[420s] status=running\n",
      "[435s] status=running\n",
      "[450s] status=running\n",
      "[465s] status=running\n",
      "[480s] status=running\n",
      "[495s] status=running\n",
      "[510s] status=running\n",
      "[525s] status=running\n",
      "[540s] status=running\n",
      "[555s] status=running\n",
      "[570s] status=running\n",
      "[585s] status=running\n",
      "[600s] status=running\n",
      "[615s] status=running\n",
      "[630s] status=running\n",
      "[645s] status=running\n",
      "[660s] status=running\n",
      "[675s] status=running\n",
      "[690s] status=running\n",
      "[705s] status=running\n",
      "[720s] status=running\n",
      "[735s] status=running\n",
      "[750s] status=running\n",
      "[765s] status=running\n",
      "[780s] status=running\n",
      "[795s] status=running\n",
      "[810s] status=running\n",
      "[825s] status=running\n",
      "[840s] status=running\n",
      "[855s] status=running\n",
      "[870s] status=running\n",
      "[885s] status=running\n",
      "[900s] status=running\n",
      "[915s] status=running\n",
      "[930s] status=running\n",
      "[945s] status=running\n",
      "[960s] status=running\n",
      "[975s] status=running\n",
      "[990s] status=running\n",
      "[1005s] status=running\n",
      "[1020s] status=running\n",
      "[1035s] status=running\n",
      "[1050s] status=running\n",
      "[1065s] status=running\n",
      "[1080s] status=running\n",
      "[1095s] status=running\n",
      "[1110s] status=running\n",
      "[1125s] status=running\n",
      "[1140s] status=running\n",
      "[1155s] status=running\n",
      "[1170s] status=running\n",
      "[1185s] status=running\n",
      "[1200s] status=running\n",
      "[1215s] status=succeeded\n",
      "âœ… succeeded: ft:gpt-4.1-mini-2025-04-14:jcs-research::CQfb02st\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-41\n",
    "GPT_finetune_1 = finetune_GPT(\n",
    "    training_file_path=\"GPT_Finetune/train_1.jsonl\",\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",  \n",
    "    hyperparameters={\"batch_size\":8, \"learning_rate_multiplier\":0.01},\n",
    "    api_key= api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3accd52b-a215-4169-ac60-bbdaccc175c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 16:21:34.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-14 16:21:34.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-14 16:21:34.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "Classifying text_class: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 [23:53<00:00,  2.57s/item]\n"
     ]
    }
   ],
   "source": [
    "# Classify with fineâ€‘tuned model\n",
    "GPT_41_finetune_1 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category = category_GPT,\n",
    "    prompt = prompt_GPT,\n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model = \"ft:gpt-4.1-mini-2025-04-14:jcs-research::CQfb02st\",\n",
    "    api_key = api_key,\n",
    "    temperature = 0.8,\n",
    "    mode = \"text\",\n",
    "    output_column_name=\"GPT_41_finetune_1\",\n",
    "    num_themes = 8,\n",
    "    num_votes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eb0c6e7-73e1-4d5b-a61a-64751f3ea611",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_41_finetune_1.to_csv(\"Result/00_GPT_41_finetune_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cf1c706-f7a0-4c9e-91e2-045b7d56155c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_41_finetune_1_1' vs. 'Q3_1' ==\n",
      "Accuracy:   88.33%\n",
      "Macro F1:   64.61%\n",
      "Micro  F1:  88.33%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       509\n",
      "           1       0.34      0.38      0.36        48\n",
      "\n",
      "    accuracy                           0.88       557\n",
      "   macro avg       0.64      0.65      0.65       557\n",
      "weighted avg       0.89      0.88      0.89       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[474  35]\n",
      " [ 30  18]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_2' vs. 'Q3_2' ==\n",
      "Accuracy:   87.79%\n",
      "Macro F1:   72.56%\n",
      "Micro  F1:  87.79%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       482\n",
      "           1       0.55      0.49      0.52        75\n",
      "\n",
      "    accuracy                           0.88       557\n",
      "   macro avg       0.74      0.72      0.73       557\n",
      "weighted avg       0.87      0.88      0.87       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[452  30]\n",
      " [ 38  37]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_3' vs. 'Q3_3' ==\n",
      "Accuracy:   97.31%\n",
      "Macro F1:   79.03%\n",
      "Micro  F1:  97.31%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       540\n",
      "           1       0.55      0.65      0.59        17\n",
      "\n",
      "    accuracy                           0.97       557\n",
      "   macro avg       0.77      0.82      0.79       557\n",
      "weighted avg       0.98      0.97      0.97       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[531   9]\n",
      " [  6  11]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_4' vs. 'Q3_4' ==\n",
      "Accuracy:   80.07%\n",
      "Macro F1:   69.49%\n",
      "Micro  F1:  80.07%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87       465\n",
      "           1       0.43      0.64      0.52        92\n",
      "\n",
      "    accuracy                           0.80       557\n",
      "   macro avg       0.68      0.74      0.69       557\n",
      "weighted avg       0.84      0.80      0.82       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[387  78]\n",
      " [ 33  59]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_5' vs. 'Q3_5' ==\n",
      "Accuracy:   91.20%\n",
      "Macro F1:   59.97%\n",
      "Micro  F1:  91.20%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       541\n",
      "           1       0.16      0.50      0.25        16\n",
      "\n",
      "    accuracy                           0.91       557\n",
      "   macro avg       0.57      0.71      0.60       557\n",
      "weighted avg       0.96      0.91      0.93       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[500  41]\n",
      " [  8   8]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_6' vs. 'Q3_6' ==\n",
      "Accuracy:   87.25%\n",
      "Macro F1:   85.65%\n",
      "Micro  F1:  87.25%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81       204\n",
      "           1       0.86      0.95      0.90       353\n",
      "\n",
      "    accuracy                           0.87       557\n",
      "   macro avg       0.88      0.84      0.86       557\n",
      "weighted avg       0.87      0.87      0.87       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[150  54]\n",
      " [ 17 336]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_7' vs. 'Q3_7' ==\n",
      "Accuracy:   75.22%\n",
      "Macro F1:   73.82%\n",
      "Micro  F1:  75.22%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       344\n",
      "           1       0.67      0.68      0.68       213\n",
      "\n",
      "    accuracy                           0.75       557\n",
      "   macro avg       0.74      0.74      0.74       557\n",
      "weighted avg       0.75      0.75      0.75       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[274  70]\n",
      " [ 68 145]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_1_8' vs. 'Q3_8' ==\n",
      "Accuracy:   93.18%\n",
      "Macro F1:   58.63%\n",
      "Micro  F1:  93.18%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       527\n",
      "           1       0.28      0.17      0.21        30\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.62      0.57      0.59       557\n",
      "weighted avg       0.92      0.93      0.92       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[514  13]\n",
      " [ 25   5]]\n",
      "\n",
      ">> Overall accuracy: 87.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_41_finetune_1_1 vs Q3_1': {'accuracy': 0.8833034111310593,\n",
       "  'precision_macro': 0.6400494159928122,\n",
       "  'recall_macro': 0.6531188605108055,\n",
       "  'f1_macro': 0.6461348997683578,\n",
       "  'precision_micro': 0.8833034111310593,\n",
       "  'recall_micro': 0.8833034111310593,\n",
       "  'f1_micro': 0.8833034111310593,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.94      0.93      0.94       509\\n           1       0.34      0.38      0.36        48\\n\\n    accuracy                           0.88       557\\n   macro avg       0.64      0.65      0.65       557\\nweighted avg       0.89      0.88      0.89       557\\n',\n",
       "  'confusion_matrix': array([[474,  35],\n",
       "         [ 30,  18]])},\n",
       " 'GPT_41_finetune_1_2 vs Q3_2': {'accuracy': 0.8779174147217235,\n",
       "  'precision_macro': 0.737343892780993,\n",
       "  'recall_macro': 0.7155463347164592,\n",
       "  'f1_macro': 0.7255839564133774,\n",
       "  'precision_micro': 0.8779174147217235,\n",
       "  'recall_micro': 0.8779174147217235,\n",
       "  'f1_micro': 0.8779174147217235,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.94      0.93       482\\n           1       0.55      0.49      0.52        75\\n\\n    accuracy                           0.88       557\\n   macro avg       0.74      0.72      0.73       557\\nweighted avg       0.87      0.88      0.87       557\\n',\n",
       "  'confusion_matrix': array([[452,  30],\n",
       "         [ 38,  37]])},\n",
       " 'GPT_41_finetune_1_3 vs Q3_3': {'accuracy': 0.9730700179533214,\n",
       "  'precision_macro': 0.7694134078212291,\n",
       "  'recall_macro': 0.8151960784313725,\n",
       "  'f1_macro': 0.7903335089964616,\n",
       "  'precision_micro': 0.9730700179533214,\n",
       "  'recall_micro': 0.9730700179533214,\n",
       "  'f1_micro': 0.9730700179533214,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.98      0.99       540\\n           1       0.55      0.65      0.59        17\\n\\n    accuracy                           0.97       557\\n   macro avg       0.77      0.82      0.79       557\\nweighted avg       0.98      0.97      0.97       557\\n',\n",
       "  'confusion_matrix': array([[531,   9],\n",
       "         [  6,  11]])},\n",
       " 'GPT_41_finetune_1_4 vs Q3_4': {'accuracy': 0.800718132854578,\n",
       "  'precision_macro': 0.6760427528675703,\n",
       "  'recall_macro': 0.736781206171108,\n",
       "  'f1_macro': 0.6949300569906003,\n",
       "  'precision_micro': 0.800718132854578,\n",
       "  'recall_micro': 0.800718132854578,\n",
       "  'f1_micro': 0.800718132854578,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.83      0.87       465\\n           1       0.43      0.64      0.52        92\\n\\n    accuracy                           0.80       557\\n   macro avg       0.68      0.74      0.69       557\\nweighted avg       0.84      0.80      0.82       557\\n',\n",
       "  'confusion_matrix': array([[387,  78],\n",
       "         [ 33,  59]])},\n",
       " 'GPT_41_finetune_1_5 vs Q3_5': {'accuracy': 0.9120287253141831,\n",
       "  'precision_macro': 0.573758637313193,\n",
       "  'recall_macro': 0.7121072088724585,\n",
       "  'f1_macro': 0.5997213463371709,\n",
       "  'precision_micro': 0.9120287253141831,\n",
       "  'recall_micro': 0.9120287253141831,\n",
       "  'f1_micro': 0.9120287253141831,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.92      0.95       541\\n           1       0.16      0.50      0.25        16\\n\\n    accuracy                           0.91       557\\n   macro avg       0.57      0.71      0.60       557\\nweighted avg       0.96      0.91      0.93       557\\n',\n",
       "  'confusion_matrix': array([[500,  41],\n",
       "         [  8,   8]])},\n",
       " 'GPT_41_finetune_1_6 vs Q3_6': {'accuracy': 0.8725314183123878,\n",
       "  'precision_macro': 0.8798710271764164,\n",
       "  'recall_macro': 0.843567738710215,\n",
       "  'f1_macro': 0.8565333952469227,\n",
       "  'precision_micro': 0.8725314183123878,\n",
       "  'recall_micro': 0.8725314183123878,\n",
       "  'f1_micro': 0.8725314183123878,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.90      0.74      0.81       204\\n           1       0.86      0.95      0.90       353\\n\\n    accuracy                           0.87       557\\n   macro avg       0.88      0.84      0.86       557\\nweighted avg       0.87      0.87      0.87       557\\n',\n",
       "  'confusion_matrix': array([[150,  54],\n",
       "         [ 17, 336]])},\n",
       " 'GPT_41_finetune_1_7 vs Q3_7': {'accuracy': 0.7522441651705566,\n",
       "  'precision_macro': 0.7377940976472188,\n",
       "  'recall_macro': 0.7386314008079484,\n",
       "  'f1_macro': 0.7382019563499632,\n",
       "  'precision_micro': 0.7522441651705566,\n",
       "  'recall_micro': 0.7522441651705566,\n",
       "  'f1_micro': 0.7522441651705566,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.80      0.80       344\\n           1       0.67      0.68      0.68       213\\n\\n    accuracy                           0.75       557\\n   macro avg       0.74      0.74      0.74       557\\nweighted avg       0.75      0.75      0.75       557\\n',\n",
       "  'confusion_matrix': array([[274,  70],\n",
       "         [ 68, 145]])},\n",
       " 'GPT_41_finetune_1_8 vs Q3_8': {'accuracy': 0.9317773788150808,\n",
       "  'precision_macro': 0.6156977942692228,\n",
       "  'recall_macro': 0.5709993674889311,\n",
       "  'f1_macro': 0.5863430268918074,\n",
       "  'precision_micro': 0.9317773788150808,\n",
       "  'recall_micro': 0.9317773788150808,\n",
       "  'f1_micro': 0.9317773788150808,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.98      0.96       527\\n           1       0.28      0.17      0.21        30\\n\\n    accuracy                           0.93       557\\n   macro avg       0.62      0.57      0.59       557\\nweighted avg       0.92      0.93      0.92       557\\n',\n",
       "  'confusion_matrix': array([[514,  13],\n",
       "         [ 25,   5]])},\n",
       " 'overall_accuracy': 0.8754488330341114}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_41_finetune_1,\n",
    "    predicted_cols=[\n",
    "        \"GPT_41_finetune_1_1\",\n",
    "        \"GPT_41_finetune_1_2\",\n",
    "        \"GPT_41_finetune_1_3\",\n",
    "        \"GPT_41_finetune_1_4\",\n",
    "        \"GPT_41_finetune_1_5\",\n",
    "        \"GPT_41_finetune_1_6\",\n",
    "        \"GPT_41_finetune_1_7\",\n",
    "        \"GPT_41_finetune_1_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74573292-b99d-4679-a535-54d45ab87c9b",
   "metadata": {},
   "source": [
    "# Finetune with N = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1221a1d3-26ee-4e14-8c5f-7c1d13606926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_original</th>\n",
       "      <th>GUID</th>\n",
       "      <th>Date (GMT)</th>\n",
       "      <th>URL</th>\n",
       "      <th>Post_Title</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3_1_og</th>\n",
       "      <th>Q3_2_og</th>\n",
       "      <th>Train</th>\n",
       "      <th>Q3_1</th>\n",
       "      <th>Q3_2</th>\n",
       "      <th>Q3_3</th>\n",
       "      <th>Q3_4</th>\n",
       "      <th>Q3_5</th>\n",
       "      <th>Q3_6</th>\n",
       "      <th>Q3_7</th>\n",
       "      <th>Q3_8</th>\n",
       "      <th>Q3_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>163</td>\n",
       "      <td>0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d</td>\n",
       "      <td>2018-01-31 06:08:46</td>\n",
       "      <td>https://www.politico.com/story/2018/01/31/stat...</td>\n",
       "      <td>Democrats furious over Trump's immigration rhe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>1059</td>\n",
       "      <td>33a28b82-e7c0-47b4-a637-bfaa67b6f8a8</td>\n",
       "      <td>2018-01-02 23:54:54</td>\n",
       "      <td>http://abcnews.go.com/politics/wirestory/lates...</td>\n",
       "      <td>The Latest: Trump says Dems not helping young ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "      <td>2233</td>\n",
       "      <td>2563ec73-f243-4c60-b613-e2bd9b9389bd</td>\n",
       "      <td>2018-01-10 05:44:22</td>\n",
       "      <td>http://www.breitbart.com/news/us-judge-blocks-...</td>\n",
       "      <td>US judge blocks Trump move rescinding immigran...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601</td>\n",
       "      <td>2944</td>\n",
       "      <td>f5d33307-e783-4059-a33d-0538df26f633</td>\n",
       "      <td>2018-01-10 20:38:15</td>\n",
       "      <td>http://thehill.com/homenews/senate/368354-rand...</td>\n",
       "      <td>Rand Paul: 'We don't have money to spend' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1826</td>\n",
       "      <td>8405</td>\n",
       "      <td>caac1fde-9fc9-4584-ac2a-fb524a4f355c</td>\n",
       "      <td>2018-01-04 01:05:07</td>\n",
       "      <td>https://www.yahoo.com/news/u-deportations-alle...</td>\n",
       "      <td>U.S. deportations of alleged El Salvador gang ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1206</td>\n",
       "      <td>5669</td>\n",
       "      <td>a9f52452-a990-4090-aa04-70ddb5c4063a</td>\n",
       "      <td>2018-01-09 03:12:26</td>\n",
       "      <td>http://www.cnn.com/2018/01/08/politics/john-ke...</td>\n",
       "      <td>John Kelly leading White House's immigration e...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>575</td>\n",
       "      <td>2813</td>\n",
       "      <td>e3b74e2a-9485-4a61-8db2-1fecd1cbf2a1</td>\n",
       "      <td>2018-01-12 12:42:26</td>\n",
       "      <td>https://www.yahoo.com/news/trump-rejects-senat...</td>\n",
       "      <td>Trump rejects senators' bipartisan 'Dreamer'im...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1602</td>\n",
       "      <td>7387</td>\n",
       "      <td>6f75121d-acc5-4e1f-9e0a-d674df237524</td>\n",
       "      <td>2018-01-10 08:00:00</td>\n",
       "      <td>https://www.yahoo.com/news/ice-agents-raid-7-e...</td>\n",
       "      <td>ICE Agents Raid 7-Eleven Stores In Search Of U...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>40</td>\n",
       "      <td>185</td>\n",
       "      <td>7d2614ea-829d-4a26-9f7a-d4a62354b2b8</td>\n",
       "      <td>2018-01-08 23:59:26</td>\n",
       "      <td>http://www.breitbart.com/big-government/2018/0...</td>\n",
       "      <td>Mandatory E-Verifyâ€“Trumpâ€™s Most Popular Immigr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>761</td>\n",
       "      <td>3729</td>\n",
       "      <td>0f678508-31da-4e27-a9a7-7152949d39cf</td>\n",
       "      <td>2018-01-12 23:55:28</td>\n",
       "      <td>http://abcnews.go.com/Politics/times-trump-acc...</td>\n",
       "      <td>5 times Trump was accused of making racially t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  ID_original                                  GUID  \\\n",
       "0    1927          163  0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d   \n",
       "1     221         1059  33a28b82-e7c0-47b4-a637-bfaa67b6f8a8   \n",
       "2     452         2233  2563ec73-f243-4c60-b613-e2bd9b9389bd   \n",
       "3     601         2944  f5d33307-e783-4059-a33d-0538df26f633   \n",
       "4    1826         8405  caac1fde-9fc9-4584-ac2a-fb524a4f355c   \n",
       "..    ...          ...                                   ...   \n",
       "395  1206         5669  a9f52452-a990-4090-aa04-70ddb5c4063a   \n",
       "396   575         2813  e3b74e2a-9485-4a61-8db2-1fecd1cbf2a1   \n",
       "397  1602         7387  6f75121d-acc5-4e1f-9e0a-d674df237524   \n",
       "398    40          185  7d2614ea-829d-4a26-9f7a-d4a62354b2b8   \n",
       "399   761         3729  0f678508-31da-4e27-a9a7-7152949d39cf   \n",
       "\n",
       "             Date (GMT)                                                URL  \\\n",
       "0   2018-01-31 06:08:46  https://www.politico.com/story/2018/01/31/stat...   \n",
       "1   2018-01-02 23:54:54  http://abcnews.go.com/politics/wirestory/lates...   \n",
       "2   2018-01-10 05:44:22  http://www.breitbart.com/news/us-judge-blocks-...   \n",
       "3   2018-01-10 20:38:15  http://thehill.com/homenews/senate/368354-rand...   \n",
       "4   2018-01-04 01:05:07  https://www.yahoo.com/news/u-deportations-alle...   \n",
       "..                  ...                                                ...   \n",
       "395 2018-01-09 03:12:26  http://www.cnn.com/2018/01/08/politics/john-ke...   \n",
       "396 2018-01-12 12:42:26  https://www.yahoo.com/news/trump-rejects-senat...   \n",
       "397 2018-01-10 08:00:00  https://www.yahoo.com/news/ice-agents-raid-7-e...   \n",
       "398 2018-01-08 23:59:26  http://www.breitbart.com/big-government/2018/0...   \n",
       "399 2018-01-12 23:55:28  http://abcnews.go.com/Politics/times-trump-acc...   \n",
       "\n",
       "                                            Post_Title  Q1  Q2  Q3_1_og  \\\n",
       "0    Democrats furious over Trump's immigration rhe...   1   2        6   \n",
       "1    The Latest: Trump says Dems not helping young ...   1   2        6   \n",
       "2    US judge blocks Trump move rescinding immigran...   1   2        6   \n",
       "3    Rand Paul: 'We don't have money to spend' for ...   1   2        6   \n",
       "4    U.S. deportations of alleged El Salvador gang ...   1   1        2   \n",
       "..                                                 ...  ..  ..      ...   \n",
       "395  John Kelly leading White House's immigration e...   1   2        6   \n",
       "396  Trump rejects senators' bipartisan 'Dreamer'im...   1   2        6   \n",
       "397  ICE Agents Raid 7-Eleven Stores In Search Of U...   1   1        1   \n",
       "398  Mandatory E-Verifyâ€“Trumpâ€™s Most Popular Immigr...   1   2        7   \n",
       "399  5 times Trump was accused of making racially t...   1   2        6   \n",
       "\n",
       "     Q3_2_og  Train  Q3_1  Q3_2  Q3_3  Q3_4  Q3_5  Q3_6  Q3_7  Q3_8  \\\n",
       "0         99      1     0     0     0     0     0     1     0     0   \n",
       "1         99      1     0     0     0     0     0     1     0     0   \n",
       "2         99      1     0     0     0     0     0     1     0     0   \n",
       "3          1      1     1     0     0     0     0     1     0     0   \n",
       "4         99      1     0     1     0     0     0     0     0     0   \n",
       "..       ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "395       99      1     0     0     0     0     0     1     0     0   \n",
       "396        7      1     0     0     0     0     0     1     1     0   \n",
       "397       99      1     1     0     0     0     0     0     0     0   \n",
       "398        6      1     0     0     0     0     0     1     1     0   \n",
       "399        4      1     0     0     0     1     0     1     0     0   \n",
       "\n",
       "                     Q3_clean  \n",
       "0    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "3    [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4    [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "..                        ...  \n",
       "395  [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "396  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "397  [1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "398  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "399  [0, 0, 0, 1, 0, 1, 0, 0]  \n",
       "\n",
       "[400 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finetune_df_1 = pd.read_excel(\"Data_train/train_1.xlsx\", sheet_name=0)  \n",
    "Finetune_df_2 = pd.read_excel(\"Data_train/train_2.xlsx\", sheet_name=0)  \n",
    "\n",
    "Finetune_df_2_all = pd.concat([Finetune_df_1, Finetune_df_2], axis=0, ignore_index=True)\n",
    "Finetune_df_2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20104284-1a5d-4a81-bf8b-359225f74b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_GPT_finetune_jsonl(Finetune_df_2_all, \n",
    "                        output_path=\"GPT_Finetune/train_2.jsonl\", \n",
    "                        system_prompt = prompt_GPT,\n",
    "                        input_col = [\"Post_Title\"],\n",
    "                        label_col=[\"Q3_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c96e5f-28a0-4eb0-a56c-a3c279669e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fine-tune job ftjob-1ZsfPJnuQgDfQgfetiN8tR9q\n",
      "[0s] status=validating_files\n",
      "[15s] status=validating_files\n",
      "[30s] status=validating_files\n",
      "[45s] status=validating_files\n",
      "[60s] status=validating_files\n",
      "[75s] status=validating_files\n",
      "[90s] status=validating_files\n",
      "[105s] status=validating_files\n",
      "[120s] status=validating_files\n",
      "[135s] status=validating_files\n",
      "[150s] status=validating_files\n",
      "[165s] status=validating_files\n",
      "[180s] status=running\n",
      "[195s] status=running\n",
      "[210s] status=running\n",
      "[225s] status=running\n",
      "[240s] status=running\n",
      "[255s] status=running\n",
      "[270s] status=running\n",
      "[285s] status=running\n",
      "[300s] status=running\n",
      "[315s] status=running\n",
      "[330s] status=running\n",
      "[345s] status=running\n",
      "[360s] status=running\n",
      "[375s] status=running\n",
      "[390s] status=running\n",
      "[405s] status=running\n",
      "[420s] status=running\n",
      "[435s] status=running\n",
      "[450s] status=running\n",
      "[465s] status=running\n",
      "[480s] status=running\n",
      "[495s] status=running\n",
      "[510s] status=running\n",
      "[525s] status=running\n",
      "[540s] status=running\n",
      "[555s] status=running\n",
      "[570s] status=running\n",
      "[585s] status=running\n",
      "[600s] status=running\n",
      "[615s] status=running\n",
      "[630s] status=running\n",
      "[645s] status=running\n",
      "[660s] status=running\n",
      "[675s] status=running\n",
      "[690s] status=running\n",
      "[705s] status=running\n",
      "[720s] status=running\n",
      "[735s] status=running\n",
      "[750s] status=running\n",
      "[765s] status=running\n",
      "[780s] status=running\n",
      "[795s] status=running\n",
      "[810s] status=running\n",
      "[825s] status=running\n",
      "[840s] status=running\n",
      "[855s] status=running\n",
      "[870s] status=running\n",
      "[885s] status=running\n",
      "[900s] status=running\n",
      "[915s] status=running\n",
      "[930s] status=running\n",
      "[945s] status=running\n",
      "[960s] status=running\n",
      "[975s] status=running\n",
      "[990s] status=running\n",
      "[1005s] status=running\n",
      "[1020s] status=running\n",
      "[1035s] status=running\n",
      "[1050s] status=running\n",
      "[1065s] status=running\n",
      "[1080s] status=running\n",
      "[1095s] status=running\n",
      "[1110s] status=running\n",
      "[1125s] status=running\n",
      "[1140s] status=running\n",
      "[1155s] status=running\n",
      "[1170s] status=running\n",
      "[1185s] status=running\n",
      "[1200s] status=running\n",
      "[1215s] status=running\n",
      "[1230s] status=running\n",
      "[1245s] status=running\n",
      "[1260s] status=running\n",
      "[1275s] status=running\n",
      "[1290s] status=running\n",
      "[1305s] status=running\n",
      "[1320s] status=running\n",
      "[1335s] status=running\n",
      "[1350s] status=running\n",
      "[1365s] status=running\n",
      "[1380s] status=running\n",
      "[1395s] status=running\n",
      "[1410s] status=running\n",
      "[1425s] status=running\n",
      "[1440s] status=running\n",
      "[1455s] status=running\n",
      "[1470s] status=running\n",
      "[1485s] status=running\n",
      "[1500s] status=running\n",
      "[1515s] status=running\n",
      "[1530s] status=running\n",
      "[1545s] status=running\n",
      "[1560s] status=running\n",
      "[1575s] status=running\n",
      "[1590s] status=running\n",
      "[1605s] status=running\n",
      "[1620s] status=running\n",
      "[1635s] status=running\n",
      "[1650s] status=running\n",
      "[1665s] status=running\n",
      "[1680s] status=running\n",
      "[1695s] status=running\n",
      "[1710s] status=running\n",
      "[1725s] status=running\n",
      "[1740s] status=running\n",
      "[1755s] status=running\n",
      "[1770s] status=running\n",
      "[1785s] status=running\n",
      "[1800s] status=running\n",
      "[1815s] status=running\n",
      "[1830s] status=running\n",
      "[1845s] status=running\n",
      "[1860s] status=running\n",
      "[1875s] status=running\n",
      "[1890s] status=running\n",
      "[1905s] status=running\n",
      "[1920s] status=running\n",
      "[1935s] status=running\n",
      "[1950s] status=running\n",
      "[1965s] status=running\n",
      "[1980s] status=running\n",
      "[1995s] status=running\n",
      "[2010s] status=running\n",
      "[2025s] status=running\n",
      "[2040s] status=running\n",
      "[2055s] status=running\n",
      "[2070s] status=running\n",
      "[2085s] status=running\n",
      "[2100s] status=running\n",
      "[2115s] status=running\n",
      "[2130s] status=running\n",
      "[2145s] status=running\n",
      "[2160s] status=running\n",
      "[2175s] status=running\n",
      "[2190s] status=running\n",
      "[2205s] status=running\n",
      "[2220s] status=running\n",
      "[2235s] status=running\n",
      "[2250s] status=running\n",
      "[2265s] status=running\n",
      "[2280s] status=running\n",
      "[2295s] status=running\n",
      "[2310s] status=running\n",
      "[2325s] status=running\n",
      "[2340s] status=running\n",
      "[2355s] status=running\n",
      "[2370s] status=running\n",
      "[2385s] status=running\n",
      "[2400s] status=running\n",
      "[2415s] status=running\n",
      "[2430s] status=running\n",
      "[2445s] status=running\n",
      "[2460s] status=running\n",
      "[2475s] status=running\n",
      "[2490s] status=running\n",
      "[2505s] status=running\n",
      "[2520s] status=running\n",
      "[2535s] status=running\n",
      "[2550s] status=running\n",
      "[2565s] status=running\n",
      "[2580s] status=running\n",
      "[2595s] status=running\n",
      "[2610s] status=running\n",
      "[2625s] status=running\n",
      "[2640s] status=running\n",
      "[2655s] status=running\n",
      "[2670s] status=running\n",
      "[2685s] status=running\n",
      "[2700s] status=running\n",
      "[2715s] status=running\n",
      "[2730s] status=running\n",
      "[2745s] status=running\n",
      "[2760s] status=running\n",
      "[2775s] status=running\n",
      "[2790s] status=running\n",
      "[2805s] status=running\n",
      "[2820s] status=running\n",
      "[2835s] status=running\n",
      "[2850s] status=running\n",
      "[2865s] status=running\n",
      "[2880s] status=running\n",
      "[2895s] status=running\n",
      "[2910s] status=running\n",
      "[2925s] status=running\n",
      "[2940s] status=running\n",
      "[2955s] status=running\n",
      "[2970s] status=running\n",
      "[2985s] status=running\n",
      "[3000s] status=running\n",
      "[3015s] status=running\n",
      "[3030s] status=running\n",
      "[3045s] status=running\n",
      "[3060s] status=running\n",
      "[3075s] status=running\n",
      "[3090s] status=running\n",
      "[3105s] status=running\n",
      "[3120s] status=running\n",
      "[3135s] status=running\n",
      "[3150s] status=running\n",
      "[3165s] status=running\n",
      "[3180s] status=running\n",
      "[3195s] status=running\n",
      "[3210s] status=running\n",
      "[3225s] status=running\n",
      "[3240s] status=running\n",
      "[3255s] status=running\n",
      "[3270s] status=running\n",
      "[3285s] status=running\n",
      "[3300s] status=running\n",
      "[3315s] status=running\n",
      "[3330s] status=running\n",
      "[3345s] status=running\n",
      "[3360s] status=running\n",
      "[3375s] status=running\n",
      "[3390s] status=running\n",
      "[3405s] status=running\n",
      "[3420s] status=running\n",
      "[3435s] status=running\n",
      "[3450s] status=running\n",
      "[3465s] status=running\n",
      "[3480s] status=running\n",
      "[3495s] status=running\n",
      "[3510s] status=running\n",
      "[3525s] status=running\n",
      "[3540s] status=running\n",
      "[3555s] status=running\n",
      "[3570s] status=running\n",
      "[3585s] status=running\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Job ftjob-1ZsfPJnuQgDfQgfetiN8tR9q didnâ€™t finish within 3600s",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune GPT-4o\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m GPT_finetune_2 \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_GPT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPT_Finetune/train_2.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4.1-mini-2025-04-14\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate_multiplier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/labelgenius/LabelGenius.py:1144\u001b[0m, in \u001b[0;36mfinetune_GPT\u001b[0;34m(training_file_path, model, method_type, hyperparameters, poll_interval, max_wait_time, api_key)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(poll_interval)\n\u001b[1;32m   1142\u001b[0m     elapsed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll_interval\n\u001b[0;32m-> 1144\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m didnâ€™t finish within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_wait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Job ftjob-1ZsfPJnuQgDfQgfetiN8tR9q didnâ€™t finish within 3600s"
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-4o\n",
    "GPT_finetune_2 = finetune_GPT(\n",
    "    training_file_path=\"GPT_Finetune/train_2.jsonl\",\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",  \n",
    "    hyperparameters={\"batch_size\":8, \"learning_rate_multiplier\":0.01},\n",
    "    api_key= api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "485dc9b6-8b5a-498b-8af3-8cb4f3311138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 19:46:08.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-14 19:46:08.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-14 19:46:08.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "Classifying text_class: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 [20:58<00:00,  2.26s/item]\n"
     ]
    }
   ],
   "source": [
    "# Classify with fineâ€‘tuned  model\n",
    "GPT_41_finetune_2 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category = category_GPT,\n",
    "    prompt = prompt_GPT,\n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model = \"ft:gpt-4.1-mini-2025-04-14:jcs-research::CQgyNjuW\",\n",
    "    api_key = api_key,\n",
    "    temperature = 0.8,\n",
    "    mode = \"text\",\n",
    "    output_column_name=\"GPT_41_finetune_2\",\n",
    "    num_themes = 8,\n",
    "    num_votes = 1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_41_finetune_2.to_csv(\"Result/00_GPT_41_finetune_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8110e520-b9dd-4fa9-9120-cdb9281d1ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_41_finetune_2_1' vs. 'Q3_1' ==\n",
      "Accuracy:   89.77%\n",
      "Macro F1:   66.56%\n",
      "Micro  F1:  89.77%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       509\n",
      "           1       0.40      0.38      0.39        48\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.67      0.66      0.67       557\n",
      "weighted avg       0.89      0.90      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[482  27]\n",
      " [ 30  18]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_2' vs. 'Q3_2' ==\n",
      "Accuracy:   88.33%\n",
      "Macro F1:   73.61%\n",
      "Micro  F1:  88.33%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       482\n",
      "           1       0.58      0.51      0.54        75\n",
      "\n",
      "    accuracy                           0.88       557\n",
      "   macro avg       0.75      0.72      0.74       557\n",
      "weighted avg       0.88      0.88      0.88       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[454  28]\n",
      " [ 37  38]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_3' vs. 'Q3_3' ==\n",
      "Accuracy:   97.31%\n",
      "Macro F1:   77.88%\n",
      "Micro  F1:  97.31%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       540\n",
      "           1       0.56      0.59      0.57        17\n",
      "\n",
      "    accuracy                           0.97       557\n",
      "   macro avg       0.77      0.79      0.78       557\n",
      "weighted avg       0.97      0.97      0.97       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[532   8]\n",
      " [  7  10]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_4' vs. 'Q3_4' ==\n",
      "Accuracy:   82.59%\n",
      "Macro F1:   71.44%\n",
      "Micro  F1:  82.59%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       465\n",
      "           1       0.48      0.61      0.54        92\n",
      "\n",
      "    accuracy                           0.83       557\n",
      "   macro avg       0.70      0.74      0.71       557\n",
      "weighted avg       0.85      0.83      0.83       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[404  61]\n",
      " [ 36  56]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_5' vs. 'Q3_5' ==\n",
      "Accuracy:   94.43%\n",
      "Macro F1:   66.91%\n",
      "Micro  F1:  94.43%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       541\n",
      "           1       0.27      0.56      0.37        16\n",
      "\n",
      "    accuracy                           0.94       557\n",
      "   macro avg       0.63      0.76      0.67       557\n",
      "weighted avg       0.97      0.94      0.95       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[517  24]\n",
      " [  7   9]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_6' vs. 'Q3_6' ==\n",
      "Accuracy:   87.61%\n",
      "Macro F1:   86.44%\n",
      "Micro  F1:  87.61%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       204\n",
      "           1       0.89      0.92      0.90       353\n",
      "\n",
      "    accuracy                           0.88       557\n",
      "   macro avg       0.87      0.86      0.86       557\n",
      "weighted avg       0.88      0.88      0.88       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[162  42]\n",
      " [ 27 326]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_7' vs. 'Q3_7' ==\n",
      "Accuracy:   73.79%\n",
      "Macro F1:   72.10%\n",
      "Micro  F1:  73.79%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       344\n",
      "           1       0.66      0.64      0.65       213\n",
      "\n",
      "    accuracy                           0.74       557\n",
      "   macro avg       0.72      0.72      0.72       557\n",
      "weighted avg       0.74      0.74      0.74       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[274  70]\n",
      " [ 76 137]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_2_8' vs. 'Q3_8' ==\n",
      "Accuracy:   93.00%\n",
      "Macro F1:   56.68%\n",
      "Micro  F1:  93.00%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       527\n",
      "           1       0.24      0.13      0.17        30\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.59      0.55      0.57       557\n",
      "weighted avg       0.91      0.93      0.92       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[514  13]\n",
      " [ 26   4]]\n",
      "\n",
      ">> Overall accuracy: 88.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_41_finetune_2_1 vs Q3_1': {'accuracy': 0.8976660682226212,\n",
       "  'precision_macro': 0.670703125,\n",
       "  'recall_macro': 0.6609774066797642,\n",
       "  'f1_macro': 0.6656345771065685,\n",
       "  'precision_micro': 0.8976660682226212,\n",
       "  'recall_micro': 0.8976660682226212,\n",
       "  'f1_micro': 0.8976660682226212,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.94      0.95      0.94       509\\n           1       0.40      0.38      0.39        48\\n\\n    accuracy                           0.90       557\\n   macro avg       0.67      0.66      0.67       557\\nweighted avg       0.89      0.90      0.90       557\\n',\n",
       "  'confusion_matrix': array([[482,  27],\n",
       "         [ 30,  18]])},\n",
       " 'GPT_41_finetune_2_2 vs Q3_2': {'accuracy': 0.8833034111310593,\n",
       "  'precision_macro': 0.7502005801394804,\n",
       "  'recall_macro': 0.7242876901798063,\n",
       "  'f1_macro': 0.7361016961506782,\n",
       "  'precision_micro': 0.8833034111310593,\n",
       "  'recall_micro': 0.8833034111310593,\n",
       "  'f1_micro': 0.8833034111310593,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.94      0.93       482\\n           1       0.58      0.51      0.54        75\\n\\n    accuracy                           0.88       557\\n   macro avg       0.75      0.72      0.74       557\\nweighted avg       0.88      0.88      0.88       557\\n',\n",
       "  'confusion_matrix': array([[454,  28],\n",
       "         [ 37,  38]])},\n",
       " 'GPT_41_finetune_2_3 vs Q3_3': {'accuracy': 0.9730700179533214,\n",
       "  'precision_macro': 0.7712842712842713,\n",
       "  'recall_macro': 0.7867102396514161,\n",
       "  'f1_macro': 0.7787634052694293,\n",
       "  'precision_micro': 0.9730700179533214,\n",
       "  'recall_micro': 0.9730700179533214,\n",
       "  'f1_micro': 0.9730700179533214,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99       540\\n           1       0.56      0.59      0.57        17\\n\\n    accuracy                           0.97       557\\n   macro avg       0.77      0.79      0.78       557\\nweighted avg       0.97      0.97      0.97       557\\n',\n",
       "  'confusion_matrix': array([[532,   8],\n",
       "         [  7,  10]])},\n",
       " 'GPT_41_finetune_2_4 vs Q3_4': {'accuracy': 0.8258527827648114,\n",
       "  'precision_macro': 0.6984071484071485,\n",
       "  'recall_macro': 0.7387564282374941,\n",
       "  'f1_macro': 0.714351423511063,\n",
       "  'precision_micro': 0.8258527827648114,\n",
       "  'recall_micro': 0.8258527827648114,\n",
       "  'f1_micro': 0.8258527827648114,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.87      0.89       465\\n           1       0.48      0.61      0.54        92\\n\\n    accuracy                           0.83       557\\n   macro avg       0.70      0.74      0.71       557\\nweighted avg       0.85      0.83      0.83       557\\n',\n",
       "  'confusion_matrix': array([[404,  61],\n",
       "         [ 36,  56]])},\n",
       " 'GPT_41_finetune_2_5 vs Q3_5': {'accuracy': 0.9443447037701975,\n",
       "  'precision_macro': 0.6296842470506592,\n",
       "  'recall_macro': 0.7590688539741219,\n",
       "  'f1_macro': 0.6691194787774265,\n",
       "  'precision_micro': 0.9443447037701975,\n",
       "  'recall_micro': 0.9443447037701975,\n",
       "  'f1_micro': 0.9443447037701975,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.96      0.97       541\\n           1       0.27      0.56      0.37        16\\n\\n    accuracy                           0.94       557\\n   macro avg       0.63      0.76      0.67       557\\nweighted avg       0.97      0.94      0.95       557\\n',\n",
       "  'confusion_matrix': array([[517,  24],\n",
       "         [  7,   9]])},\n",
       " 'GPT_41_finetune_2_6 vs Q3_6': {'accuracy': 0.8761220825852782,\n",
       "  'precision_macro': 0.8715062111801242,\n",
       "  'recall_macro': 0.8588151974670888,\n",
       "  'f1_macro': 0.8643635324136325,\n",
       "  'precision_micro': 0.8761220825852782,\n",
       "  'recall_micro': 0.8761220825852782,\n",
       "  'f1_micro': 0.8761220825852782,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.86      0.79      0.82       204\\n           1       0.89      0.92      0.90       353\\n\\n    accuracy                           0.88       557\\n   macro avg       0.87      0.86      0.86       557\\nweighted avg       0.88      0.88      0.88       557\\n',\n",
       "  'confusion_matrix': array([[162,  42],\n",
       "         [ 27, 326]])},\n",
       " 'GPT_41_finetune_2_7 vs Q3_7': {'accuracy': 0.7378815080789947,\n",
       "  'precision_macro': 0.7223464458247066,\n",
       "  'recall_macro': 0.7198520580849437,\n",
       "  'f1_macro': 0.72100315630575,\n",
       "  'precision_micro': 0.7378815080789947,\n",
       "  'recall_micro': 0.7378815080789947,\n",
       "  'f1_micro': 0.7378815080789947,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.78      0.80      0.79       344\\n           1       0.66      0.64      0.65       213\\n\\n    accuracy                           0.74       557\\n   macro avg       0.72      0.72      0.72       557\\nweighted avg       0.74      0.74      0.74       557\\n',\n",
       "  'confusion_matrix': array([[274,  70],\n",
       "         [ 76, 137]])},\n",
       " 'GPT_41_finetune_2_8 vs Q3_8': {'accuracy': 0.9299820466786356,\n",
       "  'precision_macro': 0.5935729847494553,\n",
       "  'recall_macro': 0.5543327008222644,\n",
       "  'f1_macro': 0.5668308440846278,\n",
       "  'precision_micro': 0.9299820466786356,\n",
       "  'recall_micro': 0.9299820466786356,\n",
       "  'f1_micro': 0.9299820466786356,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.98      0.96       527\\n           1       0.24      0.13      0.17        30\\n\\n    accuracy                           0.93       557\\n   macro avg       0.59      0.55      0.57       557\\nweighted avg       0.91      0.93      0.92       557\\n',\n",
       "  'confusion_matrix': array([[514,  13],\n",
       "         [ 26,   4]])},\n",
       " 'overall_accuracy': 0.8835278276481149}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_41_finetune_2,\n",
    "    predicted_cols=[\n",
    "        \"GPT_41_finetune_2_1\",\n",
    "        \"GPT_41_finetune_2_2\",\n",
    "        \"GPT_41_finetune_2_3\",\n",
    "        \"GPT_41_finetune_2_4\",\n",
    "        \"GPT_41_finetune_2_5\",\n",
    "        \"GPT_41_finetune_2_6\",\n",
    "        \"GPT_41_finetune_2_7\",\n",
    "        \"GPT_41_finetune_2_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f745ee8-bff5-47ed-8b29-e9a8478e1444",
   "metadata": {},
   "source": [
    "# Finetune with N = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "986f7158-6cf4-4965-b175-02b46085eaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_original</th>\n",
       "      <th>GUID</th>\n",
       "      <th>Date (GMT)</th>\n",
       "      <th>URL</th>\n",
       "      <th>Post_Title</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3_1_og</th>\n",
       "      <th>Q3_2_og</th>\n",
       "      <th>Train</th>\n",
       "      <th>Q3_1</th>\n",
       "      <th>Q3_2</th>\n",
       "      <th>Q3_3</th>\n",
       "      <th>Q3_4</th>\n",
       "      <th>Q3_5</th>\n",
       "      <th>Q3_6</th>\n",
       "      <th>Q3_7</th>\n",
       "      <th>Q3_8</th>\n",
       "      <th>Q3_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>163</td>\n",
       "      <td>0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d</td>\n",
       "      <td>2018-01-31 06:08:46</td>\n",
       "      <td>https://www.politico.com/story/2018/01/31/stat...</td>\n",
       "      <td>Democrats furious over Trump's immigration rhe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>1059</td>\n",
       "      <td>33a28b82-e7c0-47b4-a637-bfaa67b6f8a8</td>\n",
       "      <td>2018-01-02 23:54:54</td>\n",
       "      <td>http://abcnews.go.com/politics/wirestory/lates...</td>\n",
       "      <td>The Latest: Trump says Dems not helping young ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "      <td>2233</td>\n",
       "      <td>2563ec73-f243-4c60-b613-e2bd9b9389bd</td>\n",
       "      <td>2018-01-10 05:44:22</td>\n",
       "      <td>http://www.breitbart.com/news/us-judge-blocks-...</td>\n",
       "      <td>US judge blocks Trump move rescinding immigran...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601</td>\n",
       "      <td>2944</td>\n",
       "      <td>f5d33307-e783-4059-a33d-0538df26f633</td>\n",
       "      <td>2018-01-10 20:38:15</td>\n",
       "      <td>http://thehill.com/homenews/senate/368354-rand...</td>\n",
       "      <td>Rand Paul: 'We don't have money to spend' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1826</td>\n",
       "      <td>8405</td>\n",
       "      <td>caac1fde-9fc9-4584-ac2a-fb524a4f355c</td>\n",
       "      <td>2018-01-04 01:05:07</td>\n",
       "      <td>https://www.yahoo.com/news/u-deportations-alle...</td>\n",
       "      <td>U.S. deportations of alleged El Salvador gang ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1722</td>\n",
       "      <td>7947</td>\n",
       "      <td>4a3a26aa-33b2-4baf-82b7-f843e008d4a4</td>\n",
       "      <td>2018-01-06 14:01:55</td>\n",
       "      <td>http://thehill.com/homenews/administration/367...</td>\n",
       "      <td>Warren rips Trump over immigration demands: 'D...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>420</td>\n",
       "      <td>2026</td>\n",
       "      <td>e0125f37-8a12-4e24-9d50-8c55289e306e</td>\n",
       "      <td>2018-01-09 17:16:46</td>\n",
       "      <td>https://www.yahoo.com/news/m/2c7a8f6d-bc8b-3eb...</td>\n",
       "      <td>Trumpâ€™s Mass Deportation of Salvadorans Should...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>407</td>\n",
       "      <td>1938</td>\n",
       "      <td>64b509cc-eb7a-49a5-84cb-fc981727285b</td>\n",
       "      <td>2018-01-05 00:16:07</td>\n",
       "      <td>https://www.washingtonpost.com/politics/congre...</td>\n",
       "      <td>Trump, GOP senators sound hopeful on immigrati...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1541</td>\n",
       "      <td>7140</td>\n",
       "      <td>3454dcf9-82b1-48e1-95b5-14aa45b42d9f</td>\n",
       "      <td>2018-01-06 17:46:29</td>\n",
       "      <td>https://www.yahoo.com/news/m/0900e309-d149-344...</td>\n",
       "      <td>Trump administration wants $18B to build 'big,...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1632</td>\n",
       "      <td>7550</td>\n",
       "      <td>e1c3429e-2723-42a8-81da-defc1942e281</td>\n",
       "      <td>2018-01-14 05:00:00</td>\n",
       "      <td>https://www.yahoo.com/news/m/2033ef2c-411c-335...</td>\n",
       "      <td>â€˜No more Lotteries!,â€™ Donald Trump says in twe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  ID_original                                  GUID  \\\n",
       "0    1927          163  0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d   \n",
       "1     221         1059  33a28b82-e7c0-47b4-a637-bfaa67b6f8a8   \n",
       "2     452         2233  2563ec73-f243-4c60-b613-e2bd9b9389bd   \n",
       "3     601         2944  f5d33307-e783-4059-a33d-0538df26f633   \n",
       "4    1826         8405  caac1fde-9fc9-4584-ac2a-fb524a4f355c   \n",
       "..    ...          ...                                   ...   \n",
       "595  1722         7947  4a3a26aa-33b2-4baf-82b7-f843e008d4a4   \n",
       "596   420         2026  e0125f37-8a12-4e24-9d50-8c55289e306e   \n",
       "597   407         1938  64b509cc-eb7a-49a5-84cb-fc981727285b   \n",
       "598  1541         7140  3454dcf9-82b1-48e1-95b5-14aa45b42d9f   \n",
       "599  1632         7550  e1c3429e-2723-42a8-81da-defc1942e281   \n",
       "\n",
       "             Date (GMT)                                                URL  \\\n",
       "0   2018-01-31 06:08:46  https://www.politico.com/story/2018/01/31/stat...   \n",
       "1   2018-01-02 23:54:54  http://abcnews.go.com/politics/wirestory/lates...   \n",
       "2   2018-01-10 05:44:22  http://www.breitbart.com/news/us-judge-blocks-...   \n",
       "3   2018-01-10 20:38:15  http://thehill.com/homenews/senate/368354-rand...   \n",
       "4   2018-01-04 01:05:07  https://www.yahoo.com/news/u-deportations-alle...   \n",
       "..                  ...                                                ...   \n",
       "595 2018-01-06 14:01:55  http://thehill.com/homenews/administration/367...   \n",
       "596 2018-01-09 17:16:46  https://www.yahoo.com/news/m/2c7a8f6d-bc8b-3eb...   \n",
       "597 2018-01-05 00:16:07  https://www.washingtonpost.com/politics/congre...   \n",
       "598 2018-01-06 17:46:29  https://www.yahoo.com/news/m/0900e309-d149-344...   \n",
       "599 2018-01-14 05:00:00  https://www.yahoo.com/news/m/2033ef2c-411c-335...   \n",
       "\n",
       "                                            Post_Title  Q1  Q2  Q3_1_og  \\\n",
       "0    Democrats furious over Trump's immigration rhe...   1   2        6   \n",
       "1    The Latest: Trump says Dems not helping young ...   1   2        6   \n",
       "2    US judge blocks Trump move rescinding immigran...   1   2        6   \n",
       "3    Rand Paul: 'We don't have money to spend' for ...   1   2        6   \n",
       "4    U.S. deportations of alleged El Salvador gang ...   1   1        2   \n",
       "..                                                 ...  ..  ..      ...   \n",
       "595  Warren rips Trump over immigration demands: 'D...   1   2        6   \n",
       "596  Trumpâ€™s Mass Deportation of Salvadorans Should...   1   2        6   \n",
       "597  Trump, GOP senators sound hopeful on immigrati...   1   2        6   \n",
       "598  Trump administration wants $18B to build 'big,...   1   2        6   \n",
       "599  â€˜No more Lotteries!,â€™ Donald Trump says in twe...   1   2        7   \n",
       "\n",
       "     Q3_2_og  Train  Q3_1  Q3_2  Q3_3  Q3_4  Q3_5  Q3_6  Q3_7  Q3_8  \\\n",
       "0         99      1     0     0     0     0     0     1     0     0   \n",
       "1         99      1     0     0     0     0     0     1     0     0   \n",
       "2         99      1     0     0     0     0     0     1     0     0   \n",
       "3          1      1     1     0     0     0     0     1     0     0   \n",
       "4         99      1     0     1     0     0     0     0     0     0   \n",
       "..       ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "595        4      1     0     0     0     1     0     1     0     0   \n",
       "596        4      1     0     0     0     1     0     1     0     0   \n",
       "597        7      1     0     0     0     0     0     1     1     0   \n",
       "598        1      1     1     0     0     0     0     1     0     0   \n",
       "599        6      1     0     0     0     0     0     1     1     0   \n",
       "\n",
       "                     Q3_clean  \n",
       "0    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "3    [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4    [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "..                        ...  \n",
       "595  [0, 0, 0, 1, 0, 1, 0, 0]  \n",
       "596  [0, 0, 0, 1, 0, 1, 0, 0]  \n",
       "597  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "598  [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "599  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "\n",
       "[600 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finetune_df_1 = pd.read_excel(\"Data_train/train_1.xlsx\", sheet_name=0)\n",
    "Finetune_df_2 = pd.read_excel(\"Data_train/train_2.xlsx\", sheet_name=0)\n",
    "Finetune_df_3 = pd.read_excel(\"Data_train/train_3.xlsx\", sheet_name=0)\n",
    "\n",
    "# Concatenate all three DataFrames row-wise\n",
    "Finetune_df_3_all = pd.concat([Finetune_df_1, Finetune_df_2, Finetune_df_3], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "Finetune_df_3_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57e719a4-2595-42f5-a97b-5b3bc81f67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_GPT_finetune_jsonl(Finetune_df_3_all, \n",
    "                        output_path=\"GPT_Finetune/train_3.jsonl\", \n",
    "                        system_prompt = prompt_GPT,\n",
    "                        input_col = [\"Post_Title\"],\n",
    "                        label_col=[\"Q3_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47a0e00f-0377-4330-b86a-4dfbae1ca1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fine-tune job ftjob-uw6flmM1l1kYKoTdMaoYYVdG\n",
      "[0s] status=validating_files\n",
      "[15s] status=validating_files\n",
      "[30s] status=validating_files\n",
      "[45s] status=validating_files\n",
      "[60s] status=validating_files\n",
      "[75s] status=validating_files\n",
      "[90s] status=validating_files\n",
      "[105s] status=validating_files\n",
      "[120s] status=validating_files\n",
      "[135s] status=validating_files\n",
      "[150s] status=running\n",
      "[165s] status=running\n",
      "[180s] status=running\n",
      "[195s] status=running\n",
      "[210s] status=running\n",
      "[225s] status=running\n",
      "[240s] status=running\n",
      "[255s] status=running\n",
      "[270s] status=running\n",
      "[285s] status=running\n",
      "[300s] status=running\n",
      "[315s] status=running\n",
      "[330s] status=running\n",
      "[345s] status=running\n",
      "[360s] status=running\n",
      "[375s] status=running\n",
      "[390s] status=running\n",
      "[405s] status=running\n",
      "[420s] status=running\n",
      "[435s] status=running\n",
      "[450s] status=running\n",
      "[465s] status=running\n",
      "[480s] status=running\n",
      "[495s] status=running\n",
      "[510s] status=running\n",
      "[525s] status=running\n",
      "[540s] status=running\n",
      "[555s] status=running\n",
      "[570s] status=running\n",
      "[585s] status=running\n",
      "[600s] status=running\n",
      "[615s] status=running\n",
      "[630s] status=running\n",
      "[645s] status=running\n",
      "[660s] status=running\n",
      "[675s] status=running\n",
      "[690s] status=running\n",
      "[705s] status=running\n",
      "[720s] status=running\n",
      "[735s] status=running\n",
      "[750s] status=running\n",
      "[765s] status=running\n",
      "[780s] status=running\n",
      "[795s] status=running\n",
      "[810s] status=running\n",
      "[825s] status=running\n",
      "[840s] status=running\n",
      "[855s] status=running\n",
      "[870s] status=running\n",
      "[885s] status=running\n",
      "[900s] status=running\n",
      "[915s] status=running\n",
      "[930s] status=running\n",
      "[945s] status=running\n",
      "[960s] status=running\n",
      "[975s] status=running\n",
      "[990s] status=running\n",
      "[1005s] status=running\n",
      "[1020s] status=running\n",
      "[1035s] status=running\n",
      "[1050s] status=running\n",
      "[1065s] status=running\n",
      "[1080s] status=running\n",
      "[1095s] status=running\n",
      "[1110s] status=running\n",
      "[1125s] status=running\n",
      "[1140s] status=running\n",
      "[1155s] status=running\n",
      "[1170s] status=running\n",
      "[1185s] status=running\n",
      "[1200s] status=running\n",
      "[1215s] status=running\n",
      "[1230s] status=running\n",
      "[1245s] status=running\n",
      "[1260s] status=running\n",
      "[1275s] status=running\n",
      "[1290s] status=running\n",
      "[1305s] status=running\n",
      "[1320s] status=running\n",
      "[1335s] status=running\n",
      "[1350s] status=running\n",
      "[1365s] status=running\n",
      "[1380s] status=running\n",
      "[1395s] status=running\n",
      "[1410s] status=running\n",
      "[1425s] status=running\n",
      "[1440s] status=running\n",
      "[1455s] status=running\n",
      "[1470s] status=running\n",
      "[1485s] status=running\n",
      "[1500s] status=running\n",
      "[1515s] status=running\n",
      "[1530s] status=running\n",
      "[1545s] status=running\n",
      "[1560s] status=succeeded\n",
      "âœ… succeeded: ft:gpt-4.1-mini-2025-04-14:jcs-research::CQkBTsNI\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-4o\n",
    "GPT_finetune_3 = finetune_GPT(\n",
    "    training_file_path=\"GPT_Finetune/train_3.jsonl\",\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",  \n",
    "    hyperparameters={\"batch_size\":8, \"learning_rate_multiplier\":0.01},\n",
    "    api_key= api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d9da292-5a00-4bb1-b02a-79daeb1c6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 21:18:29.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-14 21:18:29.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-14 21:18:29.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "Classifying text_class: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 [21:03<00:00,  2.27s/item]\n"
     ]
    }
   ],
   "source": [
    "# Classify with fineâ€‘tuned  model\n",
    "GPT_41_finetune_3 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category = category_GPT,\n",
    "    prompt = prompt_GPT,\n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model = \"ft:gpt-4.1-mini-2025-04-14:jcs-research::CQkBTsNI\",\n",
    "    api_key = api_key,\n",
    "    temperature = 0.8,\n",
    "    mode = \"text\",\n",
    "    output_column_name=\"GPT_41_finetune_3\",\n",
    "    num_themes = 8,\n",
    "    num_votes = 1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_41_finetune_3.to_csv(\"Result/00_GPT_41_finetune_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68ed487a-df62-4ead-bc3b-de6dea1521a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_41_finetune_3_1' vs. 'Q3_1' ==\n",
      "Accuracy:   90.13%\n",
      "Macro F1:   68.35%\n",
      "Micro  F1:  90.13%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       509\n",
      "           1       0.43      0.42      0.42        48\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.69      0.68      0.68       557\n",
      "weighted avg       0.90      0.90      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[482  27]\n",
      " [ 28  20]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_2' vs. 'Q3_2' ==\n",
      "Accuracy:   88.33%\n",
      "Macro F1:   73.29%\n",
      "Micro  F1:  88.33%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       482\n",
      "           1       0.58      0.49      0.53        75\n",
      "\n",
      "    accuracy                           0.88       557\n",
      "   macro avg       0.75      0.72      0.73       557\n",
      "weighted avg       0.88      0.88      0.88       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[455  27]\n",
      " [ 38  37]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_3' vs. 'Q3_3' ==\n",
      "Accuracy:   97.31%\n",
      "Macro F1:   79.03%\n",
      "Micro  F1:  97.31%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       540\n",
      "           1       0.55      0.65      0.59        17\n",
      "\n",
      "    accuracy                           0.97       557\n",
      "   macro avg       0.77      0.82      0.79       557\n",
      "weighted avg       0.98      0.97      0.97       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[531   9]\n",
      " [  6  11]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_4' vs. 'Q3_4' ==\n",
      "Accuracy:   81.87%\n",
      "Macro F1:   71.10%\n",
      "Micro  F1:  81.87%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       465\n",
      "           1       0.46      0.63      0.53        92\n",
      "\n",
      "    accuracy                           0.82       557\n",
      "   macro avg       0.69      0.74      0.71       557\n",
      "weighted avg       0.85      0.82      0.83       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[398  67]\n",
      " [ 34  58]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_5' vs. 'Q3_5' ==\n",
      "Accuracy:   91.92%\n",
      "Macro F1:   58.40%\n",
      "Micro  F1:  91.92%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       541\n",
      "           1       0.15      0.38      0.21        16\n",
      "\n",
      "    accuracy                           0.92       557\n",
      "   macro avg       0.56      0.66      0.58       557\n",
      "weighted avg       0.96      0.92      0.94       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[506  35]\n",
      " [ 10   6]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_6' vs. 'Q3_6' ==\n",
      "Accuracy:   84.74%\n",
      "Macro F1:   83.55%\n",
      "Micro  F1:  84.74%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       204\n",
      "           1       0.88      0.88      0.88       353\n",
      "\n",
      "    accuracy                           0.85       557\n",
      "   macro avg       0.84      0.84      0.84       557\n",
      "weighted avg       0.85      0.85      0.85       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[161  43]\n",
      " [ 42 311]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_7' vs. 'Q3_7' ==\n",
      "Accuracy:   76.30%\n",
      "Macro F1:   75.00%\n",
      "Micro  F1:  76.30%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       344\n",
      "           1       0.69      0.70      0.69       213\n",
      "\n",
      "    accuracy                           0.76       557\n",
      "   macro avg       0.75      0.75      0.75       557\n",
      "weighted avg       0.76      0.76      0.76       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[276  68]\n",
      " [ 64 149]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_3_8' vs. 'Q3_8' ==\n",
      "Accuracy:   92.82%\n",
      "Macro F1:   56.46%\n",
      "Micro  F1:  92.82%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       527\n",
      "           1       0.22      0.13      0.17        30\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.59      0.55      0.56       557\n",
      "weighted avg       0.91      0.93      0.92       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[513  14]\n",
      " [ 26   4]]\n",
      "\n",
      ">> Overall accuracy: 87.93%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_41_finetune_3_1 vs Q3_1': {'accuracy': 0.9012567324955116,\n",
       "  'precision_macro': 0.6853149770546516,\n",
       "  'recall_macro': 0.6818107400130976,\n",
       "  'f1_macro': 0.6835390733949693,\n",
       "  'precision_micro': 0.9012567324955116,\n",
       "  'recall_micro': 0.9012567324955116,\n",
       "  'f1_micro': 0.9012567324955116,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.95      0.95       509\\n           1       0.43      0.42      0.42        48\\n\\n    accuracy                           0.90       557\\n   macro avg       0.69      0.68      0.68       557\\nweighted avg       0.90      0.90      0.90       557\\n',\n",
       "  'confusion_matrix': array([[482,  27],\n",
       "         [ 28,  20]])},\n",
       " 'GPT_41_finetune_3_2 vs Q3_2': {'accuracy': 0.8833034111310593,\n",
       "  'precision_macro': 0.7505229462474645,\n",
       "  'recall_macro': 0.71865836791148,\n",
       "  'f1_macro': 0.7328537170263789,\n",
       "  'precision_micro': 0.8833034111310593,\n",
       "  'recall_micro': 0.8833034111310593,\n",
       "  'f1_micro': 0.8833034111310593,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.94      0.93       482\\n           1       0.58      0.49      0.53        75\\n\\n    accuracy                           0.88       557\\n   macro avg       0.75      0.72      0.73       557\\nweighted avg       0.88      0.88      0.88       557\\n',\n",
       "  'confusion_matrix': array([[455,  27],\n",
       "         [ 38,  37]])},\n",
       " 'GPT_41_finetune_3_3 vs Q3_3': {'accuracy': 0.9730700179533214,\n",
       "  'precision_macro': 0.7694134078212291,\n",
       "  'recall_macro': 0.8151960784313725,\n",
       "  'f1_macro': 0.7903335089964616,\n",
       "  'precision_micro': 0.9730700179533214,\n",
       "  'recall_micro': 0.9730700179533214,\n",
       "  'f1_micro': 0.9730700179533214,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.98      0.99       540\\n           1       0.55      0.65      0.59        17\\n\\n    accuracy                           0.97       557\\n   macro avg       0.77      0.82      0.79       557\\nweighted avg       0.98      0.97      0.97       557\\n',\n",
       "  'confusion_matrix': array([[531,   9],\n",
       "         [  6,  11]])},\n",
       " 'GPT_41_finetune_3_4 vs Q3_4': {'accuracy': 0.8186714542190305,\n",
       "  'precision_macro': 0.6926481481481481,\n",
       "  'recall_macro': 0.7431743805516597,\n",
       "  'f1_macro': 0.7109823323007054,\n",
       "  'precision_micro': 0.8186714542190305,\n",
       "  'recall_micro': 0.8186714542190305,\n",
       "  'f1_micro': 0.8186714542190305,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.86      0.89       465\\n           1       0.46      0.63      0.53        92\\n\\n    accuracy                           0.82       557\\n   macro avg       0.69      0.74      0.71       557\\nweighted avg       0.85      0.82      0.83       557\\n',\n",
       "  'confusion_matrix': array([[398,  67],\n",
       "         [ 34,  58]])},\n",
       " 'GPT_41_finetune_3_5 vs Q3_5': {'accuracy': 0.9192100538599641,\n",
       "  'precision_macro': 0.5634808092266969,\n",
       "  'recall_macro': 0.6551524953789278,\n",
       "  'f1_macro': 0.5839764975352288,\n",
       "  'precision_micro': 0.9192100538599641,\n",
       "  'recall_micro': 0.9192100538599641,\n",
       "  'f1_micro': 0.9192100538599641,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.94      0.96       541\\n           1       0.15      0.38      0.21        16\\n\\n    accuracy                           0.92       557\\n   macro avg       0.56      0.66      0.58       557\\nweighted avg       0.96      0.92      0.94       557\\n',\n",
       "  'confusion_matrix': array([[506,  35],\n",
       "         [ 10,   6]])},\n",
       " 'GPT_41_finetune_3_6 vs Q3_6': {'accuracy': 0.8473967684021544,\n",
       "  'precision_macro': 0.8358172608610949,\n",
       "  'recall_macro': 0.8351177581514192,\n",
       "  'f1_macro': 0.8354642414048354,\n",
       "  'precision_micro': 0.8473967684021544,\n",
       "  'recall_micro': 0.8473967684021544,\n",
       "  'f1_micro': 0.8473967684021544,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.79      0.79      0.79       204\\n           1       0.88      0.88      0.88       353\\n\\n    accuracy                           0.85       557\\n   macro avg       0.84      0.84      0.84       557\\nweighted avg       0.85      0.85      0.85       557\\n',\n",
       "  'confusion_matrix': array([[161,  43],\n",
       "         [ 42, 311]])},\n",
       " 'GPT_41_finetune_3_7 vs Q3_7': {'accuracy': 0.7630161579892281,\n",
       "  'precision_macro': 0.7492003252914069,\n",
       "  'recall_macro': 0.7509280489136368,\n",
       "  'f1_macro': 0.7500203998368014,\n",
       "  'precision_micro': 0.7630161579892281,\n",
       "  'recall_micro': 0.7630161579892281,\n",
       "  'f1_micro': 0.7630161579892281,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.80      0.81       344\\n           1       0.69      0.70      0.69       213\\n\\n    accuracy                           0.76       557\\n   macro avg       0.75      0.75      0.75       557\\nweighted avg       0.76      0.76      0.76       557\\n',\n",
       "  'confusion_matrix': array([[276,  68],\n",
       "         [ 64, 149]])},\n",
       " 'GPT_41_finetune_3_8 vs Q3_8': {'accuracy': 0.9281867145421903,\n",
       "  'precision_macro': 0.5869923727066584,\n",
       "  'recall_macro': 0.5533839342188488,\n",
       "  'f1_macro': 0.5645716072545341,\n",
       "  'precision_micro': 0.9281867145421903,\n",
       "  'recall_micro': 0.9281867145421903,\n",
       "  'f1_micro': 0.9281867145421903,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.97      0.96       527\\n           1       0.22      0.13      0.17        30\\n\\n    accuracy                           0.93       557\\n   macro avg       0.59      0.55      0.56       557\\nweighted avg       0.91      0.93      0.92       557\\n',\n",
       "  'confusion_matrix': array([[513,  14],\n",
       "         [ 26,   4]])},\n",
       " 'overall_accuracy': 0.8792639138240574}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_41_finetune_3,\n",
    "    predicted_cols=[\n",
    "        \"GPT_41_finetune_3_1\",\n",
    "        \"GPT_41_finetune_3_2\",\n",
    "        \"GPT_41_finetune_3_3\",\n",
    "        \"GPT_41_finetune_3_4\",\n",
    "        \"GPT_41_finetune_3_5\",\n",
    "        \"GPT_41_finetune_3_6\",\n",
    "        \"GPT_41_finetune_3_7\",\n",
    "        \"GPT_41_finetune_3_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80553332-9f91-49f8-b7d1-fbaadc9d3e9f",
   "metadata": {},
   "source": [
    "# Finetune with N = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abd683b5-d847-4283-86ab-6c46c162d28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_original</th>\n",
       "      <th>GUID</th>\n",
       "      <th>Date (GMT)</th>\n",
       "      <th>URL</th>\n",
       "      <th>Post_Title</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3_1_og</th>\n",
       "      <th>Q3_2_og</th>\n",
       "      <th>Train</th>\n",
       "      <th>Q3_1</th>\n",
       "      <th>Q3_2</th>\n",
       "      <th>Q3_3</th>\n",
       "      <th>Q3_4</th>\n",
       "      <th>Q3_5</th>\n",
       "      <th>Q3_6</th>\n",
       "      <th>Q3_7</th>\n",
       "      <th>Q3_8</th>\n",
       "      <th>Q3_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>163</td>\n",
       "      <td>0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d</td>\n",
       "      <td>2018-01-31 06:08:46</td>\n",
       "      <td>https://www.politico.com/story/2018/01/31/stat...</td>\n",
       "      <td>Democrats furious over Trump's immigration rhe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>1059</td>\n",
       "      <td>33a28b82-e7c0-47b4-a637-bfaa67b6f8a8</td>\n",
       "      <td>2018-01-02 23:54:54</td>\n",
       "      <td>http://abcnews.go.com/politics/wirestory/lates...</td>\n",
       "      <td>The Latest: Trump says Dems not helping young ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "      <td>2233</td>\n",
       "      <td>2563ec73-f243-4c60-b613-e2bd9b9389bd</td>\n",
       "      <td>2018-01-10 05:44:22</td>\n",
       "      <td>http://www.breitbart.com/news/us-judge-blocks-...</td>\n",
       "      <td>US judge blocks Trump move rescinding immigran...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601</td>\n",
       "      <td>2944</td>\n",
       "      <td>f5d33307-e783-4059-a33d-0538df26f633</td>\n",
       "      <td>2018-01-10 20:38:15</td>\n",
       "      <td>http://thehill.com/homenews/senate/368354-rand...</td>\n",
       "      <td>Rand Paul: 'We don't have money to spend' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1826</td>\n",
       "      <td>8405</td>\n",
       "      <td>caac1fde-9fc9-4584-ac2a-fb524a4f355c</td>\n",
       "      <td>2018-01-04 01:05:07</td>\n",
       "      <td>https://www.yahoo.com/news/u-deportations-alle...</td>\n",
       "      <td>U.S. deportations of alleged El Salvador gang ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>128</td>\n",
       "      <td>641</td>\n",
       "      <td>058aeb5a-a475-43fa-9e4e-c920c00d590b</td>\n",
       "      <td>2018-01-05 12:19:07</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/01/05/ses...</td>\n",
       "      <td>Sessions to review docket practice used by imm...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1047</td>\n",
       "      <td>4992</td>\n",
       "      <td>5085fce0-f595-468b-bddc-872cf70443dc</td>\n",
       "      <td>2018-01-12 18:06:20</td>\n",
       "      <td>https://www.usatoday.com/story/news/politics/2...</td>\n",
       "      <td>Paul Ryan: Trump's comments on immigration'unh...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>939</td>\n",
       "      <td>4514</td>\n",
       "      <td>452ef9c0-8075-4820-a902-b447ac6471ae</td>\n",
       "      <td>2018-01-09 20:42:58</td>\n",
       "      <td>http://www.breitbart.com/texas/2018/01/09/poli...</td>\n",
       "      <td>Police Union Calls for Probe of San Antonio Ch...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>1220</td>\n",
       "      <td>5702</td>\n",
       "      <td>2240a886-b52e-44a2-b365-a8c2258a4d63</td>\n",
       "      <td>2018-01-10 03:24:00</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/conservat...</td>\n",
       "      <td>Conservatives Alarmed By Trumpâ€™s â€˜Comprehensiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1162</td>\n",
       "      <td>5503</td>\n",
       "      <td>f6ceda44-32ae-455b-af73-f5092d314d89</td>\n",
       "      <td>2018-01-11 14:43:22</td>\n",
       "      <td>http://www.cnn.com/transcripts/1801/11/nday.02...</td>\n",
       "      <td>Trump Open to Talks with North; Boardroom Trum...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  ID_original                                  GUID  \\\n",
       "0    1927          163  0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d   \n",
       "1     221         1059  33a28b82-e7c0-47b4-a637-bfaa67b6f8a8   \n",
       "2     452         2233  2563ec73-f243-4c60-b613-e2bd9b9389bd   \n",
       "3     601         2944  f5d33307-e783-4059-a33d-0538df26f633   \n",
       "4    1826         8405  caac1fde-9fc9-4584-ac2a-fb524a4f355c   \n",
       "..    ...          ...                                   ...   \n",
       "795   128          641  058aeb5a-a475-43fa-9e4e-c920c00d590b   \n",
       "796  1047         4992  5085fce0-f595-468b-bddc-872cf70443dc   \n",
       "797   939         4514  452ef9c0-8075-4820-a902-b447ac6471ae   \n",
       "798  1220         5702  2240a886-b52e-44a2-b365-a8c2258a4d63   \n",
       "799  1162         5503  f6ceda44-32ae-455b-af73-f5092d314d89   \n",
       "\n",
       "             Date (GMT)                                                URL  \\\n",
       "0   2018-01-31 06:08:46  https://www.politico.com/story/2018/01/31/stat...   \n",
       "1   2018-01-02 23:54:54  http://abcnews.go.com/politics/wirestory/lates...   \n",
       "2   2018-01-10 05:44:22  http://www.breitbart.com/news/us-judge-blocks-...   \n",
       "3   2018-01-10 20:38:15  http://thehill.com/homenews/senate/368354-rand...   \n",
       "4   2018-01-04 01:05:07  https://www.yahoo.com/news/u-deportations-alle...   \n",
       "..                  ...                                                ...   \n",
       "795 2018-01-05 12:19:07  http://www.foxnews.com/politics/2018/01/05/ses...   \n",
       "796 2018-01-12 18:06:20  https://www.usatoday.com/story/news/politics/2...   \n",
       "797 2018-01-09 20:42:58  http://www.breitbart.com/texas/2018/01/09/poli...   \n",
       "798 2018-01-10 03:24:00  https://www.huffingtonpost.com/entry/conservat...   \n",
       "799 2018-01-11 14:43:22  http://www.cnn.com/transcripts/1801/11/nday.02...   \n",
       "\n",
       "                                            Post_Title  Q1  Q2  Q3_1_og  \\\n",
       "0    Democrats furious over Trump's immigration rhe...   1   2        6   \n",
       "1    The Latest: Trump says Dems not helping young ...   1   2        6   \n",
       "2    US judge blocks Trump move rescinding immigran...   1   2        6   \n",
       "3    Rand Paul: 'We don't have money to spend' for ...   1   2        6   \n",
       "4    U.S. deportations of alleged El Salvador gang ...   1   1        2   \n",
       "..                                                 ...  ..  ..      ...   \n",
       "795  Sessions to review docket practice used by imm...   1   2        6   \n",
       "796  Paul Ryan: Trump's comments on immigration'unh...   1   2        6   \n",
       "797  Police Union Calls for Probe of San Antonio Ch...   1   1        2   \n",
       "798  Conservatives Alarmed By Trumpâ€™s â€˜Comprehensiv...   1   2        6   \n",
       "799  Trump Open to Talks with North; Boardroom Trum...   1   2        6   \n",
       "\n",
       "     Q3_2_og  Train  Q3_1  Q3_2  Q3_3  Q3_4  Q3_5  Q3_6  Q3_7  Q3_8  \\\n",
       "0         99      1     0     0     0     0     0     1     0     0   \n",
       "1         99      1     0     0     0     0     0     1     0     0   \n",
       "2         99      1     0     0     0     0     0     1     0     0   \n",
       "3          1      1     1     0     0     0     0     1     0     0   \n",
       "4         99      1     0     1     0     0     0     0     0     0   \n",
       "..       ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "795       99      1     0     0     0     0     0     1     0     0   \n",
       "796        4      1     0     0     0     1     0     1     0     0   \n",
       "797       99      1     0     1     0     0     0     0     0     0   \n",
       "798        7      1     0     0     0     0     0     1     1     0   \n",
       "799        7      1     0     0     0     0     0     1     1     0   \n",
       "\n",
       "                     Q3_clean  \n",
       "0    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "3    [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4    [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "..                        ...  \n",
       "795  [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "796  [0, 0, 0, 1, 0, 1, 0, 0]  \n",
       "797  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "798  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "799  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "\n",
       "[800 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finetune_df_1 = pd.read_excel(\"Data_train/train_1.xlsx\", sheet_name=0)\n",
    "Finetune_df_2 = pd.read_excel(\"Data_train/train_2.xlsx\", sheet_name=0)\n",
    "Finetune_df_3 = pd.read_excel(\"Data_train/train_3.xlsx\", sheet_name=0)\n",
    "Finetune_df_4 = pd.read_excel(\"Data_train/train_4.xlsx\", sheet_name=0)\n",
    "\n",
    "# Concatenate all three DataFrames row-wise\n",
    "Finetune_df_4_all = pd.concat([Finetune_df_1, Finetune_df_2, Finetune_df_3, Finetune_df_4], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "Finetune_df_4_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c59c681a-abda-43e4-8ff9-c39189f95702",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_GPT_finetune_jsonl(Finetune_df_4_all, \n",
    "                        output_path=\"GPT_Finetune/train_4.jsonl\", \n",
    "                        system_prompt = prompt_GPT,\n",
    "                        input_col = [\"Post_Title\"],\n",
    "                        label_col=[\"Q3_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773dc19c-a6aa-49ff-bddc-b1527c6831c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fine-tune job ftjob-cA5nHBmVW10gqOgFhGQ1jkMk\n",
      "[0s] status=validating_files\n",
      "[15s] status=validating_files\n",
      "[30s] status=validating_files\n",
      "[45s] status=validating_files\n",
      "[60s] status=validating_files\n",
      "[75s] status=validating_files\n",
      "[90s] status=validating_files\n",
      "[105s] status=validating_files\n",
      "[120s] status=validating_files\n",
      "[135s] status=validating_files\n",
      "[150s] status=running\n",
      "[165s] status=running\n",
      "[180s] status=running\n",
      "[195s] status=running\n",
      "[210s] status=running\n",
      "[225s] status=running\n",
      "[240s] status=running\n",
      "[255s] status=running\n",
      "[270s] status=running\n",
      "[285s] status=running\n",
      "[300s] status=running\n",
      "[315s] status=running\n",
      "[330s] status=running\n",
      "[345s] status=running\n",
      "[360s] status=running\n",
      "[375s] status=running\n",
      "[390s] status=running\n",
      "[405s] status=running\n",
      "[420s] status=running\n",
      "[435s] status=running\n",
      "[450s] status=running\n",
      "[465s] status=running\n",
      "[480s] status=running\n",
      "[495s] status=running\n",
      "[510s] status=running\n",
      "[525s] status=running\n",
      "[540s] status=running\n",
      "[555s] status=running\n",
      "[570s] status=running\n",
      "[585s] status=running\n",
      "[600s] status=running\n",
      "[615s] status=running\n",
      "[630s] status=running\n",
      "[645s] status=running\n",
      "[660s] status=running\n",
      "[675s] status=running\n",
      "[690s] status=running\n",
      "[705s] status=running\n",
      "[720s] status=running\n",
      "[735s] status=running\n",
      "[750s] status=running\n",
      "[765s] status=running\n",
      "[780s] status=running\n",
      "[795s] status=running\n",
      "[810s] status=running\n",
      "[825s] status=running\n",
      "[840s] status=running\n",
      "[855s] status=running\n",
      "[870s] status=running\n",
      "[885s] status=running\n",
      "[900s] status=running\n",
      "[915s] status=running\n",
      "[930s] status=running\n",
      "[945s] status=running\n",
      "[960s] status=running\n",
      "[975s] status=running\n",
      "[990s] status=running\n",
      "[1005s] status=running\n",
      "[1020s] status=running\n",
      "[1035s] status=running\n",
      "[1050s] status=running\n",
      "[1065s] status=running\n",
      "[1080s] status=running\n",
      "[1095s] status=running\n",
      "[1110s] status=running\n",
      "[1125s] status=running\n",
      "[1140s] status=running\n",
      "[1155s] status=running\n",
      "[1170s] status=running\n",
      "[1185s] status=running\n",
      "[1200s] status=running\n",
      "[1215s] status=running\n",
      "[1230s] status=running\n",
      "[1245s] status=running\n",
      "[1260s] status=running\n",
      "[1275s] status=running\n",
      "[1290s] status=running\n",
      "[1305s] status=running\n",
      "[1320s] status=running\n",
      "[1335s] status=running\n",
      "[1350s] status=running\n",
      "[1365s] status=running\n",
      "[1380s] status=running\n",
      "[1395s] status=running\n",
      "[1410s] status=running\n",
      "[1425s] status=running\n",
      "[1440s] status=running\n",
      "[1455s] status=running\n",
      "[1470s] status=running\n",
      "[1485s] status=running\n",
      "[1500s] status=running\n",
      "[1515s] status=running\n",
      "[1530s] status=running\n",
      "[1545s] status=running\n",
      "[1560s] status=running\n",
      "[1575s] status=running\n",
      "[1590s] status=running\n",
      "[1605s] status=running\n",
      "[1620s] status=running\n",
      "[1635s] status=running\n",
      "[1650s] status=running\n",
      "[1665s] status=running\n",
      "[1680s] status=running\n",
      "[1695s] status=running\n",
      "[1710s] status=running\n",
      "[1725s] status=running\n",
      "[1740s] status=running\n",
      "[1755s] status=running\n",
      "[1770s] status=running\n",
      "[1785s] status=running\n",
      "[1800s] status=running\n",
      "[1815s] status=running\n",
      "[1830s] status=running\n",
      "[1845s] status=running\n",
      "[1860s] status=running\n",
      "[1875s] status=running\n",
      "[1890s] status=running\n",
      "[1905s] status=running\n",
      "[1920s] status=running\n",
      "[1935s] status=running\n",
      "[1950s] status=running\n",
      "[1965s] status=running\n",
      "[1980s] status=running\n",
      "[1995s] status=running\n",
      "[2010s] status=running\n",
      "[2025s] status=running\n",
      "[2040s] status=running\n",
      "[2055s] status=running\n",
      "[2070s] status=running\n",
      "[2085s] status=running\n",
      "[2100s] status=running\n",
      "[2115s] status=running\n",
      "[2130s] status=running\n",
      "[2145s] status=running\n",
      "[2160s] status=running\n",
      "[2175s] status=running\n",
      "[2190s] status=running\n",
      "[2205s] status=running\n",
      "[2220s] status=running\n",
      "[2235s] status=running\n",
      "[2250s] status=running\n",
      "[2265s] status=running\n",
      "[2280s] status=running\n",
      "[2295s] status=running\n",
      "[2310s] status=running\n",
      "[2325s] status=running\n",
      "[2340s] status=running\n",
      "[2355s] status=running\n",
      "[2370s] status=running\n",
      "[2385s] status=running\n",
      "[2400s] status=running\n",
      "[2415s] status=succeeded\n",
      "âœ… succeeded: ft:gpt-4.1-mini-2025-04-14:jcs-research::CQl25PPV\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-4o\n",
    "GPT_finetune_4 = finetune_GPT(\n",
    "    training_file_path=\"GPT_Finetune/train_4.jsonl\",\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",  \n",
    "    hyperparameters={\"batch_size\":8, \"learning_rate_multiplier\":0.01},\n",
    "    api_key= api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2136e1d5-a530-4f69-805a-3d0d7392a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 22:28:13.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-14 22:28:13.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-14 22:28:13.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "Classifying text_class: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 [20:39<00:00,  2.23s/item]\n"
     ]
    }
   ],
   "source": [
    "# Classify with fineâ€‘tuned  model\n",
    "GPT_41_finetune_4 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category = category_GPT,\n",
    "    prompt = prompt_GPT,\n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model = \"ft:gpt-4.1-mini-2025-04-14:jcs-research::CQl25PPV\",\n",
    "    api_key = api_key,\n",
    "    temperature = 0.8,\n",
    "    mode = \"text\",\n",
    "    output_column_name=\"GPT_41_finetune_4\",\n",
    "    num_themes = 8,\n",
    "    num_votes = 1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_41_finetune_4.to_csv(\"Result/00_GPT_41_finetune_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8d34bc-58e8-485b-9b99-687c002f15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_41_finetune_4_1' vs. 'Q3_1' ==\n",
      "Accuracy:   90.13%\n",
      "Macro F1:   68.95%\n",
      "Micro  F1:  90.13%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       509\n",
      "           1       0.43      0.44      0.43        48\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.69      0.69      0.69       557\n",
      "weighted avg       0.90      0.90      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[481  28]\n",
      " [ 27  21]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_2' vs. 'Q3_2' ==\n",
      "Accuracy:   90.48%\n",
      "Macro F1:   78.74%\n",
      "Micro  F1:  90.48%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       482\n",
      "           1       0.66      0.60      0.63        75\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.80      0.78      0.79       557\n",
      "weighted avg       0.90      0.90      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[459  23]\n",
      " [ 30  45]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_3' vs. 'Q3_3' ==\n",
      "Accuracy:   97.85%\n",
      "Macro F1:   80.70%\n",
      "Micro  F1:  97.85%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       540\n",
      "           1       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.83      0.79      0.81       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[535   5]\n",
      " [  7  10]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_4' vs. 'Q3_4' ==\n",
      "Accuracy:   82.41%\n",
      "Macro F1:   71.66%\n",
      "Micro  F1:  82.41%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       465\n",
      "           1       0.48      0.63      0.54        92\n",
      "\n",
      "    accuracy                           0.82       557\n",
      "   macro avg       0.70      0.75      0.72       557\n",
      "weighted avg       0.85      0.82      0.83       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[401  64]\n",
      " [ 34  58]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_5' vs. 'Q3_5' ==\n",
      "Accuracy:   93.00%\n",
      "Macro F1:   61.37%\n",
      "Micro  F1:  93.00%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       541\n",
      "           1       0.19      0.44      0.26        16\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.59      0.69      0.61       557\n",
      "weighted avg       0.96      0.93      0.94       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[511  30]\n",
      " [  9   7]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_6' vs. 'Q3_6' ==\n",
      "Accuracy:   81.69%\n",
      "Macro F1:   80.51%\n",
      "Micro  F1:  81.69%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       204\n",
      "           1       0.87      0.84      0.85       353\n",
      "\n",
      "    accuracy                           0.82       557\n",
      "   macro avg       0.80      0.81      0.81       557\n",
      "weighted avg       0.82      0.82      0.82       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[159  45]\n",
      " [ 57 296]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_7' vs. 'Q3_7' ==\n",
      "Accuracy:   76.12%\n",
      "Macro F1:   74.75%\n",
      "Micro  F1:  76.12%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       344\n",
      "           1       0.69      0.69      0.69       213\n",
      "\n",
      "    accuracy                           0.76       557\n",
      "   macro avg       0.75      0.75      0.75       557\n",
      "weighted avg       0.76      0.76      0.76       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[277  67]\n",
      " [ 66 147]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_4_8' vs. 'Q3_8' ==\n",
      "Accuracy:   93.36%\n",
      "Macro F1:   58.90%\n",
      "Micro  F1:  93.36%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       527\n",
      "           1       0.29      0.17      0.21        30\n",
      "\n",
      "    accuracy                           0.93       557\n",
      "   macro avg       0.62      0.57      0.59       557\n",
      "weighted avg       0.92      0.93      0.92       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[515  12]\n",
      " [ 25   5]]\n",
      "\n",
      ">> Overall accuracy: 88.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_41_finetune_4_1 vs Q3_1': {'accuracy': 0.9012567324955116,\n",
       "  'precision_macro': 0.6877109111361079,\n",
       "  'recall_macro': 0.6912450884086444,\n",
       "  'f1_macro': 0.6894545307098907,\n",
       "  'precision_micro': 0.9012567324955116,\n",
       "  'recall_micro': 0.9012567324955116,\n",
       "  'f1_micro': 0.9012567324955116,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.94      0.95       509\\n           1       0.43      0.44      0.43        48\\n\\n    accuracy                           0.90       557\\n   macro avg       0.69      0.69      0.69       557\\nweighted avg       0.90      0.90      0.90       557\\n',\n",
       "  'confusion_matrix': array([[481,  28],\n",
       "         [ 27,  21]])},\n",
       " 'GPT_41_finetune_4_2 vs Q3_2': {'accuracy': 0.9048473967684022,\n",
       "  'precision_macro': 0.8002075063154096,\n",
       "  'recall_macro': 0.7761410788381742,\n",
       "  'f1_macro': 0.7873938625740892,\n",
       "  'precision_micro': 0.9048473967684022,\n",
       "  'recall_micro': 0.9048473967684022,\n",
       "  'f1_micro': 0.9048473967684022,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.94      0.95      0.95       482\\n           1       0.66      0.60      0.63        75\\n\\n    accuracy                           0.90       557\\n   macro avg       0.80      0.78      0.79       557\\nweighted avg       0.90      0.90      0.90       557\\n',\n",
       "  'confusion_matrix': array([[459,  23],\n",
       "         [ 30,  45]])},\n",
       " 'GPT_41_finetune_4_3 vs Q3_3': {'accuracy': 0.9784560143626571,\n",
       "  'precision_macro': 0.8268757687576875,\n",
       "  'recall_macro': 0.7894880174291938,\n",
       "  'f1_macro': 0.8069547134935304,\n",
       "  'precision_micro': 0.9784560143626571,\n",
       "  'recall_micro': 0.9784560143626571,\n",
       "  'f1_micro': 0.9784560143626571,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99       540\\n           1       0.67      0.59      0.62        17\\n\\n    accuracy                           0.98       557\\n   macro avg       0.83      0.79      0.81       557\\nweighted avg       0.98      0.98      0.98       557\\n',\n",
       "  'confusion_matrix': array([[535,   5],\n",
       "         [  7,  10]])},\n",
       " 'GPT_41_finetune_4_4 vs Q3_4': {'accuracy': 0.8240574506283662,\n",
       "  'precision_macro': 0.6986244582626719,\n",
       "  'recall_macro': 0.7464001870032726,\n",
       "  'f1_macro': 0.7165835929387331,\n",
       "  'precision_micro': 0.8240574506283662,\n",
       "  'recall_micro': 0.8240574506283662,\n",
       "  'f1_micro': 0.8240574506283662,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.92      0.86      0.89       465\\n           1       0.48      0.63      0.54        92\\n\\n    accuracy                           0.82       557\\n   macro avg       0.70      0.75      0.72       557\\nweighted avg       0.85      0.82      0.83       557\\n',\n",
       "  'confusion_matrix': array([[401,  64],\n",
       "         [ 34,  58]])},\n",
       " 'GPT_41_finetune_4_5 vs Q3_5': {'accuracy': 0.9299820466786356,\n",
       "  'precision_macro': 0.5859407484407484,\n",
       "  'recall_macro': 0.6910235674676525,\n",
       "  'f1_macro': 0.6136965838564544,\n",
       "  'precision_micro': 0.9299820466786356,\n",
       "  'recall_micro': 0.9299820466786356,\n",
       "  'f1_micro': 0.9299820466786356,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.98      0.94      0.96       541\\n           1       0.19      0.44      0.26        16\\n\\n    accuracy                           0.93       557\\n   macro avg       0.59      0.69      0.61       557\\nweighted avg       0.96      0.93      0.94       557\\n',\n",
       "  'confusion_matrix': array([[511,  30],\n",
       "         [  9,   7]])},\n",
       " 'GPT_41_finetune_4_6 vs Q3_6': {'accuracy': 0.8168761220825853,\n",
       "  'precision_macro': 0.8020731508634735,\n",
       "  'recall_macro': 0.8089693384435928,\n",
       "  'f1_macro': 0.8050843968711403,\n",
       "  'precision_micro': 0.8168761220825853,\n",
       "  'recall_micro': 0.8168761220825853,\n",
       "  'f1_micro': 0.8168761220825853,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.74      0.78      0.76       204\\n           1       0.87      0.84      0.85       353\\n\\n    accuracy                           0.82       557\\n   macro avg       0.80      0.81      0.81       557\\nweighted avg       0.82      0.82      0.82       557\\n',\n",
       "  'confusion_matrix': array([[159,  45],\n",
       "         [ 57, 296]])},\n",
       " 'GPT_41_finetune_4_7 vs Q3_7': {'accuracy': 0.7612208258527827,\n",
       "  'precision_macro': 0.7472480313887905,\n",
       "  'recall_macro': 0.7476867016049786,\n",
       "  'f1_macro': 0.7474646240484883,\n",
       "  'precision_micro': 0.7612208258527827,\n",
       "  'recall_micro': 0.7612208258527827,\n",
       "  'f1_micro': 0.7612208258527827,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.81      0.81       344\\n           1       0.69      0.69      0.69       213\\n\\n    accuracy                           0.76       557\\n   macro avg       0.75      0.75      0.75       557\\nweighted avg       0.76      0.76      0.76       557\\n',\n",
       "  'confusion_matrix': array([[277,  67],\n",
       "         [ 66, 147]])},\n",
       " 'GPT_41_finetune_4_8 vs Q3_8': {'accuracy': 0.933572710951526,\n",
       "  'precision_macro': 0.6239106753812637,\n",
       "  'recall_macro': 0.5719481340923466,\n",
       "  'f1_macro': 0.5890446469520828,\n",
       "  'precision_micro': 0.933572710951526,\n",
       "  'recall_micro': 0.933572710951526,\n",
       "  'f1_micro': 0.933572710951526,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.98      0.97       527\\n           1       0.29      0.17      0.21        30\\n\\n    accuracy                           0.93       557\\n   macro avg       0.62      0.57      0.59       557\\nweighted avg       0.92      0.93      0.92       557\\n',\n",
       "  'confusion_matrix': array([[515,  12],\n",
       "         [ 25,   5]])},\n",
       " 'overall_accuracy': 0.8812836624775583}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_41_finetune_4,\n",
    "    predicted_cols=[\n",
    "        \"GPT_41_finetune_4_1\",\n",
    "        \"GPT_41_finetune_4_2\",\n",
    "        \"GPT_41_finetune_4_3\",\n",
    "        \"GPT_41_finetune_4_4\",\n",
    "        \"GPT_41_finetune_4_5\",\n",
    "        \"GPT_41_finetune_4_6\",\n",
    "        \"GPT_41_finetune_4_7\",\n",
    "        \"GPT_41_finetune_4_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fecee33-1ec6-45d3-919d-67387663d9fd",
   "metadata": {},
   "source": [
    "# Finetune with N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b010ed90-0db8-4cae-b46e-b7df6a3d25b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_original</th>\n",
       "      <th>GUID</th>\n",
       "      <th>Date (GMT)</th>\n",
       "      <th>URL</th>\n",
       "      <th>Post_Title</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3_1_og</th>\n",
       "      <th>Q3_2_og</th>\n",
       "      <th>Train</th>\n",
       "      <th>Q3_1</th>\n",
       "      <th>Q3_2</th>\n",
       "      <th>Q3_3</th>\n",
       "      <th>Q3_4</th>\n",
       "      <th>Q3_5</th>\n",
       "      <th>Q3_6</th>\n",
       "      <th>Q3_7</th>\n",
       "      <th>Q3_8</th>\n",
       "      <th>Q3_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927</td>\n",
       "      <td>163</td>\n",
       "      <td>0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d</td>\n",
       "      <td>2018-01-31 06:08:46</td>\n",
       "      <td>https://www.politico.com/story/2018/01/31/stat...</td>\n",
       "      <td>Democrats furious over Trump's immigration rhe...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>1059</td>\n",
       "      <td>33a28b82-e7c0-47b4-a637-bfaa67b6f8a8</td>\n",
       "      <td>2018-01-02 23:54:54</td>\n",
       "      <td>http://abcnews.go.com/politics/wirestory/lates...</td>\n",
       "      <td>The Latest: Trump says Dems not helping young ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "      <td>2233</td>\n",
       "      <td>2563ec73-f243-4c60-b613-e2bd9b9389bd</td>\n",
       "      <td>2018-01-10 05:44:22</td>\n",
       "      <td>http://www.breitbart.com/news/us-judge-blocks-...</td>\n",
       "      <td>US judge blocks Trump move rescinding immigran...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601</td>\n",
       "      <td>2944</td>\n",
       "      <td>f5d33307-e783-4059-a33d-0538df26f633</td>\n",
       "      <td>2018-01-10 20:38:15</td>\n",
       "      <td>http://thehill.com/homenews/senate/368354-rand...</td>\n",
       "      <td>Rand Paul: 'We don't have money to spend' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1826</td>\n",
       "      <td>8405</td>\n",
       "      <td>caac1fde-9fc9-4584-ac2a-fb524a4f355c</td>\n",
       "      <td>2018-01-04 01:05:07</td>\n",
       "      <td>https://www.yahoo.com/news/u-deportations-alle...</td>\n",
       "      <td>U.S. deportations of alleged El Salvador gang ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1122</td>\n",
       "      <td>5327</td>\n",
       "      <td>136e6f79-418c-42aa-b47d-17df079d259c</td>\n",
       "      <td>2018-01-13 01:23:20</td>\n",
       "      <td>https://www.yahoo.com/news/m/9d804ffa-8bb1-33c...</td>\n",
       "      <td>Immigrants with jobs, education worry that Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1352</td>\n",
       "      <td>6257</td>\n",
       "      <td>ef615e42-abb5-48d2-a46d-282f33d06942</td>\n",
       "      <td>2018-01-03 06:44:46</td>\n",
       "      <td>http://www.breitbart.com/texas/2018/01/02/char...</td>\n",
       "      <td>Charge Sanctuary City Politicians With a Crime...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1004</td>\n",
       "      <td>4768</td>\n",
       "      <td>f24e4cb0-ea95-4bb4-98e2-9d2888b19e0d</td>\n",
       "      <td>2018-01-05 21:17:01</td>\n",
       "      <td>http://www.breitbart.com/big-government/2018/0...</td>\n",
       "      <td>Immigration Expert: Trump Wants â€˜to End Chain ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>524</td>\n",
       "      <td>2576</td>\n",
       "      <td>3021d2c9-a80e-4179-b9b6-0afa8d144d76</td>\n",
       "      <td>2018-01-12 04:50:46</td>\n",
       "      <td>https://www.wsj.com/articles/immigrants-connec...</td>\n",
       "      <td>Immigrants Connected to Sanctuary Movement Arr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>330</td>\n",
       "      <td>1618</td>\n",
       "      <td>d20ef606-6b70-408c-b91a-5d94b7e6b62a</td>\n",
       "      <td>2018-01-11 20:56:50</td>\n",
       "      <td>http://dailycaller.com/2018/01/10/trump-draws-...</td>\n",
       "      <td>Trump Draws A Red Line On Wall Funding For DAC...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  ID_original                                  GUID  \\\n",
       "0    1927          163  0ba254e8-fc2b-4eef-9426-4a3cbd3ee70d   \n",
       "1     221         1059  33a28b82-e7c0-47b4-a637-bfaa67b6f8a8   \n",
       "2     452         2233  2563ec73-f243-4c60-b613-e2bd9b9389bd   \n",
       "3     601         2944  f5d33307-e783-4059-a33d-0538df26f633   \n",
       "4    1826         8405  caac1fde-9fc9-4584-ac2a-fb524a4f355c   \n",
       "..    ...          ...                                   ...   \n",
       "995  1122         5327  136e6f79-418c-42aa-b47d-17df079d259c   \n",
       "996  1352         6257  ef615e42-abb5-48d2-a46d-282f33d06942   \n",
       "997  1004         4768  f24e4cb0-ea95-4bb4-98e2-9d2888b19e0d   \n",
       "998   524         2576  3021d2c9-a80e-4179-b9b6-0afa8d144d76   \n",
       "999   330         1618  d20ef606-6b70-408c-b91a-5d94b7e6b62a   \n",
       "\n",
       "             Date (GMT)                                                URL  \\\n",
       "0   2018-01-31 06:08:46  https://www.politico.com/story/2018/01/31/stat...   \n",
       "1   2018-01-02 23:54:54  http://abcnews.go.com/politics/wirestory/lates...   \n",
       "2   2018-01-10 05:44:22  http://www.breitbart.com/news/us-judge-blocks-...   \n",
       "3   2018-01-10 20:38:15  http://thehill.com/homenews/senate/368354-rand...   \n",
       "4   2018-01-04 01:05:07  https://www.yahoo.com/news/u-deportations-alle...   \n",
       "..                  ...                                                ...   \n",
       "995 2018-01-13 01:23:20  https://www.yahoo.com/news/m/9d804ffa-8bb1-33c...   \n",
       "996 2018-01-03 06:44:46  http://www.breitbart.com/texas/2018/01/02/char...   \n",
       "997 2018-01-05 21:17:01  http://www.breitbart.com/big-government/2018/0...   \n",
       "998 2018-01-12 04:50:46  https://www.wsj.com/articles/immigrants-connec...   \n",
       "999 2018-01-11 20:56:50  http://dailycaller.com/2018/01/10/trump-draws-...   \n",
       "\n",
       "                                            Post_Title  Q1  Q2  Q3_1_og  \\\n",
       "0    Democrats furious over Trump's immigration rhe...   1   2        6   \n",
       "1    The Latest: Trump says Dems not helping young ...   1   2        6   \n",
       "2    US judge blocks Trump move rescinding immigran...   1   2        6   \n",
       "3    Rand Paul: 'We don't have money to spend' for ...   1   2        6   \n",
       "4    U.S. deportations of alleged El Salvador gang ...   1   1        2   \n",
       "..                                                 ...  ..  ..      ...   \n",
       "995  Immigrants with jobs, education worry that Tru...   1   2        1   \n",
       "996  Charge Sanctuary City Politicians With a Crime...   1   2        2   \n",
       "997  Immigration Expert: Trump Wants â€˜to End Chain ...   1   2        6   \n",
       "998  Immigrants Connected to Sanctuary Movement Arr...   1   1        2   \n",
       "999  Trump Draws A Red Line On Wall Funding For DAC...   1   2        6   \n",
       "\n",
       "     Q3_2_og  Train  Q3_1  Q3_2  Q3_3  Q3_4  Q3_5  Q3_6  Q3_7  Q3_8  \\\n",
       "0         99      1     0     0     0     0     0     1     0     0   \n",
       "1         99      1     0     0     0     0     0     1     0     0   \n",
       "2         99      1     0     0     0     0     0     1     0     0   \n",
       "3          1      1     1     0     0     0     0     1     0     0   \n",
       "4         99      1     0     1     0     0     0     0     0     0   \n",
       "..       ...    ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "995        6      1     1     0     0     0     0     1     0     0   \n",
       "996       99      1     0     1     0     0     0     0     0     0   \n",
       "997        7      1     0     0     0     0     0     1     1     0   \n",
       "998       99      1     0     1     0     0     0     0     0     0   \n",
       "999        1      1     1     0     0     0     0     1     0     0   \n",
       "\n",
       "                     Q3_clean  \n",
       "0    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "2    [0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "3    [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4    [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "..                        ...  \n",
       "995  [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "996  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "997  [0, 0, 0, 0, 0, 1, 1, 0]  \n",
       "998  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "999  [1, 0, 0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Finetune_df_1 = pd.read_excel(\"Data_train/train_1.xlsx\", sheet_name=0)\n",
    "Finetune_df_2 = pd.read_excel(\"Data_train/train_2.xlsx\", sheet_name=0)\n",
    "Finetune_df_3 = pd.read_excel(\"Data_train/train_3.xlsx\", sheet_name=0)\n",
    "Finetune_df_4 = pd.read_excel(\"Data_train/train_4.xlsx\", sheet_name=0)\n",
    "Finetune_df_5 = pd.read_excel(\"Data_train/train_5.xlsx\", sheet_name=0)\n",
    "\n",
    "# Concatenate all three DataFrames row-wise\n",
    "Finetune_df_5_all = pd.concat([Finetune_df_1, Finetune_df_2, Finetune_df_3, Finetune_df_4,Finetune_df_5], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "Finetune_df_5_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fae5c2d-3835-4700-8356-c6fe76931714",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_GPT_finetune_jsonl(Finetune_df_5_all, \n",
    "                        output_path=\"GPT_Finetune/train_5.jsonl\", \n",
    "                        system_prompt = prompt_GPT,\n",
    "                        input_col = [\"Post_Title\"],\n",
    "                        label_col=[\"Q3_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bddab5e-5be6-42f3-8bfd-3f852e1c393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fine-tune job ftjob-gJfwn5MA3w474rCfO409npET\n",
      "[0s] status=validating_files\n",
      "[15s] status=validating_files\n",
      "[30s] status=validating_files\n",
      "[45s] status=validating_files\n",
      "[60s] status=validating_files\n",
      "[75s] status=validating_files\n",
      "[90s] status=validating_files\n",
      "[105s] status=validating_files\n",
      "[120s] status=validating_files\n",
      "[135s] status=validating_files\n",
      "[150s] status=running\n",
      "[165s] status=running\n",
      "[180s] status=running\n",
      "[195s] status=running\n",
      "[210s] status=running\n",
      "[225s] status=running\n",
      "[240s] status=running\n",
      "[255s] status=running\n",
      "[270s] status=running\n",
      "[285s] status=running\n",
      "[300s] status=running\n",
      "[315s] status=running\n",
      "[330s] status=running\n",
      "[345s] status=running\n",
      "[360s] status=running\n",
      "[375s] status=running\n",
      "[390s] status=running\n",
      "[405s] status=running\n",
      "[420s] status=running\n",
      "[435s] status=running\n",
      "[450s] status=running\n",
      "[465s] status=running\n",
      "[480s] status=running\n",
      "[495s] status=running\n",
      "[510s] status=running\n",
      "[525s] status=running\n",
      "[540s] status=running\n",
      "[555s] status=running\n",
      "[570s] status=running\n",
      "[585s] status=running\n",
      "[600s] status=running\n",
      "[615s] status=running\n",
      "[630s] status=running\n",
      "[645s] status=running\n",
      "[660s] status=running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune GPT-41\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m GPT_finetune_5 \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_GPT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPT_Finetune/train_5.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4.1-mini-2025-04-14\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate_multiplier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/labelgenius/LabelGenius.py:1141\u001b[0m, in \u001b[0;36mfinetune_GPT\u001b[0;34m(training_file_path, model, method_type, hyperparameters, poll_interval, max_wait_time, api_key)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ended with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Error info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tune job \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ended with status \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1139\u001b[0m                            \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1141\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m     elapsed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll_interval\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m didnâ€™t finish within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_wait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine-tune GPT-41\n",
    "GPT_finetune_5 = finetune_GPT(\n",
    "    training_file_path=\"GPT_Finetune/train_5.jsonl\",\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",  \n",
    "    hyperparameters={\"batch_size\":8, \"learning_rate_multiplier\":0.01},\n",
    "    api_key= api_key \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7170e0a5-752a-4018-8f7a-808f6d5a0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-15 02:16:57.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-15 02:16:57.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-15 02:16:57.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ]  14%|â–ˆâ–ˆâ–ˆâ–                    | 80/557 | ETA 17:50 |  2.24s/row | , âš¡ cache: 6  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 3, 0, 1, 0, 0, 0, 0] (expected 8 labels). Raw: \"[0, 3, 0, 1, 0, 0, 0, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  2.29s/row | , âš¡ cache: 59 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n",
      "âš¡ Cache hits: 59\n",
      "ðŸ” Re-run (new GPT): 498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  10%|â–ˆ          | 55/557 | ETA 4:32:10 | 32.53s/row | , âš¡ cache: 11 | redo: 44\n",
      "[ GPT â€¢ text_class ]  19%|â–ˆâ–Š        | 104/557 | ETA 1:54:54 | 15.22s/row | , âš¡ cache: 56 | redo: 48\n"
     ]
    }
   ],
   "source": [
    "# Classify with fineâ€‘tuned  model\n",
    "GPT_41_finetune_5 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category = category_GPT,\n",
    "    prompt = prompt_GPT,\n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model = \"ft:gpt-4.1-2025-04-14:jcs-research::CQmu7nC0\",\n",
    "    api_key = api_key,\n",
    "    temperature = 0.8,\n",
    "    mode = \"text\",\n",
    "    output_column_name=\"GPT_41_finetune_5\",\n",
    "    num_themes = 8,\n",
    "    num_votes = 1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_41_finetune_5.to_csv(\"Result/00_GPT_41_finetune_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8833569-9a0d-473a-96ba-b4324c600189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Verification of 'GPT_41_finetune_5_1' vs. 'Q3_1' ==\n",
      "Accuracy:   92.28%\n",
      "Macro F1:   62.71%\n",
      "Micro  F1:  92.28%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       509\n",
      "           1       0.69      0.19      0.30        48\n",
      "\n",
      "    accuracy                           0.92       557\n",
      "   macro avg       0.81      0.59      0.63       557\n",
      "weighted avg       0.91      0.92      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[505   4]\n",
      " [ 39   9]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_2' vs. 'Q3_2' ==\n",
      "Accuracy:   90.48%\n",
      "Macro F1:   79.47%\n",
      "Micro  F1:  90.48%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       482\n",
      "           1       0.65      0.64      0.64        75\n",
      "\n",
      "    accuracy                           0.90       557\n",
      "   macro avg       0.80      0.79      0.79       557\n",
      "weighted avg       0.90      0.90      0.90       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[456  26]\n",
      " [ 27  48]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_3' vs. 'Q3_3' ==\n",
      "Accuracy:   99.10%\n",
      "Macro F1:   92.63%\n",
      "Micro  F1:  99.10%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       540\n",
      "           1       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.99       557\n",
      "   macro avg       0.91      0.94      0.93       557\n",
      "weighted avg       0.99      0.99      0.99       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[537   3]\n",
      " [  2  15]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_4' vs. 'Q3_4' ==\n",
      "Accuracy:   81.15%\n",
      "Macro F1:   67.63%\n",
      "Micro  F1:  81.15%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89       465\n",
      "           1       0.44      0.50      0.47        92\n",
      "\n",
      "    accuracy                           0.81       557\n",
      "   macro avg       0.67      0.69      0.68       557\n",
      "weighted avg       0.82      0.81      0.82       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[406  59]\n",
      " [ 46  46]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_5' vs. 'Q3_5' ==\n",
      "Accuracy:   91.38%\n",
      "Macro F1:   63.42%\n",
      "Micro  F1:  91.38%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       541\n",
      "           1       0.20      0.69      0.31        16\n",
      "\n",
      "    accuracy                           0.91       557\n",
      "   macro avg       0.60      0.80      0.63       557\n",
      "weighted avg       0.97      0.91      0.94       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[498  43]\n",
      " [  5  11]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_6' vs. 'Q3_6' ==\n",
      "Accuracy:   86.89%\n",
      "Macro F1:   85.98%\n",
      "Micro  F1:  86.89%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       204\n",
      "           1       0.90      0.89      0.90       353\n",
      "\n",
      "    accuracy                           0.87       557\n",
      "   macro avg       0.86      0.86      0.86       557\n",
      "weighted avg       0.87      0.87      0.87       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[171  33]\n",
      " [ 40 313]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_7' vs. 'Q3_7' ==\n",
      "Accuracy:   76.66%\n",
      "Macro F1:   74.86%\n",
      "Micro  F1:  76.66%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       344\n",
      "           1       0.71      0.65      0.68       213\n",
      "\n",
      "    accuracy                           0.77       557\n",
      "   macro avg       0.75      0.74      0.75       557\n",
      "weighted avg       0.76      0.77      0.76       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[288  56]\n",
      " [ 74 139]]\n",
      "\n",
      "== Verification of 'GPT_41_finetune_5_8' vs. 'Q3_8' ==\n",
      "Accuracy:   93.54%\n",
      "Macro F1:   59.18%\n",
      "Micro  F1:  93.54%\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       527\n",
      "           1       0.31      0.17      0.22        30\n",
      "\n",
      "    accuracy                           0.94       557\n",
      "   macro avg       0.63      0.57      0.59       557\n",
      "weighted avg       0.92      0.94      0.93       557\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[516  11]\n",
      " [ 25   5]]\n",
      "\n",
      ">> Overall accuracy: 88.94%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GPT_41_finetune_5_1 vs Q3_1': {'accuracy': 0.9228007181328546,\n",
       "  'precision_macro': 0.8103082579185521,\n",
       "  'recall_macro': 0.5898207269155207,\n",
       "  'f1_macro': 0.6271231298553703,\n",
       "  'precision_micro': 0.9228007181328546,\n",
       "  'recall_micro': 0.9228007181328546,\n",
       "  'f1_micro': 0.9228007181328546,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.93      0.99      0.96       509\\n           1       0.69      0.19      0.30        48\\n\\n    accuracy                           0.92       557\\n   macro avg       0.81      0.59      0.63       557\\nweighted avg       0.91      0.92      0.90       557\\n',\n",
       "  'confusion_matrix': array([[505,   4],\n",
       "         [ 39,   9]])},\n",
       " 'GPT_41_finetune_5_2 vs Q3_2': {'accuracy': 0.9048473967684022,\n",
       "  'precision_macro': 0.7963740137653181,\n",
       "  'recall_macro': 0.7930290456431535,\n",
       "  'f1_macro': 0.7946865111103383,\n",
       "  'precision_micro': 0.9048473967684022,\n",
       "  'recall_micro': 0.9048473967684022,\n",
       "  'f1_micro': 0.9048473967684022,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.94      0.95      0.95       482\\n           1       0.65      0.64      0.64        75\\n\\n    accuracy                           0.90       557\\n   macro avg       0.80      0.79      0.79       557\\nweighted avg       0.90      0.90      0.90       557\\n',\n",
       "  'confusion_matrix': array([[456,  26],\n",
       "         [ 27,  48]])},\n",
       " 'GPT_41_finetune_5_3 vs Q3_3': {'accuracy': 0.9910233393177738,\n",
       "  'precision_macro': 0.9148113790970934,\n",
       "  'recall_macro': 0.9383986928104575,\n",
       "  'f1_macro': 0.9262544684231431,\n",
       "  'precision_micro': 0.9910233393177738,\n",
       "  'recall_micro': 0.9910233393177738,\n",
       "  'f1_micro': 0.9910233393177738,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       1.00      0.99      1.00       540\\n           1       0.83      0.88      0.86        17\\n\\n    accuracy                           0.99       557\\n   macro avg       0.91      0.94      0.93       557\\nweighted avg       0.99      0.99      0.99       557\\n',\n",
       "  'confusion_matrix': array([[537,   3],\n",
       "         [  2,  15]])},\n",
       " 'GPT_41_finetune_5_4 vs Q3_4': {'accuracy': 0.8114901256732495,\n",
       "  'precision_macro': 0.6681626632954066,\n",
       "  'recall_macro': 0.6865591397849462,\n",
       "  'f1_macro': 0.6762506296741194,\n",
       "  'precision_micro': 0.8114901256732495,\n",
       "  'recall_micro': 0.8114901256732495,\n",
       "  'f1_micro': 0.8114901256732495,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.90      0.87      0.89       465\\n           1       0.44      0.50      0.47        92\\n\\n    accuracy                           0.81       557\\n   macro avg       0.67      0.69      0.68       557\\nweighted avg       0.82      0.81      0.82       557\\n',\n",
       "  'confusion_matrix': array([[406,  59],\n",
       "         [ 46,  46]])},\n",
       " 'GPT_41_finetune_5_5 vs Q3_5': {'accuracy': 0.9138240574506283,\n",
       "  'precision_macro': 0.5968816729254105,\n",
       "  'recall_macro': 0.8040087800369686,\n",
       "  'f1_macro': 0.6341543513957306,\n",
       "  'precision_micro': 0.9138240574506283,\n",
       "  'recall_micro': 0.9138240574506283,\n",
       "  'f1_micro': 0.9138240574506283,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.92      0.95       541\\n           1       0.20      0.69      0.31        16\\n\\n    accuracy                           0.91       557\\n   macro avg       0.60      0.80      0.63       557\\nweighted avg       0.97      0.91      0.94       557\\n',\n",
       "  'confusion_matrix': array([[498,  43],\n",
       "         [  5,  11]])},\n",
       " 'GPT_41_finetune_5_6 vs Q3_6': {'accuracy': 0.8689407540394973,\n",
       "  'precision_macro': 0.8575254088705038,\n",
       "  'recall_macro': 0.8624604232627895,\n",
       "  'f1_macro': 0.8598307392660771,\n",
       "  'precision_micro': 0.8689407540394973,\n",
       "  'recall_micro': 0.8689407540394973,\n",
       "  'f1_micro': 0.8689407540394973,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.81      0.84      0.82       204\\n           1       0.90      0.89      0.90       353\\n\\n    accuracy                           0.87       557\\n   macro avg       0.86      0.86      0.86       557\\nweighted avg       0.87      0.87      0.87       557\\n',\n",
       "  'confusion_matrix': array([[171,  33],\n",
       "         [ 40, 313]])},\n",
       " 'GPT_41_finetune_5_7 vs Q3_7': {'accuracy': 0.7666068222621185,\n",
       "  'precision_macro': 0.7542003116588751,\n",
       "  'recall_macro': 0.7448957309749973,\n",
       "  'f1_macro': 0.7486182858412487,\n",
       "  'precision_micro': 0.7666068222621185,\n",
       "  'recall_micro': 0.7666068222621185,\n",
       "  'f1_micro': 0.7666068222621185,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.84      0.82       344\\n           1       0.71      0.65      0.68       213\\n\\n    accuracy                           0.77       557\\n   macro avg       0.75      0.74      0.75       557\\nweighted avg       0.76      0.77      0.76       557\\n',\n",
       "  'confusion_matrix': array([[288,  56],\n",
       "         [ 74, 139]])},\n",
       " 'GPT_41_finetune_5_8 vs Q3_8': {'accuracy': 0.9353680430879713,\n",
       "  'precision_macro': 0.6331446395563771,\n",
       "  'recall_macro': 0.5728969006957622,\n",
       "  'f1_macro': 0.5918417195896434,\n",
       "  'precision_micro': 0.9353680430879713,\n",
       "  'recall_micro': 0.9353680430879713,\n",
       "  'f1_micro': 0.9353680430879713,\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.98      0.97       527\\n           1       0.31      0.17      0.22        30\\n\\n    accuracy                           0.94       557\\n   macro avg       0.63      0.57      0.59       557\\nweighted avg       0.92      0.94      0.93       557\\n',\n",
       "  'confusion_matrix': array([[516,  11],\n",
       "         [ 25,   5]])},\n",
       " 'overall_accuracy': 0.8893626570915619}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_verification(\n",
    "    GPT_41_finetune_5,\n",
    "    predicted_cols=[\n",
    "        \"GPT_41_finetune_5_1\",\n",
    "        \"GPT_41_finetune_5_2\",\n",
    "        \"GPT_41_finetune_5_3\",\n",
    "        \"GPT_41_finetune_5_4\",\n",
    "        \"GPT_41_finetune_5_5\",\n",
    "        \"GPT_41_finetune_5_6\",\n",
    "        \"GPT_41_finetune_5_7\",\n",
    "        \"GPT_41_finetune_5_8\"\n",
    "    ],\n",
    "    true_cols=[\"Q3_1\",\"Q3_2\",\"Q3_3\",\"Q3_4\",\"Q3_5\",\"Q3_6\",\"Q3_7\",\"Q3_8\"],\n",
    "    category=category_GPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d4235-188c-4e8f-9aca-797e34d00d60",
   "metadata": {},
   "source": [
    "# Other baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "271987b2-e8e4-403d-ace0-f6151e7d0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-15 12:02:51.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-15 12:02:51.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-15 12:02:51.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  9.05row/s | , âš¡ cache: 557  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GPT_41 = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category=category_GPT,\n",
    "    prompt=prompt_GPT,          \n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    api_key=api_key,\n",
    "    temperature= 0.8,\n",
    "    mode=\"text\",\n",
    "    output_column_name=\"GPT_41\",\n",
    "    num_themes=8,\n",
    "    num_votes=3,\n",
    "    wait_time = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GPT_41.to_csv(\"Result/GPT_41.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d104b8b0-9203-4c0e-8336-f660d7726483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-15 12:03:53.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-15 12:03:53.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-15 12:03:53.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  9.16row/s | , âš¡ cache: 557  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n"
     ]
    }
   ],
   "source": [
    "GPT_5_nr = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category=category_GPT,\n",
    "    prompt=prompt_GPT,          \n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=api_key,\n",
    "    reasoning_effort= \"minimal\",\n",
    "    mode=\"text\",\n",
    "    output_column_name=\"GPT_5_nano_nr\",\n",
    "    num_themes=8,\n",
    "    num_votes=3,\n",
    "    wait_time = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_5_nr.to_csv(\"Result/GPT_5_nano_nr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b4446b-44ae-40bf-8bd2-8b38efc6bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 14:57:04.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-19 14:57:04.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-19 14:57:04.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  5.22s/row | , âš¡ cache: 53  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GPT_5_r = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category=category_GPT,\n",
    "    prompt=prompt_GPT,          \n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model=\"gpt-5\",\n",
    "    api_key=api_key,\n",
    "    reasoning_effort= \"medium\",\n",
    "    mode=\"text\",\n",
    "    output_column_name=\"GPT_5_r\",\n",
    "    num_themes=8,\n",
    "    num_votes=3,\n",
    "    wait_time = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GPT_5_r.to_csv(\"Result/GPT_5_r.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741b035f-4508-4779-872b-c8cb55480014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 15:45:30.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1m[ENV] Python: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\u001b[0m\n",
      "\u001b[32m2025-10-19 15:45:30.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1m[ENV] OpenAI SDK: 1.70.0\u001b[0m\n",
      "\u001b[32m2025-10-19 15:45:30.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlabelgenius.LabelGenius\u001b[0m:\u001b[36mprint_env_info\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1m[ENV] Platform: macOS-15.6-arm64-arm-64bit\u001b[0m\n",
      "[ GPT â€¢ text_class ]   5%|â–ˆâ–                      | 27/557 | ETA 14:10 |  1.60s/row | , âš¡ cache: 0  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n",
      "Row 0 RETRY #2 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]   6%|â–ˆâ–Œ                      | 35/557 | ETA 15:07 |  1.74s/row | , âš¡ cache: 0 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n",
      "Row 0 RETRY #2 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 113/557 | ETA 19:40 |  2.66s/row | , âš¡ cache: 1 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 146/557 | ETA 10:53 |  1.59s/row | , âš¡ cache: 3 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 5, 1, 0, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 5, 1, 0, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 234/557 | ETA 08:15 |  1.54s/row | , âš¡ cache: 9 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n",
      "Row 0 RETRY #2 â€” invalid output: [0, 0, 0, 0, 0, 0, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 0, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 276/557 | ETA 06:12 |  1.33s/row | , âš¡ cache: 14 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 0, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 0, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 331/557 | ETA 05:49 |  1.55s/row | , âš¡ cache: 18 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 1, 6, 0, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 1, 6, 0, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 422/557 | ETA 03:28 |  1.54s/row | , âš¡ cache: 29 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 462/557 | ETA 01:43 |  1.09s/row | , âš¡ cache: 39 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 0, 1, 7, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 0, 1, 7, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 478/557 | ETA 01:43 |  1.32s/row | , âš¡ cache: 43 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 RETRY #1 â€” invalid output: [0, 0, 0, 0, 5, 1, 0, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 5, 1, 0, 0]\"\n",
      "Row 0 RETRY #2 â€” invalid output: [0, 1, 0, 0, 5, 0, 0, 0] (expected 8 labels). Raw: \"[0, 1, 0, 0, 5, 0, 0, 0]\"\n",
      "Row 0 RETRY #3 â€” invalid output: [0, 2, 0, 0, 1, 0, 0, 0] (expected 8 labels). Raw: \"[0, 2, 0, 0, 1, 0, 0, 0]\"\n",
      "Row 0 RETRY #4 â€” invalid output: [0, 0, 0, 0, 5, 1, 0, 0] (expected 8 labels). Raw: \"[0, 0, 0, 0, 5, 1, 0, 0]\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ]  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 480/557 | ETA 02:01 |  1.58s/row | , âš¡ cache: 43 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 FAILED after 4 retries. Last reason: invalid format repeatedly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ GPT â€¢ text_class ] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 557/557 | ETA 00:00 |  1.55s/row | , âš¡ cache: 53 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished classification of 557 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GPT_5_nr = classification_GPT(\n",
    "    text_path=\"Data_test/test_set.xlsx\",\n",
    "    category=category_GPT,\n",
    "    prompt=prompt_GPT,          \n",
    "    column_4_labeling=[\"Post_Title\"],\n",
    "    model=\"gpt-5\",\n",
    "    api_key=api_key,\n",
    "    reasoning_effort= \"minimal\",\n",
    "    mode=\"text\",\n",
    "    output_column_name=\"GPT_5_nr\",\n",
    "    num_themes=8,\n",
    "    num_votes=3,\n",
    "    wait_time = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "GPT_5_nr.to_csv(\"Result/GPT_5_nr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd916dfc-d765-444c-8ea6-87dce74766cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
