{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a79fbe4-dd49-40ec-b01a-9aebf484e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20fcab2-c28f-4222-b24d-f42be9136581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test records: 48988\n",
      "Records with valid images: 48988\n"
     ]
    }
   ],
   "source": [
    "# Load dataset N24News JSON file\n",
    "data_path = \"N24News/news/nytimes_train.json\"\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "\n",
    "# Build image_path (.jpg in N24News/imgs)\n",
    "df_test[\"image_path\"] = df_test[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(\"N24News\", \"imgs\", f\"{x}.jpg\")\n",
    ")\n",
    "df_test[\"image_exists\"] = df_test[\"image_path\"].apply(os.path.exists) # check if the image path exits\n",
    "print(\"Total test records:\", len(df_test))\n",
    "print(\"Records with valid images:\", df_test[\"image_exists\"].sum())\n",
    "# Filter for valid records only\n",
    "df_valid = df_test[df_test[\"image_exists\"]].copy()\n",
    "# Check if we have enough records for sampling (20 sample datasets * 200 records = 4000 records)\n",
    "enough_for_disjoint = len(df_valid) >= 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ed7d8e-3f43-41ad-a603-5adf7cc8799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample 1 → Data_Train/nytimes_1.json, Data_Train/nytimes_1.csv, Data_Train/imgs_1\n",
      "Saved sample 2 → Data_Train/nytimes_2.json, Data_Train/nytimes_2.csv, Data_Train/imgs_2\n",
      "Saved sample 3 → Data_Train/nytimes_3.json, Data_Train/nytimes_3.csv, Data_Train/imgs_3\n",
      "Saved sample 4 → Data_Train/nytimes_4.json, Data_Train/nytimes_4.csv, Data_Train/imgs_4\n",
      "Saved sample 5 → Data_Train/nytimes_5.json, Data_Train/nytimes_5.csv, Data_Train/imgs_5\n",
      "Saved sample 6 → Data_Train/nytimes_6.json, Data_Train/nytimes_6.csv, Data_Train/imgs_6\n",
      "Saved sample 7 → Data_Train/nytimes_7.json, Data_Train/nytimes_7.csv, Data_Train/imgs_7\n",
      "Saved sample 8 → Data_Train/nytimes_8.json, Data_Train/nytimes_8.csv, Data_Train/imgs_8\n",
      "Saved sample 9 → Data_Train/nytimes_9.json, Data_Train/nytimes_9.csv, Data_Train/imgs_9\n",
      "Saved sample 10 → Data_Train/nytimes_10.json, Data_Train/nytimes_10.csv, Data_Train/imgs_10\n",
      "Saved sample 11 → Data_Train/nytimes_11.json, Data_Train/nytimes_11.csv, Data_Train/imgs_11\n",
      "Saved sample 12 → Data_Train/nytimes_12.json, Data_Train/nytimes_12.csv, Data_Train/imgs_12\n",
      "Saved sample 13 → Data_Train/nytimes_13.json, Data_Train/nytimes_13.csv, Data_Train/imgs_13\n",
      "Saved sample 14 → Data_Train/nytimes_14.json, Data_Train/nytimes_14.csv, Data_Train/imgs_14\n",
      "Saved sample 15 → Data_Train/nytimes_15.json, Data_Train/nytimes_15.csv, Data_Train/imgs_15\n",
      "Saved sample 16 → Data_Train/nytimes_16.json, Data_Train/nytimes_16.csv, Data_Train/imgs_16\n",
      "Saved sample 17 → Data_Train/nytimes_17.json, Data_Train/nytimes_17.csv, Data_Train/imgs_17\n",
      "Saved sample 18 → Data_Train/nytimes_18.json, Data_Train/nytimes_18.csv, Data_Train/imgs_18\n",
      "Saved sample 19 → Data_Train/nytimes_19.json, Data_Train/nytimes_19.csv, Data_Train/imgs_19\n",
      "Saved sample 20 → Data_Train/nytimes_20.json, Data_Train/nytimes_20.csv, Data_Train/imgs_20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# assume df_valid exists and has columns \"image_exists\", \"section\", \"image_path\"\n",
    "valid_df = df_valid[df_valid[\"image_exists\"]]\n",
    "\n",
    "# Section → numeric mapping\n",
    "section_mapping = {\n",
    "    \"Health\": 1, \"Science\": 2, \"Television\": 3, \"Travel\": 4, \"Movies\": 5,\n",
    "    \"Dance\": 6, \"Real Estate\": 7, \"Economy\": 8, \"Sports\": 9, \"Theater\": 10,\n",
    "    \"Opinion\": 11, \"Music\": 12, \"Books\": 13, \"Art & Design\": 14, \"Style\": 15,\n",
    "    \"Media\": 16, \"Food\": 17, \"Well\": 18, \"Fashion & Style\": 19, \"Technology\": 20,\n",
    "    \"Your Money\": 21, \"Education\": 22, \"Automobiles\": 23, \"Global Business\": 24\n",
    "}\n",
    "\n",
    "base_dir = \"Data_Train\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    # Sample\n",
    "    sample_df = valid_df.sample(n=200, random_state=1000 + i).copy()\n",
    "    sample_df[\"section_numeric\"] = sample_df[\"section\"].map(section_mapping)\n",
    "\n",
    "    # Paths under Data_Train/\n",
    "    json_path = os.path.join(base_dir, f\"nytimes_{i}.json\")\n",
    "    csv_path  = os.path.join(base_dir, f\"nytimes_{i}.csv\")\n",
    "    imgs_dir  = os.path.join(base_dir, f\"imgs_{i}\")\n",
    "    os.makedirs(imgs_dir, exist_ok=True)\n",
    "\n",
    "    # Save JSON\n",
    "    records = sample_df.drop(columns=[\"image_exists\"]).to_dict(orient=\"records\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Save CSV\n",
    "    sample_df.drop(columns=[\"image_exists\"]).to_csv(csv_path, index=False)\n",
    "\n",
    "    # Copy images\n",
    "    for _, row in sample_df.iterrows():\n",
    "        src = row[\"image_path\"]\n",
    "        if os.path.exists(src):\n",
    "            dst = os.path.join(imgs_dir, os.path.basename(src))\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "    print(f\"Saved sample {i} → {json_path}, {csv_path}, {imgs_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fd9e8d-9a58-4c70-9e7d-ed0883cb5bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 48988\n",
      "Records with valid images: 48988\n",
      "Saved 4000-sample →\n",
      "  JSON: Data_test/nytimes_test_sample4000.json\n",
      "  CSV:  Data_test/nytimes_test_sample4000.csv\n",
      "  IMGS: Data_test/imgs_test_sample4000\n"
     ]
    }
   ],
   "source": [
    "# 1) Load the full dataset and build image paths\n",
    "data_path = \"N24News/news/nytimes_train.json\"\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(\"N24News\", \"imgs\", f\"{x}.jpg\")\n",
    ")\n",
    "df[\"image_exists\"] = df[\"image_path\"].apply(os.path.exists)\n",
    "\n",
    "print(\"Total records:\", len(df))\n",
    "print(\"Records with valid images:\", df[\"image_exists\"].sum())\n",
    "\n",
    "# 2) Filter to only valid‐image rows\n",
    "df_valid = df[df[\"image_exists\"]].copy()\n",
    "\n",
    "# 3) Sample 4000 rows for testing\n",
    "sample_df = df_valid.sample(n=4000, random_state=42).copy()\n",
    "\n",
    "# 4) Map section names → numeric codes\n",
    "sample_df[\"section_numeric\"] = sample_df[\"section\"].map(section_mapping)\n",
    "\n",
    "# 5) Prepare output directory\n",
    "base_test_dir = \"Data_test\"\n",
    "os.makedirs(base_test_dir, exist_ok=True)\n",
    "\n",
    "# 6) Save sampled JSON\n",
    "out_json = os.path.join(base_test_dir, \"nytimes_test_sample4000.json\")\n",
    "with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    records = sample_df.drop(columns=[\"image_exists\"], errors=\"ignore\").to_dict(orient=\"records\")\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 7) Save sampled CSV\n",
    "out_csv = os.path.join(base_test_dir, \"nytimes_test_sample4000.csv\")\n",
    "sample_df.drop(columns=[\"image_exists\"], errors=\"ignore\").to_csv(out_csv, index=False)\n",
    "\n",
    "# 8) Copy sampled images\n",
    "imgs_test_dir = os.path.join(base_test_dir, \"imgs_test_sample4000\")\n",
    "os.makedirs(imgs_test_dir, exist_ok=True)\n",
    "for _, row in sample_df.iterrows():\n",
    "    src = row[\"image_path\"]\n",
    "    if os.path.exists(src):\n",
    "        dst = os.path.join(imgs_test_dir, os.path.basename(src))\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "print(f\"Saved 4000-sample →\\n  JSON: {out_json}\\n  CSV:  {out_csv}\\n  IMGS: {imgs_test_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a4c39e-57d3-4c0e-a7ae-3fdbfba26f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images copied into Data_train/imgs_all\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "BASE_PATH = \"Data_train\"\n",
    "IMG_DIR_TEMPLATE = \"imgs_{}\"\n",
    "MERGED_IMG_DIR = os.path.join(BASE_PATH, \"imgs_all\")\n",
    "\n",
    "# 1) Create the merged folder if it doesn't exist\n",
    "os.makedirs(MERGED_IMG_DIR, exist_ok=True)\n",
    "\n",
    "# 2) Copy all images from imgs_1 … imgs_20 into imgs_all\n",
    "for i in range(1, 21):\n",
    "    src_dir = os.path.join(BASE_PATH, IMG_DIR_TEMPLATE.format(i))\n",
    "    if not os.path.isdir(src_dir):\n",
    "        continue\n",
    "    for fname in os.listdir(src_dir):\n",
    "        src_path = os.path.join(src_dir, fname)\n",
    "        dst_path = os.path.join(MERGED_IMG_DIR, fname)\n",
    "        # if you want to avoid overwriting same-named files, you could add a prefix:\n",
    "        # dst_path = os.path.join(MERGED_IMG_DIR, f\"round{i}_{fname}\")\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(f\"All images copied into {MERGED_IMG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42257495-805b-4bcf-af20-dcacbade9e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
